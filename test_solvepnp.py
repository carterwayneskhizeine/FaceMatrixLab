#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
solvePnPæµ‹è¯•è„šæœ¬
å¿«é€ŸéªŒè¯é‡æŠ•å½±è¯¯å·®æ”¹å–„æƒ…å†µ
"""

import cv2
import mediapipe as mp
import numpy as np
import time

# MediaPipe å¯¼å…¥
BaseOptions = mp.tasks.BaseOptions
FaceLandmarker = mp.tasks.vision.FaceLandmarker
FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
VisionRunningMode = mp.tasks.vision.RunningMode

def load_obj_vertices(path):
    """åŠ è½½OBJæ–‡ä»¶é¡¶ç‚¹"""
    vertices = []
    with open(path, 'r') as f:
        for line in f:
            if line.startswith('v '):
                parts = line.strip().split()
                x, y, z = float(parts[1]), float(parts[2]), float(parts[3])
                vertices.append([x, y, z])
    return np.array(vertices, dtype=np.float32)

def load_camera_calibration():
    """åŠ è½½ç›¸æœºæ ‡å®šå‚æ•°"""
    try:
        if os.path.exists("calib.npz"):
            calib_data = np.load("calib.npz")
            return calib_data['K'], calib_data['dist']
        else:
            print("æ ‡å®šæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ä¼°è®¡å‚æ•°")
            K = np.array([[1000, 0, 640], [0, 1000, 360], [0, 0, 1]], dtype=np.float32)
            dist = np.zeros((5,), dtype=np.float64)
            return K, dist
    except:
        print("åŠ è½½æ ‡å®šå¤±è´¥ï¼Œä½¿ç”¨ä¼°è®¡å‚æ•°")
        K = np.array([[1000, 0, 640], [0, 1000, 360], [0, 0, 1]], dtype=np.float32)
        dist = np.zeros((5,), dtype=np.float64)
        return K, dist

def test_solvepnp():
    """æµ‹è¯•solvePnPå®ç°"""
    print("=== solvePnPæµ‹è¯•å¼€å§‹ ===")
    
    # åŠ è½½æ¨¡å‹å’Œæ ‡å®š
    try:
        vertices = load_obj_vertices("obj/Andy_Wah_facemesh.obj")
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {len(vertices)} ä¸ªé¡¶ç‚¹")
        
        # æ¨¡å‹å°ºå¯¸åˆ†æ
        bbox = np.array([
            [vertices[:, 0].min(), vertices[:, 1].min(), vertices[:, 2].min()],
            [vertices[:, 0].max(), vertices[:, 1].max(), vertices[:, 2].max()]
        ])
        width = bbox[1, 0] - bbox[0, 0]
        height = bbox[1, 1] - bbox[0, 1]
        depth = bbox[1, 2] - bbox[0, 2]
        
        print(f"ğŸ“ æ¨¡å‹å°ºå¯¸: å®½{width:.2f} é«˜{height:.2f} æ·±{depth:.2f}")
        
        # ç¼©æ”¾åˆ°çœŸå®äººè„¸å°ºå¯¸
        target_width = 160.0  # æ¯«ç±³
        scale_factor = target_width / width
        vertices_scaled = vertices * scale_factor
        
        print(f"ğŸ”§ ç¼©æ”¾ç³»æ•°: {scale_factor:.3f}x (ç›®æ ‡å®½åº¦{target_width}mm)")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # åŠ è½½ç›¸æœºæ ‡å®š
    K, dist = load_camera_calibration()
    print("ğŸ“· ç›¸æœºå‚æ•°:")
    print(f"   fx={K[0,0]:.2f}, fy={K[1,1]:.2f}")
    print(f"   cx={K[0,2]:.2f}, cy={K[1,2]:.2f}")
    
    # å…³é”®ç‚¹ç´¢å¼•
    pnp_indices = [1, 168, 10, 152, 175, 33, 263, 130, 359, 70, 300, 107, 336, 19, 94, 234, 454, 172, 397]
    
    # åˆ›å»ºMediaPipeæ£€æµ‹å™¨
    model_path = "face_landmarker.task"
    if not os.path.exists(model_path):
        print("âŒ MediaPipeæ¨¡å‹ä¸å­˜åœ¨")
        return
    
    options = FaceLandmarkerOptions(
        base_options=BaseOptions(model_asset_path=model_path),
        running_mode=VisionRunningMode.VIDEO,
        num_faces=1
    )
    
    try:
        landmarker = FaceLandmarker.create_from_options(options)
        print("âœ… MediaPipeæ£€æµ‹å™¨åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ MediaPipeæ£€æµ‹å™¨åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # å¼€å§‹æ‘„åƒå¤´æµ‹è¯•
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return
    
    print("ğŸ¥ å¼€å§‹æµ‹è¯•...")
    print("æŒ‰ESCé€€å‡ºï¼ŒæŒ‰ç©ºæ ¼æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯")
    
    frame_count = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame = cv2.flip(frame, 1)
            frame_count += 1
            
            # è½¬æ¢ä¸ºRGB
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
            
            # æ£€æµ‹
            timestamp_ms = int(time.time() * 1000)
            result = landmarker.detect_for_video(mp_image, timestamp_ms)
            
            if result.face_landmarks:
                landmarks = result.face_landmarks[0]
                
                # å‡†å¤‡solvePnPæ•°æ®
                img_points = []
                obj_points = []
                
                for idx in pnp_indices:
                    if idx < len(landmarks) and idx < len(vertices_scaled):
                        x_pixel = landmarks[idx].x * frame.shape[1]
                        y_pixel = landmarks[idx].y * frame.shape[0]
                        img_points.append([x_pixel, y_pixel])
                        obj_points.append(vertices_scaled[idx])
                
                if len(img_points) >= 8:
                    img_points = np.array(img_points, dtype=np.float32)
                    obj_points = np.array(obj_points, dtype=np.float32)
                    
                    # solvePnP
                    try:
                        success, rvec, tvec = cv2.solvePnP(
                            obj_points, img_points, K, dist,
                            flags=cv2.SOLVEPNP_ITERATIVE
                        )
                        
                        if success:
                            # è®¡ç®—é‡æŠ•å½±è¯¯å·®
                            reproj_points, _ = cv2.projectPoints(obj_points, rvec, tvec, K, dist)
                            reproj_points = reproj_points.reshape(-1, 2)
                            reproj_error = np.mean(np.linalg.norm(img_points - reproj_points, axis=1))
                            
                            # æ˜¾ç¤ºç»“æœ
                            if reproj_error < 10:
                                color = (0, 255, 0)  # ç»¿è‰²ï¼šä¼˜ç§€
                                status = "ä¼˜ç§€"
                            elif reproj_error < 20:
                                color = (0, 255, 255)  # é»„è‰²ï¼šè‰¯å¥½
                                status = "è‰¯å¥½"
                            else:
                                color = (0, 0, 255)  # çº¢è‰²ï¼šéœ€æ”¹è¿›
                                status = "éœ€æ”¹è¿›"
                            
                            cv2.putText(frame, f"Reproj Error: {reproj_error:.2f}px ({status})", 
                                      (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
                            
                            # æ¯30å¸§è¾“å‡ºè¯¦ç»†ä¿¡æ¯
                            if frame_count % 30 == 0:
                                print(f"ç¬¬{frame_count}å¸§ - é‡æŠ•å½±è¯¯å·®: {reproj_error:.2f}px ({status})")
                                print(f"  å¹³ç§»: T=[{tvec[0,0]:.1f}, {tvec[1,0]:.1f}, {tvec[2,0]:.1f}]mm")
                        else:
                            cv2.putText(frame, "solvePnP Failed", (10, 30), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                    
                    except Exception as e:
                        cv2.putText(frame, f"Error: {str(e)[:30]}", (10, 30), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                
                # ç»˜åˆ¶å…³é”®ç‚¹
                for idx in pnp_indices:
                    if idx < len(landmarks):
                        x = int(landmarks[idx].x * frame.shape[1])
                        y = int(landmarks[idx].y * frame.shape[0])
                        cv2.circle(frame, (x, y), 3, (255, 0, 0), -1)
            
            cv2.imshow('solvePnPæµ‹è¯•', frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC
                break
    
    except KeyboardInterrupt:
        print("\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    
    finally:
        cap.release()
        cv2.destroyAllWindows()
        print("=== æµ‹è¯•ç»“æŸ ===")

if __name__ == "__main__":
    import os
    test_solvepnp() 