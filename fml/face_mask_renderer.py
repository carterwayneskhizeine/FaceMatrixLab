#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FaceMatrixLab 3D é¢å…·æ¸²æŸ“å™¨
ä½¿ç”¨ MediaPipe çš„ faceLandmarks (468ä¸ªNormalizedLandmarkç‚¹) æ¥æŒ‚è½½å¹¶æ¸²æŸ“ Andy_Wah_facemesh.obj æ¨¡å‹
é‡ç‚¹ä½¿ç”¨é¢å¤´ã€å·¦è„¸é¢Šã€ä¸‹å·´ã€å³è„¸é¢Šè¿™4ä¸ªç‰¹å®šç‚¹å®ç°ARè·Ÿè¸ªæ•ˆæœ
ğŸ†• æ–°å¢ï¼šåŸºäº BlendShapes çš„è¡¨æƒ…é©±åŠ¨ç³»ç»Ÿ
"""

import cv2
import mediapipe as mp
import numpy as np
import time
import os
import threading
import queue
import open3d as o3d

# MediaPipe å¯¼å…¥
BaseOptions = mp.tasks.BaseOptions
FaceLandmarker = mp.tasks.vision.FaceLandmarker
FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
FaceLandmarkerResult = mp.tasks.vision.FaceLandmarkerResult
VisionRunningMode = mp.tasks.vision.RunningMode

class FaceMaskRenderer:
    def __init__(self, camera_id=0, model_path="obj/Andy_Wah_facemesh.obj"):
        """åˆå§‹åŒ–3Dé¢å…·æ¸²æŸ“å™¨"""
        print("=== FaceMatrixLab 3D é¢å…·æ¸²æŸ“å™¨åˆå§‹åŒ– ===")
        
        # åŸºæœ¬å‚æ•°
        self.camera_id = camera_id
        self.model_path = model_path
        self.is_running = False
        
        # æ¸²æŸ“å‚æ•°
        self.render_width = 1280
        self.render_height = 720
        self.fps_target = 30
        
        # ğŸ”‘ é‡è¦ï¼šæ·»åŠ å®½é«˜æ¯”å¤„ç†ï¼ˆå‚è€ƒface_landmarker_cmaera_new.pyï¼‰
        self.camera_width = 1280   # æ‘„åƒå¤´åˆ†è¾¨ç‡
        self.camera_height = 720   # æ‘„åƒå¤´åˆ†è¾¨ç‡  
        self.aspect_ratio = self.camera_width / self.camera_height
        # ğŸ”§ æ¢å¤ï¼šé‡æ–°å¯ç”¨x_scale_factorç”¨äºå®½é«˜æ¯”ä¿®æ­£
        self.x_scale_factor = self.aspect_ratio / 1.0  # å¯¹äº16:9ï¼Œçº¦ä¸º1.777
        
        # MediaPipe ç›¸å…³
        self.landmarker = None
        self.mp_model_path = self.download_mediapipe_model()
        
        # ğŸ”‘ å…³é”®ï¼šä½¿ç”¨468ä¸ªfaceLandmarksä¸­çš„4ä¸ªç‰¹å®šç‚¹
        self.forehead_index = 10    # é¢å¤´
        self.left_cheek_index = 234  # å·¦è„¸é¢Š
        self.chin_index = 152        # ä¸‹å·´
        self.right_cheek_index = 454  # å³è„¸é¢Š
        
        # æ•°æ®é˜Ÿåˆ— - ç”¨äºçº¿ç¨‹é—´é€šä¿¡
        self.data_queue = queue.Queue(maxsize=5)
        
        # ARæ¸²æŸ“ç›¸å…³
        self.show_camera_background = True  # é»˜è®¤æ˜¾ç¤ºæ‘„åƒæœºèƒŒæ™¯
        self.latest_camera_frame = None     # ä¿å­˜æœ€æ–°çš„æ‘„åƒæœºå¸§
        
        # é¢å…·è®¾ç½®
        self.current_mask_color = [0.8, 0.7, 0.6]  # é»˜è®¤è‚¤è‰²
        self.mask_colors = [
            [0.8, 0.7, 0.6],  # è‚¤è‰²
            [0.9, 0.1, 0.1],  # çº¢è‰²
            [0.1, 0.8, 0.2],  # ç»¿è‰²
            [0.2, 0.2, 0.9],  # è“è‰²
            [0.9, 0.7, 0.1],  # é‡‘è‰²
            [0.7, 0.3, 0.9],  # ç´«è‰²
        ]
        self.current_color_index = 0
        
        # è°ƒè¯•å’Œè·Ÿè¸ª
        self.debug_mode = True
        self.frame_count = 0
        
        # ğŸ†• æ–°å¢ï¼šå¹³æ»‘ç›¸æœºç§»åŠ¨ç³»æ•°
        self.camera_x_smoothing = 1.0  # çº¿æ€§æ’å€¼ç³»æ•°ï¼Œå€¼è¶Šå°è¶Šå¹³æ»‘
        
        # ğŸ†• æ–°å¢ï¼šåŸå§‹landmarksæ˜¾ç¤ºæ§åˆ¶
        self.show_original_landmarks = True  # æ˜¾ç¤ºåŸå§‹landmarksç‚¹å’Œçº¿æ¡†
        
        # ğŸ†• æ–°å¢ï¼šçº¹ç†è´´å›¾æ§åˆ¶
        self.texture_mode = True             # ä¼˜å…ˆä½¿ç”¨çº¹ç†è´´å›¾
        self.has_texture = False             # æ˜¯å¦æˆåŠŸåŠ è½½çº¹ç†
        
        # åŠ è½½3Dæ¨¡å‹
        if not self.load_face_model():
            raise Exception("æ— æ³•åŠ è½½3Dæ¨¡å‹æ–‡ä»¶")
        
        # ğŸ†• å…³é”®ï¼šæå–æ¨¡å‹ä¸­4ä¸ªå…³é”®é¡¶ç‚¹çš„åæ ‡
        self.extract_model_key_points()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.current_fps = 0
        
        print("âœ… FaceMatrixLab 3D é¢å…·æ¸²æŸ“å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ å®½é«˜æ¯”è®¾ç½®: {self.aspect_ratio:.3f} (16:9)")
        print(f"ğŸ“ Xåæ ‡ä¿®æ­£ç³»æ•°: {self.x_scale_factor:.3f}")
    
    def _lm_to_pixel(self, lm, mirror=True):
        """MediaPipe å½’ä¸€åŒ– landmark â†’ 1280Ã—720 åƒç´ åæ ‡"""
        # ç›´æ¥è½¬æ¢åˆ°åƒç´ åæ ‡ï¼Œä¸åšé¢å¤–çš„æ¯”ä¾‹ä¿®æ­£
        x = lm.x * self.render_width
        y = lm.y * self.render_height
        
        if mirror:  # æ°´å¹³ç¿»è½¬ï¼ˆæ‘„åƒå¤´é•œåƒæ•ˆæœï¼‰
            x = self.render_width - 1 - x
            
        return np.array([x, y, lm.z], dtype=np.float32)
    
    def download_mediapipe_model(self):
        """ä¸‹è½½MediaPipeäººè„¸æ ‡å¿—æ£€æµ‹æ¨¡å‹"""
        model_url = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
        model_path = "face_landmarker.task"
        
        if not os.path.exists(model_path):
            print("æ­£åœ¨ä¸‹è½½MediaPipeæ¨¡å‹...")
            try:
                import urllib.request
                urllib.request.urlretrieve(model_url, model_path)
                print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_path}")
            except Exception as e:
                print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
                return None
        else:
            print(f"âœ… MediaPipeæ¨¡å‹å·²å­˜åœ¨: {model_path}")
        
        return model_path
    
    def load_face_model(self):
        """åŠ è½½3Däººè„¸æ¨¡å‹"""
        if not os.path.exists(self.model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            return False
            
        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½3Dæ¨¡å‹: {self.model_path}")
        
        try:
            # åŠ è½½æ¨¡å‹ï¼ˆå¯ç”¨åå¤„ç†ä»¥è¯»å–æè´¨ä¿¡æ¯ï¼‰
            self.face_mesh = o3d.io.read_triangle_mesh(self.model_path, enable_post_processing=True)
            
            if len(self.face_mesh.vertices) == 0:
                print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼šæ²¡æœ‰é¡¶ç‚¹æ•°æ®")
                return False
            
            # âœ… ä»…å½“ OBJ æ²¡æœ‰ vn è®°å½•æ—¶æ‰è¡¥ç®—æ³•çº¿
            if len(self.face_mesh.vertex_normals) == 0:
                self.face_mesh.compute_vertex_normals()
                print("ğŸ”§ OBJæ–‡ä»¶æ²¡æœ‰æ³•çº¿æ•°æ®ï¼Œå·²è‡ªåŠ¨è®¡ç®—")
            else:
                print(f"âœ… å·²è¯»å– {len(self.face_mesh.vertex_normals)} æ¡åŠ æƒï¼ˆå¹³æ»‘ï¼‰é¡¶ç‚¹æ³•çº¿")
            
            # è·å–é¡¶ç‚¹ä¿¡æ¯
            vertices = np.asarray(self.face_mesh.vertices)
            self.num_vertices = len(vertices)
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ:")
            print(f"   é¡¶ç‚¹æ•°: {self.num_vertices}")
            print(f"   é¢æ•°: {len(self.face_mesh.triangles)}")
            print(f"   åæ ‡èŒƒå›´:")
            print(f"     X: [{vertices[:, 0].min():.2f}, {vertices[:, 0].max():.2f}] mm")
            print(f"     Y: [{vertices[:, 1].min():.2f}, {vertices[:, 1].max():.2f}] mm") 
            print(f"     Z: [{vertices[:, 2].min():.2f}, {vertices[:, 2].max():.2f}] mm")
            
            # ğŸ†• æ–°å¢ï¼šå°è¯•åŠ è½½çº¹ç†è´´å›¾
            texture_path = "obj/enhanced_texture.png"
            if os.path.exists(texture_path):
                try:
                    print(f"ğŸ¨ æ­£åœ¨åŠ è½½çº¹ç†è´´å›¾: {texture_path}")
                    tex_img = o3d.io.read_image(texture_path)
                    
                    # ğŸ”§ ä¿®å¤UVåæ ‡é—®é¢˜ï¼šä¸Šä¸‹ç¿»è½¬çº¹ç†
                    print("ğŸ”„ ä¿®æ­£çº¹ç†æ–¹å‘ï¼ˆä¸Šä¸‹ç¿»è½¬ï¼‰...")
                    img_array = np.asarray(tex_img)
                    
                    # ä¸Šä¸‹ç¿»è½¬å›¾åƒæ•°ç»„
                    flipped_array = np.flipud(img_array).copy()  # ç¡®ä¿æ•°ç»„è¿ç»­
                    
                    # è½¬æ¢å›Open3Då›¾åƒæ ¼å¼
                    flipped_tex_img = o3d.geometry.Image(flipped_array)
                    self.face_mesh.textures = [flipped_tex_img]
                    
                    # å¦‚æœæ¨¡å‹æ²¡æœ‰æè´¨IDï¼Œè®¾ç½®æ‰€æœ‰é¢éƒ½ä½¿ç”¨çº¹ç†ç´¢å¼•0
                    if len(self.face_mesh.triangle_material_ids) == 0:
                        self.face_mesh.triangle_material_ids = o3d.utility.IntVector([0] * len(self.face_mesh.triangles))
                    
                    print(f"âœ… çº¹ç†è´´å›¾åŠ è½½æˆåŠŸ")
                    # è·å–å›¾åƒå°ºå¯¸ï¼ˆOpen3Dæ–¹å¼ï¼‰
                    height, width = img_array.shape[:2]
                    print(f"   çº¹ç†å°ºå¯¸: {width} x {height}")
                    print(f"   å·²ä¿®æ­£UVåæ ‡æ–¹å‘")
                    self.has_texture = True
                    
                except Exception as e:
                    print(f"âš ï¸ çº¹ç†åŠ è½½å¤±è´¥: {e}")
                    self.has_texture = False
            else:
                print(f"âš ï¸ çº¹ç†æ–‡ä»¶ä¸å­˜åœ¨: {texture_path}")
                self.has_texture = False
            
            # ğŸ”§ ä¿®æ”¹ï¼šåªæœ‰å½“æ²¡æœ‰çº¹ç†æ—¶æ‰ä½¿ç”¨ç»Ÿä¸€é¢œè‰²
            if not hasattr(self, 'has_texture') or not self.has_texture:
                print("ğŸ¨ ä½¿ç”¨ç»Ÿä¸€é¢œè‰²æ¸²æŸ“")
                self.change_mask_color(self.current_color_index)
            else:
                print("ğŸ¨ ä½¿ç”¨çº¹ç†è´´å›¾æ¸²æŸ“")
            
            # å¤‡ä»½åŸå§‹é¡¶ç‚¹å’Œæ³•çº¿
            self.original_vertices = np.asarray(self.face_mesh.vertices).copy()
            self.original_normals = np.asarray(self.face_mesh.vertex_normals).copy()
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def change_mask_color(self, color_index):
        """æ›´æ”¹é¢å…·é¢œè‰²"""
        if 0 <= color_index < len(self.mask_colors):
            self.current_color_index = color_index
            self.current_mask_color = self.mask_colors[color_index]
            
            # ğŸ”§ ä¿®æ”¹ï¼šåªæœ‰åœ¨æ²¡æœ‰çº¹ç†æ—¶æ‰åº”ç”¨ç»Ÿä¸€é¢œè‰²
            if not hasattr(self, 'has_texture') or not self.has_texture:
                self.face_mesh.paint_uniform_color(self.current_mask_color)
                print(f"ğŸ­ é¢å…·é¢œè‰²å·²æ›´æ”¹ä¸ºç´¢å¼• {color_index}")
            else:
                print(f"ğŸ¨ å½“å‰ä½¿ç”¨çº¹ç†è´´å›¾ï¼Œé¢œè‰²åˆ‡æ¢å·²ç¦ç”¨")
            return True
        return False
    
    def toggle_texture_mode(self):
        """ğŸ†• åˆ‡æ¢çº¹ç†/é¢œè‰²æ¨¡å¼"""
        if self.has_texture:
            self.texture_mode = not self.texture_mode
            
            if self.texture_mode:
                print("ğŸ¨ åˆ‡æ¢åˆ°çº¹ç†è´´å›¾æ¨¡å¼")
                # æ¸…é™¤é¡¶ç‚¹é¢œè‰²ï¼Œæ¢å¤çº¹ç†
                self.face_mesh.vertex_colors = o3d.utility.Vector3dVector([])
            else:
                print("ğŸ¨ åˆ‡æ¢åˆ°ç»Ÿä¸€é¢œè‰²æ¨¡å¼")
                # åº”ç”¨ç»Ÿä¸€é¢œè‰²
                self.face_mesh.paint_uniform_color(self.current_mask_color)
        else:
            print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„çº¹ç†è´´å›¾ï¼Œæ— æ³•åˆ‡æ¢")
    
    def setup_visualizer(self):
        """è®¾ç½®Open3Då¯è§†åŒ–å™¨"""
        print("ğŸ¨ åˆå§‹åŒ–Open3Då¯è§†åŒ–å™¨...")
        # åˆ›å»ºå¯è§†åŒ–å™¨çª—å£ï¼ˆç¦»å±æ¸²æŸ“ï¼‰
        self.vis = o3d.visualization.Visualizer()
        self.vis.create_window("FaceMask Renderer", self.render_width, self.render_height, visible=False)
        
        # æ·»åŠ äººè„¸æ¨¡å‹
        self.vis.add_geometry(self.face_mesh)
        
        # è®¾ç½®æ¸²æŸ“é€‰é¡¹
        render_option = self.vis.get_render_option()
        render_option.mesh_show_back_face = True
        render_option.background_color = np.array([0.0, 0.0, 0.0])  # é»‘è‰²èƒŒæ™¯ä¾¿äºåˆæˆ
        
        # ğŸ†• è®¾ç½®æè´¨ç²—ç³™åº¦åˆ°æœ€é«˜ï¼ˆé™ä½åå°„ï¼‰
        render_option.light_on = True
        # ç¦ç”¨å…‰æ»‘ç€è‰²ï¼Œä½¿ç”¨æ›´ç²—ç³™çš„æ•ˆæœ
        render_option.mesh_show_wireframe = False
        render_option.point_show_normal = False
        
        print("ğŸ¨ æè´¨è®¾ç½®: æœ€é«˜ç²—ç³™åº¦ï¼ˆæ— åå°„ï¼‰")
        
        # è®¾ç½®ç›¸æœºè§†è§’
        ctr = self.vis.get_view_control()
        ctr.set_zoom(1.0)
        
        print("âœ… Open3Då¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        return True
    
    def create_mediapipe_landmarker(self):
        """åˆ›å»ºMediaPipeäººè„¸æ ‡å¿—æ£€æµ‹å™¨"""
        if not self.mp_model_path:
            return None
            
        try:
            options = FaceLandmarkerOptions(
                base_options=BaseOptions(model_asset_path=self.mp_model_path),
                running_mode=VisionRunningMode.VIDEO,
                num_faces=1,
                min_face_detection_confidence=0.5,
                min_face_presence_confidence=0.5,
                min_tracking_confidence=0.5,
                output_face_blendshapes=False,  # ğŸ”‘ å…³é”®ï¼šç¦ç”¨BlendShapesè¾“å‡º
                output_facial_transformation_matrixes=False,  # ğŸ”‘ å…³é”®ï¼šä¸ä½¿ç”¨transformation_matrix
            )
            
            landmarker = FaceLandmarker.create_from_options(options)
            print("âœ… MediaPipeäººè„¸æ£€æµ‹å™¨åˆ›å»ºæˆåŠŸ")
            return landmarker
            
        except Exception as e:
            print(f"âŒ MediaPipeæ£€æµ‹å™¨åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def detection_thread(self):
        """MediaPipeæ£€æµ‹çº¿ç¨‹"""
        print("ğŸ¥ å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹...")
        
        # åˆ›å»ºæ£€æµ‹å™¨
        self.landmarker = self.create_mediapipe_landmarker()
        if not self.landmarker:
            print("âŒ MediaPipeæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥")
            return
        
        # æ‰“å¼€æ‘„åƒå¤´
        cap = cv2.VideoCapture(self.camera_id)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_id}")
            return
        
        # è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨ç‡
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        frame_count = 0
        fps_start_time = time.time()
        
        try:
            while self.is_running:
                ret, frame = cap.read()
                if not ret:
                    continue
                
                frame = cv2.flip(frame, 1)  # é•œåƒç¿»è½¬
                frame_count += 1
                
                # è½¬æ¢ä¸ºRGB
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
                
                # è¿›è¡Œäººè„¸æ£€æµ‹
                timestamp_ms = int(time.time() * 1000)
                detection_result = self.landmarker.detect_for_video(mp_image, timestamp_ms)
                
                # å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
                try:
                    data_packet = {
                        'detection_result': detection_result,
                        'frame': rgb_frame,
                        'timestamp': timestamp_ms
                    }
                    self.data_queue.put_nowait(data_packet)
                except queue.Full:
                    # å¦‚æœé˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒæœ€æ—§çš„æ•°æ®
                    try:
                        self.data_queue.get_nowait()
                        self.data_queue.put_nowait(data_packet)
                    except queue.Empty:
                        pass
                
                # è®¡ç®—æ£€æµ‹FPS
                if frame_count % 30 == 0:
                    elapsed = time.time() - fps_start_time
                    self.current_fps = 30.0 / elapsed
                    fps_start_time = time.time()
                
                # æ§åˆ¶å¸§ç‡
                time.sleep(1.0 / self.fps_target)
                
        except Exception as e:
            print(f"âŒ æ£€æµ‹çº¿ç¨‹é”™è¯¯: {e}")
        finally:
            cap.release()
            print("ğŸ¥ MediaPipeæ£€æµ‹çº¿ç¨‹å·²åœæ­¢")
    
    def extract_model_key_points(self):
        """ğŸ†• æå–æ¨¡å‹ä¸­4ä¸ªå…³é”®é¡¶ç‚¹çš„3Dåæ ‡"""
        try:
            # è·å–æ¨¡å‹é¡¶ç‚¹
            vertices = np.asarray(self.face_mesh.vertices)
            
            # æå–4ä¸ªå…³é”®ç‚¹ï¼ˆindexä¸landmarksä¸€è‡´ï¼‰
            self.model_forehead = vertices[self.forehead_index].copy()      # é¢å¤´: 10
            self.model_left_cheek = vertices[self.left_cheek_index].copy()  # å·¦è„¸é¢Š: 234
            self.model_chin = vertices[self.chin_index].copy()              # ä¸‹å·´: 152
            self.model_right_cheek = vertices[self.right_cheek_index].copy() # å³è„¸é¢Š: 454
            
            print(f"ğŸ¯ æ¨¡å‹å…³é”®ç‚¹æå–æˆåŠŸ:")
            print(f"   é¢å¤´[{self.forehead_index}]: {self.model_forehead}")
            print(f"   å·¦è„¸é¢Š[{self.left_cheek_index}]: {self.model_left_cheek}")
            print(f"   ä¸‹å·´[{self.chin_index}]: {self.model_chin}")
            print(f"   å³è„¸é¢Š[{self.right_cheek_index}]: {self.model_right_cheek}")
            
            # è®¡ç®—æ¨¡å‹çš„å°ºå¯¸ä¿¡æ¯
            model_width = np.linalg.norm(self.model_right_cheek - self.model_left_cheek)
            model_height = np.linalg.norm(self.model_chin - self.model_forehead)
            print(f"   æ¨¡å‹é¢éƒ¨å°ºå¯¸: å®½åº¦={model_width:.2f}mm, é«˜åº¦={model_height:.2f}mm")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹å…³é”®ç‚¹æå–å¤±è´¥: {e}")
            return False
    
    def _follow_face_horizontally(self, model_offset_x):
        """ğŸ†• æ–°å¢ï¼šè®©3Dç›¸æœºåœ¨æ°´å¹³æ–¹å‘ä¸Šå¹³æ»‘è·Ÿéšäººè„¸ä¸­å¿ƒ"""
        try:
            # è·å–è§†å›¾æ§åˆ¶å™¨å’Œç›¸æœºå‚æ•°
            ctr = self.vis.get_view_control()
            cam = ctr.convert_to_pinhole_camera_parameters()

            # å…³é”®ï¼šåˆ›å»ºå¯å†™å‰¯æœ¬ä»¥ä¿®æ”¹
            extrinsic = cam.extrinsic.copy()

            # ç›®æ ‡ï¼šæˆ‘ä»¬å¸Œæœ›ç›¸æœºç§»åŠ¨åˆ° model_offset_x çš„ä½ç½®ã€‚
            # åœ¨Open3Dçš„è§†å›¾çŸ©é˜µ(extrinsic)ä¸­ï¼Œå¹³ç§»åˆ†é‡æ˜¯ç›¸æœºä½ç½®çš„è´Ÿå€¼ã€‚
            # æ‰€ä»¥ï¼Œè¦è®©ç›¸æœºç§»åŠ¨åˆ° +X çš„ä½ç½®ï¼Œè§†å›¾çŸ©é˜µçš„Xå¹³ç§»éœ€è¦æ˜¯ -Xã€‚
            # ä¿®æ­£ï¼šä¸ºäº†è®©æ¨¡å‹åœ¨å±å¹•ä¸Šçœ‹èµ·æ¥ç§»åŠ¨äº† model_offset_xï¼Œç›¸æœºéœ€è¦åå‘ç§»åŠ¨ã€‚
            # å³ Camera.x = -model_offset_xã€‚
            # è€Œ extrinsic[0,3] = -Camera.xï¼Œæ‰€ä»¥ extrinsic[0,3] = -(-model_offset_x) = model_offset_xã€‚
            target_cam_x = model_offset_x

            # ä½¿ç”¨çº¿æ€§æ’å€¼(Lerp)å®ç°å¹³æ»‘ç§»åŠ¨
            current_cam_x = extrinsic[0, 3]
            smoothed_cam_x = current_cam_x + self.camera_x_smoothing * (target_cam_x - current_cam_x)
            
            # æ›´æ–°è§†å›¾çŸ©é˜µçš„Xå¹³ç§»åˆ†é‡
            extrinsic[0, 3] = smoothed_cam_x
            
            # å°†ä¿®æ”¹åçš„å‚æ•°åº”ç”¨å›ç›¸æœº
            cam.extrinsic = extrinsic
            ctr.convert_from_pinhole_camera_parameters(cam, allow_arbitrary=True)

        except Exception as e:
            # åœ¨ä¸»å¾ªç¯ä¸­ï¼Œæˆ‘ä»¬ä¸å¸Œæœ›å› ä¸ºè¿™ä¸ªé”™è¯¯ä¸­æ–­æ¸²æŸ“
            if self.frame_count < 10: # ä»…åœ¨åˆå§‹å‡ å¸§æ‰“å°é”™è¯¯
                print(f"âš ï¸ æ°´å¹³è·Ÿéšç›¸æœºæ—¶å‡ºé”™: {e}")

    def update_face_model(self, detection_result):
        """ğŸ”‘ å…³é”®ï¼šåŸºäº4ä¸ªlandmarksç‚¹çš„å±å¹•ä½ç½®è®¡ç®—æ—‹è½¬ç¼©æ”¾ç§»åŠ¨"""
        if not detection_result.face_landmarks or len(detection_result.face_landmarks) == 0:
            return False
        
        # è·å–ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„äººè„¸çš„468ä¸ªå…³é”®ç‚¹
        landmarks = detection_result.face_landmarks[0]
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å…³é”®ç‚¹
        if len(landmarks) < 468:
            print(f"âš ï¸ å…³é”®ç‚¹æ•°é‡ä¸è¶³: {len(landmarks)}, æœŸæœ›468ä¸ª")
            return False
        
        # ğŸ†• æ–°å¢ï¼šè·å–æ‰€æœ‰468ä¸ªç‚¹çš„åƒç´ åæ ‡ï¼Œç”¨äºè®¡ç®—ç²¾ç¡®çš„é¢éƒ¨ä¸­å¿ƒ
        all_landmarks_px = np.array([self._lm_to_pixel(lm, mirror=False) for lm in landmarks])
        
        # æå–Xåæ ‡å¹¶è®¡ç®—æœ€å·¦å’Œæœ€å³ç‚¹çš„å¹³å‡å€¼
        x_coords = all_landmarks_px[:, 0]
        face_center_x_precise = (np.min(x_coords) + np.max(x_coords)) / 2.0
        
        # ğŸ”‘ æå–4ä¸ªç‰¹å®šå…³é”®ç‚¹ (NormalizedLandmarkç±»å‹)
        forehead = landmarks[self.forehead_index]      # é¢å¤´: 10
        left_cheek = landmarks[self.left_cheek_index]  # å·¦è„¸é¢Š: 234
        chin = landmarks[self.chin_index]              # ä¸‹å·´: 152
        right_cheek = landmarks[self.right_cheek_index] # å³è„¸é¢Š: 454
        
        # ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨åƒç´ åæ ‡æ›¿ä»£å½’ä¸€åŒ–åæ ‡ï¼Œä¸ä½¿ç”¨é•œåƒ
        forehead_px = self._lm_to_pixel(forehead, mirror=False)
        left_px = self._lm_to_pixel(left_cheek, mirror=False)
        chin_px = self._lm_to_pixel(chin, mirror=False)
        right_px = self._lm_to_pixel(right_cheek, mirror=False)
        
        # ä¿ç•™åŸå§‹å½’ä¸€åŒ–åæ ‡ç”¨äºè®¡ç®—æ—‹è½¬è§’åº¦ç­‰
        forehead_point = np.array([forehead.x, forehead.y, forehead.z])
        left_cheek_point = np.array([left_cheek.x, left_cheek.y, left_cheek.z])
        chin_point = np.array([chin.x, chin.y, chin.z])
        right_cheek_point = np.array([right_cheek.x, right_cheek.y, right_cheek.z])
        
        # ğŸ”‘ é‡è¦ï¼šåº”ç”¨Xåæ ‡ä¿®æ­£ï¼ˆå‚è€ƒface_landmarker_cmaera_new.pyï¼‰
        forehead_point[0] *= self.x_scale_factor
        left_cheek_point[0] *= self.x_scale_factor
        chin_point[0] *= self.x_scale_factor
        right_cheek_point[0] *= self.x_scale_factor
        
        # è°ƒè¯•ä¿¡æ¯ï¼ˆå‰å‡ å¸§ï¼‰
        if self.debug_mode and self.frame_count < 3:
            print(f"\n=== å¸§ {self.frame_count} - åŸºäº4ç‚¹å±å¹•ä½ç½®çš„å˜æ¢ ===")
            print(f"æ€»å…³é”®ç‚¹æ•°: {len(landmarks)}")
            print(f"å®½é«˜æ¯”ä¿®æ­£ç³»æ•°: {self.x_scale_factor:.3f}")
            print(f"ä¿®æ­£åå…³é”®ç‚¹:")
            print(f"  é¢å¤´[{self.forehead_index}]: {forehead_point}")
            print(f"  å·¦è„¸é¢Š[{self.left_cheek_index}]: {left_cheek_point}")
            print(f"  ä¸‹å·´[{self.chin_index}]: {chin_point}")
            print(f"  å³è„¸é¢Š[{self.right_cheek_index}]: {right_cheek_point}")
            print(f"åƒç´ åæ ‡:")
            print(f"  é¢å¤´[{self.forehead_index}]: {forehead_px}")
            print(f"  å·¦è„¸é¢Š[{self.left_cheek_index}]: {left_px}")
            print(f"  ä¸‹å·´[{self.chin_index}]: {chin_px}")
            print(f"  å³è„¸é¢Š[{self.right_cheek_index}]: {right_px}")
        
        # ğŸ¯ åŸºäº4ä¸ªlandmarksç‚¹è®¡ç®—å˜æ¢å‚æ•°
        
        # 1. è®¡ç®—é¢éƒ¨å°ºå¯¸å’Œä¸­å¿ƒï¼ˆå½’ä¸€åŒ–åæ ‡ï¼‰
        face_width = abs(right_cheek_point[0] - left_cheek_point[0])
        face_height = abs(chin_point[1] - forehead_point[1])
        face_center_x = (left_cheek_point[0] + right_cheek_point[0]) / 2
        face_center_y = (forehead_point[1] + chin_point[1]) / 2
        face_center_z = (forehead_point[2] + left_cheek_point[2] + chin_point[2] + right_cheek_point[2]) / 4
        
        # ğŸ”§ æ–°å¢ï¼šåŸºäºåƒç´ è®¡ç®—é¢éƒ¨å°ºå¯¸
        face_width_px = np.linalg.norm(right_px[:2] - left_px[:2])   # åƒç´ 
        face_height_px = abs(chin_px[1] - forehead_px[1])             # åƒç´ 
        
        # ğŸ”§ è®¡ç®—é¢éƒ¨ä¸­å¿ƒåƒç´ åæ ‡
        face_center_px = np.array([
            (left_px[0] + right_px[0]) * 0.5,          # X å–å·¦å³è„¸é¢Šä¸­ç‚¹ (ç”¨äºæ—§è®¡ç®—)
            (forehead_px[1] + chin_px[1]) * 0.5,       # Y å–é¢å¤´/ä¸‹å·´ä¸­ç‚¹
            (forehead_px[2] + left_px[2] + chin_px[2] + right_px[2]) / 4  # Zå–å››ç‚¹å¹³å‡
        ], dtype=np.float32)
        
        # 2. ğŸ”‘ æ ¸å¿ƒï¼šåŸºäºlandmarksç‚¹é—´è·è®¡ç®—ç¼©æ”¾
        # ä»æ¨¡å‹ä¸­è·å–å¯¹åº”4ä¸ªç‚¹çš„è·ç¦»ä½œä¸ºå‚è€ƒ
        model_face_width = np.linalg.norm(self.model_right_cheek - self.model_left_cheek)
        model_face_height = np.linalg.norm(self.model_chin - self.model_forehead)
        
        # è®¡ç®—ç¼©æ”¾å› å­ï¼šlandmarksè·ç¦» / æ¨¡å‹è·ç¦»
        # ğŸ”§ é‡æ–°è®¾è®¡ç¼©æ”¾è®¡ç®—ï¼Œè®©ç»“æœæ›´åˆç†
        # landmarksæ˜¯å½’ä¸€åŒ–åæ ‡ï¼Œæ¨¡å‹æ˜¯mmå•ä½ï¼Œéœ€è¦åˆé€‚çš„æ¯”ä¾‹è½¬æ¢
        
        # è®¾ç½®åˆç†çš„ç¼©æ”¾åŸºå‡†ï¼šå‡è®¾æ ‡å‡†äººè„¸åœ¨æ‘„åƒå¤´ä¸­çš„å½’ä¸€åŒ–å°ºå¯¸
        reference_face_width = 0.35    # ğŸ”§ å¢å¤§å‚è€ƒå°ºå¯¸è®©æ¨¡å‹æ›´å°
        reference_face_height = 0.42   # ğŸ”§ å¢å¤§å‚è€ƒå°ºå¯¸è®©æ¨¡å‹æ›´å°
        
        # åŸºäºå®é™…æ£€æµ‹å°ºå¯¸ä¸æ ‡å‡†å°ºå¯¸çš„æ¯”å€¼è®¡ç®—ç¼©æ”¾
        base_scale_x = face_width / reference_face_width
        base_scale_y = face_height / reference_face_height
        
        # ğŸ”§ å¯é€‰ï¼šä½¿ç”¨åƒç´ åæ ‡è®¡ç®—ç¼©æ”¾
        # reference_face_width_px = 430   # æ­£å¸¸è·ç¦»ä¸‹çš„è„¸å®½åƒç´ 
        # reference_face_height_px = 500  # æ­£å¸¸è·ç¦»ä¸‹çš„è„¸é«˜åƒç´ 
        # base_scale_x = face_width_px / reference_face_width_px
        # base_scale_y = face_height_px / reference_face_height_px
        
        # ğŸ”§ æ·»åŠ é¢å¤–çš„ç¼©å°ç³»æ•°
        size_reduction = 0.8  # æ•´ä½“ç¼©å°åˆ°80%
        
        scale_x = base_scale_x * size_reduction
        scale_y = base_scale_y * size_reduction
        scale_z = (scale_x + scale_y) / 2  # Zè½´ä½¿ç”¨å¹³å‡å€¼
        
        # ğŸ”§ é™åˆ¶ç¼©æ”¾èŒƒå›´ï¼Œé¿å…è¿‡åº¦å˜å½¢
        scale_x = np.clip(scale_x, 0.1, 2.0)  
        scale_y = np.clip(scale_y, 0.1, 2.0)  
        scale_z = np.clip(scale_z, 0.1, 2.0)  
        
        # 3. è®¡ç®—æ—‹è½¬è§’åº¦
        # Rollè§’åº¦ï¼šæ ¹æ®å·¦å³è„¸é¢Šè¿çº¿è®¡ç®—å¤´éƒ¨å·¦å³å€¾æ–œ
        cheek_vector = right_cheek_point - left_cheek_point
        roll_angle = -np.arctan2(cheek_vector[1], cheek_vector[0])
        
        # Pitchè§’åº¦ï¼šæ ¹æ®é¢å¤´å’Œä¸‹å·´è¿çº¿è®¡ç®—å¤´éƒ¨ä¸Šä¸‹å€¾æ–œ
        vertical_vector = chin_point - forehead_point
        pitch_angle = np.arctan2(vertical_vector[2], vertical_vector[1])
        
        # ğŸ”§ ä¿®å¤Yawè§’åº¦ï¼šä½¿ç”¨æ›´å‡†ç¡®çš„å¤´éƒ¨æœå‘è®¡ç®—
        # æ–¹æ³•1ï¼šåŸºäºå·¦å³è„¸é¢Šçš„Zæ·±åº¦å·®ï¼Œä½†å¢å¼ºå¹…åº¦
        z_left = left_cheek_point[2]
        z_right = right_cheek_point[2]
        z_diff = z_right - z_left
        
        # æ–¹æ³•2ï¼šç»“åˆXåæ ‡å·®å¼‚æ¥å¢å¼ºYawæ£€æµ‹
        # å½“å¤´å‘å·¦è½¬æ—¶ï¼Œå³è„¸é¢Šä¼šæ¯”å·¦è„¸é¢Šæ›´é è¿‘å±å¹•ä¸­å¿ƒ
        x_center = (left_cheek_point[0] + right_cheek_point[0]) / 2
        x_offset = face_center_x - x_center  # é¢éƒ¨ä¸­å¿ƒç›¸å¯¹äºè„¸é¢Šä¸­å¿ƒçš„åç§»
        
        # ç»¼åˆè®¡ç®—Yawè§’åº¦
        yaw_angle = np.arctan2(z_diff, face_width) * 2.0 + x_offset * 0.5  # ğŸ”§ å¢å¼ºæ•æ„Ÿåº¦
        
        # 4. ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨åƒç´ åæ ‡è®¡ç®—å¹³ç§»é‡ï¼Œä½†è€ƒè™‘å®½é«˜æ¯”ä¿®æ­£
        # ğŸ†• ä½¿ç”¨æˆ‘ä»¬ç²¾ç¡®è®¡ç®—çš„é¢éƒ¨ä¸­å¿ƒXåæ ‡
        face_center_pixel_x = face_center_x_precise
        face_center_pixel_y = face_center_px[1]
        
        # ğŸ”§ å…³é”®ä¿®æ­£ï¼šå¯¹Xåæ ‡åº”ç”¨å®½é«˜æ¯”ä¿®æ­£ï¼Œä½¿å…¶åœ¨æ­£ç¡®çš„æ¯”ä¾‹ä¸‹è®¡ç®—åç§»
        # å°†åƒç´ åæ ‡é‡æ–°å½’ä¸€åŒ–ï¼Œç„¶ååº”ç”¨x_scale_factorä¿®æ­£
        normalized_center_x = face_center_pixel_x / self.render_width * self.x_scale_factor
        normalized_center_y = face_center_pixel_y / self.render_height
        
        # è½¬æ¢å›å±å¹•åæ ‡è¿›è¡Œå¹³ç§»è®¡ç®—
        corrected_screen_x = normalized_center_x * self.render_width / self.x_scale_factor
        corrected_screen_y = normalized_center_y * self.render_height
        
        # ä¸å±å¹•ä¸­å¿ƒçš„å·®å€¼ Ã— ç¼©æ”¾ç³»æ•°
        model_x = (corrected_screen_x - self.render_width * 0.5) * 0.05
        model_y = -(corrected_screen_y - self.render_height * 0.5) * 0.05  # Yè½´ç¿»è½¬ + å‘ä¸Šåç§»1.5ä¸ªå•ä½ + 1.5
        model_z = face_center_px[2] * 30 + 2  # Zè½´é€‚å½“å‰ç§»
        
        # ğŸ†• å…³é”®ï¼šå°†è®¡ç®—å‡ºçš„Xåç§»é‡ç”¨äºç§»åŠ¨ç›¸æœºï¼Œè€Œä¸æ˜¯æ¨¡å‹
        self._follow_face_horizontally(model_x)

        # è°ƒè¯•ä¿¡æ¯
        if self.debug_mode and self.frame_count < 3:
            print(f"æ£€æµ‹åˆ°çš„é¢éƒ¨å°ºå¯¸: å®½åº¦={face_width:.4f}, é«˜åº¦={face_height:.4f}")
            print(f"æ£€æµ‹åˆ°çš„é¢éƒ¨åƒç´ å°ºå¯¸: å®½åº¦={face_width_px:.1f}px, é«˜åº¦={face_height_px:.1f}px")
            print(f"å‚è€ƒé¢éƒ¨å°ºå¯¸: å®½åº¦={reference_face_width:.2f}, é«˜åº¦={reference_face_height:.2f}")
            print(f"åŸºç¡€ç¼©æ”¾: X={base_scale_x:.3f}, Y={base_scale_y:.3f}")
            print(f"ç¼©å°ç³»æ•°: {size_reduction}")
            print(f"æœ€ç»ˆç¼©æ”¾å› å­: X={scale_x:.3f}, Y={scale_y:.3f}, Z={scale_z:.3f}")
            print(f"Yawè®¡ç®—: Zå·®å€¼={z_diff:.4f}, Xåç§»={x_offset:.4f}")
            print(f"æ—‹è½¬è§’åº¦: Roll={np.degrees(roll_angle):.1f}Â°, Pitch={np.degrees(pitch_angle):.1f}Â°, Yaw={np.degrees(yaw_angle):.1f}Â°")
            print(f"å½’ä¸€åŒ–é¢éƒ¨ä¸­å¿ƒ: ({face_center_x:.4f}, {face_center_y:.4f}, {face_center_z:.4f})")
            print(f"åƒç´ é¢éƒ¨ä¸­å¿ƒ: ({face_center_px[0]:.1f}, {face_center_px[1]:.1f})")
            print(f"ç²¾ç¡®åƒç´ é¢éƒ¨Xä¸­å¿ƒ: {face_center_x_precise:.1f}")
            print(f"æ¨¡å‹åæ ‡: (X={model_x:.2f} -> to cam), (Y={model_y:.2f}), (Z={model_z:.2f})")
        
        # 5. æ„å»ºå˜æ¢çŸ©é˜µï¼šå¹³ç§» + æ—‹è½¬ + ç¼©æ”¾ (TRSå˜æ¢)
        
        # ç¼©æ”¾çŸ©é˜µ
        scale_matrix = np.eye(4)
        scale_matrix[0, 0] = scale_x
        scale_matrix[1, 1] = scale_y
        scale_matrix[2, 2] = scale_z
        
        # æ—‹è½¬çŸ©é˜µ - ç»„åˆRollã€Pitchã€Yawæ—‹è½¬
        # Rollæ—‹è½¬ï¼ˆç»•Zè½´ï¼‰
        cos_roll, sin_roll = np.cos(roll_angle), np.sin(roll_angle)
        roll_matrix = np.array([
            [cos_roll, -sin_roll, 0, 0],
            [sin_roll, cos_roll, 0, 0],
            [0, 0, 1, 0],
            [0, 0, 0, 1]
        ])
        
        # Pitchæ—‹è½¬ï¼ˆç»•Xè½´ï¼‰
        cos_pitch, sin_pitch = np.cos(pitch_angle), np.sin(pitch_angle)
        pitch_matrix = np.array([
            [1, 0, 0, 0],
            [0, cos_pitch, -sin_pitch, 0],
            [0, sin_pitch, cos_pitch, 0],
            [0, 0, 0, 1]
        ])
        
        # Yawæ—‹è½¬ï¼ˆç»•Yè½´ï¼‰
        cos_yaw, sin_yaw = np.cos(yaw_angle), np.sin(yaw_angle)
        yaw_matrix = np.array([
            [cos_yaw, 0, sin_yaw, 0],
            [0, 1, 0, 0],
            [-sin_yaw, 0, cos_yaw, 0],
            [0, 0, 0, 1]
        ])
        
        # ç»„åˆæ—‹è½¬çŸ©é˜µï¼šYaw * Pitch * Roll
        rotation_matrix = yaw_matrix @ pitch_matrix @ roll_matrix
        
        # å¹³ç§»çŸ©é˜µ
        translation_matrix = np.eye(4)
        # ğŸ†• å…³é”®ï¼šä¸å†å¯¹æ¨¡å‹è¿›è¡Œæ°´å¹³å¹³ç§»ï¼Œå°†å…¶äº¤ç»™ç›¸æœºå¤„ç†
        translation_matrix[0, 3] = 0.0 # model_x
        translation_matrix[1, 3] = model_y
        translation_matrix[2, 3] = model_z
        
        # æœ€ç»ˆå˜æ¢çŸ©é˜µï¼šT * R * Sï¼ˆä»å³åˆ°å·¦åº”ç”¨ï¼‰
        transform_matrix = translation_matrix @ rotation_matrix @ scale_matrix
        
        # ğŸ†• ä¿å­˜å˜æ¢çŸ©é˜µä¾›å¯¼å‡ºä½¿ç”¨
        self.current_transform_matrix = transform_matrix
        
        if self.debug_mode and self.frame_count < 3:
            # å¢åŠ è°ƒè¯•ä¿¡æ¯
            print(f"ç²¾ç¡®çš„é¢éƒ¨ä¸­å¿ƒXåƒç´ åæ ‡: {face_center_x_precise:.2f}")
            print(f"è®¡ç®—å‡ºçš„æ¨¡å‹Xåç§»(ä¼ é€’ç»™ç›¸æœº): {model_x:.4f}")
            print(f"å˜æ¢çŸ©é˜µ:\n{transform_matrix}")
        
        # åº”ç”¨å˜æ¢åˆ°æ¨¡å‹é¡¶ç‚¹
        vertices = self.original_vertices.copy()
        vertices_homogeneous = np.hstack([vertices, np.ones((len(vertices), 1))])
        transformed_vertices = (transform_matrix @ vertices_homogeneous.T).T[:, :3]
        
        # ğŸ†• ä¿å­˜å˜æ¢åçš„é¡¶ç‚¹ä¾›å¯¼å‡ºä½¿ç”¨
        self.current_transformed_vertices = transformed_vertices
        
        # æ›´æ–°æ¨¡å‹é¡¶ç‚¹
        self.face_mesh.vertices = o3d.utility.Vector3dVector(transformed_vertices)
        
        # æ›´æ–°æ³•çº¿ï¼ˆåªç”¨æ—‹è½¬éƒ¨åˆ†ï¼Œå¿½ç•¥å¹³ç§»ï¼‰
        R = rotation_matrix[:3, :3]  # 3Ã—3 æ—‹è½¬çŸ©é˜µ
        transformed_normals = (R @ self.original_normals.T).T
        self.face_mesh.vertex_normals = o3d.utility.Vector3dVector(transformed_normals)
        
        self.frame_count += 1
        if self.frame_count >= 3:
            self.debug_mode = False
        
        return True
    
    def draw_original_landmarks(self, image, detection_result):
        """ğŸ†• æ–°å¢ï¼šç»˜åˆ¶åŸå§‹landmarksç‚¹å’Œçº¿æ¡†"""
        if not self.show_original_landmarks or not detection_result.face_landmarks:
            return image
        
        try:
            # è·å–MediaPipeé¢éƒ¨ç½‘æ ¼è¿æ¥ä¿¡æ¯
            mp_face_mesh = mp.solutions.face_mesh
            
            for face_landmarks in detection_result.face_landmarks:
                height, width, _ = image.shape
                
                # ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨_lm_to_pixelæ–¹æ³•è·å–åƒç´ åæ ‡
                coords = np.array([self._lm_to_pixel(lm, mirror=False) for lm in face_landmarks[:468]], dtype=np.float32)
                
                # ç»˜åˆ¶landmarksç‚¹ï¼ˆç»¿è‰²å°åœ†ç‚¹ï¼‰
                for i, (x, y, _) in enumerate(coords):
                    x, y = int(x), int(y)
                    # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    if 0 <= x < width and 0 <= y < height:
                        cv2.circle(image, (x, y), 1, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹
                
                # ç»˜åˆ¶é¢éƒ¨ç½‘æ ¼è¿çº¿ï¼ˆç»¿è‰²ç»†çº¿ï¼‰
                if hasattr(mp_face_mesh, 'FACEMESH_TESSELATION'):
                    connections = mp_face_mesh.FACEMESH_TESSELATION
                    for (start_idx, end_idx) in connections:
                        if start_idx < len(coords) and end_idx < len(coords):
                            sx, sy = int(coords[start_idx, 0]), int(coords[start_idx, 1])
                            ex, ey = int(coords[end_idx, 0]), int(coords[end_idx, 1])
                            # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                            if (0 <= sx < width and 0 <= sy < height and 
                                0 <= ex < width and 0 <= ey < height):
                                cv2.line(image, (sx, sy), (ex, ey), (0, 255, 0), 1)  # ç»¿è‰²çº¿
                
                # ğŸ”‘ ç‰¹åˆ«æ ‡è®°4ä¸ªå…³é”®ç‚¹ï¼ˆçº¢è‰²å¤§åœ†ç‚¹ï¼‰
                key_indices = [self.forehead_index, self.left_cheek_index, 
                              self.chin_index, self.right_cheek_index]
                key_labels = ["é¢å¤´", "å·¦è„¸é¢Š", "ä¸‹å·´", "å³è„¸é¢Š"]
                
                for idx, label in zip(key_indices, key_labels):
                    if idx < len(coords):
                        x, y = int(coords[idx, 0]), int(coords[idx, 1])
                        if 0 <= x < width and 0 <= y < height:
                            cv2.circle(image, (x, y), 3, (0, 0, 255), -1)  # çº¢è‰²å¤§ç‚¹
                            cv2.putText(image, f"{idx}", (x+5, y-5), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)
            
            return image
            
        except Exception as e:
            print(f"ç»˜åˆ¶åŸå§‹landmarksé”™è¯¯: {e}")
            return image
    
    def export_realtime_model(self):
        """ğŸ†• æ–°å¢ï¼šå¯¼å‡ºå½“å‰å®æ—¶å˜æ¢åçš„3Dæ¨¡å‹"""
        if not hasattr(self, 'current_transformed_vertices') or self.current_transformed_vertices is None:
            print("âŒ æ²¡æœ‰å¯å¯¼å‡ºçš„å˜æ¢åæ¨¡å‹æ•°æ®")
            return None
        
        try:
            # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
            timestamp = int(time.time())
            filename = f"realtime_face_model_{timestamp}.obj"
            
            # ç¡®ä¿å¯¼å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
            export_dir = "exported_models"
            os.makedirs(export_dir, exist_ok=True)
            filepath = os.path.join(export_dir, filename)
            
            print(f"\n=== å¯¼å‡ºå®æ—¶3Dæ¨¡å‹ ===")
            print(f"æ–‡ä»¶è·¯å¾„: {filepath}")
            print(f"é¡¶ç‚¹æ•°: {len(self.current_transformed_vertices)}")
            
            with open(filepath, 'w', encoding='utf-8') as f:
                # å†™å…¥OBJæ–‡ä»¶å¤´
                f.write("# FaceMatrixLab å®æ—¶3Dé¢å…·æ¨¡å‹\n")
                f.write(f"# å¯¼å‡ºæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# åŸºäºAndy_Wah_facemesh.objï¼Œåº”ç”¨å®æ—¶äººè„¸è·Ÿè¸ªå˜æ¢\n")
                f.write(f"# æ€»é¡¶ç‚¹æ•°: {len(self.current_transformed_vertices)}\n")
                f.write(f"# æ€»é¢æ•°: {len(self.face_mesh.triangles)}\n")
                f.write("\n")
                
                # å†™å…¥å˜æ¢åçš„é¡¶ç‚¹
                for i, vertex in enumerate(self.current_transformed_vertices):
                    f.write(f"v {vertex[0]:.6f} {vertex[1]:.6f} {vertex[2]:.6f}\n")
                
                f.write("\n")
                
                # å†™å…¥é¢ä¿¡æ¯ï¼ˆä¸‰è§’å½¢ï¼‰
                triangles = np.asarray(self.face_mesh.triangles)
                f.write("# é¢å®šä¹‰ (ä¸‰è§’å½¢)\n")
                for i, triangle in enumerate(triangles):
                    # OBJæ–‡ä»¶çš„é¡¶ç‚¹ç´¢å¼•ä»1å¼€å§‹
                    f.write(f"f {triangle[0]+1} {triangle[1]+1} {triangle[2]+1}\n")
                
                # å¦‚æœæœ‰å˜æ¢çŸ©é˜µï¼Œä¹Ÿä¿å­˜ä¸ºæ³¨é‡Š
                if hasattr(self, 'current_transform_matrix'):
                    f.write("\n# å½“å‰å˜æ¢çŸ©é˜µ (TRS)\n")
                    for row in self.current_transform_matrix:
                        f.write(f"# {row[0]:.6f} {row[1]:.6f} {row[2]:.6f} {row[3]:.6f}\n")
            
            # ç»Ÿè®¡æ¨¡å‹ä¿¡æ¯
            vertices = self.current_transformed_vertices
            print(f"å˜æ¢åæ¨¡å‹åæ ‡èŒƒå›´:")
            print(f"  X: [{vertices[:, 0].min():.3f}, {vertices[:, 0].max():.3f}]")
            print(f"  Y: [{vertices[:, 1].min():.3f}, {vertices[:, 1].max():.3f}]")
            print(f"  Z: [{vertices[:, 2].min():.3f}, {vertices[:, 2].max():.3f}]")
            print(f"âœ… å®æ—¶3Dæ¨¡å‹å·²å¯¼å‡º: {filepath}")
            print("ğŸ’¡ å¯ä»¥åœ¨Blenderä¸­å¯¼å…¥æ­¤OBJæ–‡ä»¶æŸ¥çœ‹æ•ˆæœ")
            
            return filepath
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå®æ—¶æ¨¡å‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def run(self):
        """å¯åŠ¨æ¸²æŸ“å™¨"""
        print("\nå¯åŠ¨FaceMatrixLab 3Dé¢å…·æ¸²æŸ“å™¨")
        print("=" * 60)
        print("ğŸ”‘ ä½¿ç”¨MediaPipe faceLandmarks (468ä¸ªNormalizedLandmarkç‚¹)")
        print("ğŸ¯ é‡ç‚¹ä½¿ç”¨4ä¸ªç‰¹å®šç‚¹è¿›è¡ŒARè·Ÿè¸ª:")
        print(f"   é¢å¤´: ç´¢å¼• {self.forehead_index}")
        print(f"   å·¦è„¸é¢Š: ç´¢å¼• {self.left_cheek_index}")
        print(f"   ä¸‹å·´: ç´¢å¼• {self.chin_index}")
        print(f"   å³è„¸é¢Š: ç´¢å¼• {self.right_cheek_index}")
        print("ğŸš€ åŠŸèƒ½ç‰¹æ€§:")
        print("   âœ… åŠ¨æ€ç¼©æ”¾ï¼šæ¨¡å‹å°ºå¯¸è·Ÿéšäººè„¸å¤§å°")
        print("   âœ… å¤´éƒ¨æ—‹è½¬ï¼šRollã€Pitchã€Yawä¸‰è½´æ—‹è½¬")
        print("   âœ… å®Œæ•´å˜æ¢ï¼šå¹³ç§»+æ—‹è½¬+ç¼©æ”¾ (TRS)")
        print("   âœ… 16:9å®½é«˜æ¯”ä¿®æ­£ï¼šæ­£ç¡®å¤„ç†1280x720åˆ†è¾¨ç‡")
        print("   âœ… åŸå§‹landmarksæ˜¾ç¤ºï¼šç»¿è‰²çº¿æ¡†å’Œå…³é”®ç‚¹")
        print("   âœ… çº¹ç†è´´å›¾æ”¯æŒï¼šenhanced_texture.png")
        print("=" * 60)
        print("æ§åˆ¶è¯´æ˜:")
        print("  Bé”®: åˆ‡æ¢æ‘„åƒæœºèƒŒæ™¯æ˜¾ç¤º")
        print("  Cé”®: åˆ‡æ¢é¢å…·é¢œè‰²")
        print("  1-6é”®: ç›´æ¥é€‰æ‹©é¢å…·é¢œè‰²")
        print("  Té”®: åˆ‡æ¢çº¹ç†è´´å›¾/ç»Ÿä¸€é¢œè‰²æ¨¡å¼")
        print("  Lé”®: åˆ‡æ¢åŸå§‹landmarksæ˜¾ç¤º")
        print("  Eé”®: å¯¼å‡ºå½“å‰å®æ—¶3Dæ¨¡å‹ä¸ºOBJæ–‡ä»¶")
        print("  Qé”®: é€€å‡ºç¨‹åº")
        print("=" * 60)
        
        self.is_running = True
        
        # è®¾ç½®å¯è§†åŒ–å™¨
        if not self.setup_visualizer():
            print("âŒ å¯è§†åŒ–å™¨åˆå§‹åŒ–å¤±è´¥")
            return
        
        # å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹
        detection_thread = threading.Thread(target=self.detection_thread, daemon=True)
        detection_thread.start()
        
        # ç­‰å¾…æ£€æµ‹çº¿ç¨‹å¯åŠ¨
        time.sleep(2)
        
        # åˆ›å»ºARåˆæˆçª—å£ - 1280x720
        cv2.namedWindow("AR Face Mask", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("AR Face Mask", self.render_width, self.render_height)
        
        try:
            # ä¸»æ¸²æŸ“å¾ªç¯
            while self.is_running:
                # è¯»å–æœ€æ–°æ•°æ®
                frame = None
                try:
                    pkt = self.data_queue.get_nowait()
                    detection_result = pkt['detection_result']
                    frame = pkt.get('frame')
                    
                    # ä¿å­˜æœ€æ–°å¸§ç”¨äºARåˆæˆ
                    if frame is not None:
                        self.latest_camera_frame = frame.copy()
                    
                    # æ›´æ–°3Dæ¨¡å‹
                    if self.update_face_model(detection_result):
                        self.vis.update_geometry(self.face_mesh)
                except queue.Empty:
                    pass
                
                # ç¦»å±æ¸²æŸ“è·å–3Dæ¨¡å‹å›¾åƒ
                self.vis.poll_events()
                self.vis.update_renderer()
                img_3d = np.asarray(self.vis.capture_screen_float_buffer(False))
                img_3d = (img_3d * 255).astype(np.uint8)
                img_3d_bgr = cv2.cvtColor(img_3d, cv2.COLOR_RGB2BGR)
                
                # ARåˆæˆ: å°†3Dæ¨¡å‹å åŠ åˆ°æ‘„åƒæœºèƒŒæ™¯ä¸Š
                if self.show_camera_background and self.latest_camera_frame is not None:
                    # å‡†å¤‡èƒŒæ™¯å›¾åƒ
                    bg = cv2.cvtColor(self.latest_camera_frame, cv2.COLOR_RGB2BGR)
                    bg = cv2.resize(bg, (self.render_width, self.render_height))
                    
                    # ğŸ†• æ–°å¢ï¼šåœ¨èƒŒæ™¯ä¸Šç»˜åˆ¶åŸå§‹landmarks
                    if hasattr(self, 'latest_detection_result'):
                        bg = self.draw_original_landmarks(bg, self.latest_detection_result)
                    
                    # åˆ›å»ºæ©ç : éé»‘è‰²åƒç´ çš„åŒºåŸŸä¸º3Dæ¨¡å‹
                    mask = img_3d_bgr.sum(axis=2) > 30
                    
                    # åˆæˆå›¾åƒ: èƒŒæ™¯ + 3Dæ¨¡å‹
                    composite = bg.copy()
                    composite[mask] = img_3d_bgr[mask]
                    
                    # æ·»åŠ ä¿¡æ¯æ˜¾ç¤º
                    fps_text = f"FPS: {self.current_fps:.1f}"
                    mask_text = f"é¢å…·é¢œè‰²: {self.current_color_index+1}/{len(self.mask_colors)}"
                    landmarks_text = "faceLandmarks: 468ç‚¹è·Ÿè¸ª"
                    ratio_text = f"å®½é«˜æ¯”: {self.aspect_ratio:.3f} (16:9ä¿®æ­£)"
                    cv2.putText(composite, fps_text, (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    cv2.putText(composite, mask_text, (10, 70), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    cv2.putText(composite, landmarks_text, (10, 110), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    cv2.putText(composite, ratio_text, (10, 150), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
                    
                    # æ˜¾ç¤ºåŸå§‹landmarksçŠ¶æ€
                    landmarks_status = f"åŸå§‹landmarks: {'æ˜¾ç¤º' if self.show_original_landmarks else 'éšè—'} (Lé”®åˆ‡æ¢)"
                    cv2.putText(composite, landmarks_status, (10, 190), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                    
                    # ğŸ†• æ˜¾ç¤ºçº¹ç†çŠ¶æ€
                    if hasattr(self, 'has_texture') and self.has_texture:
                        texture_status = f"æ¸²æŸ“æ¨¡å¼: {'çº¹ç†è´´å›¾' if self.texture_mode else 'ç»Ÿä¸€é¢œè‰²'} (Té”®åˆ‡æ¢)"
                        cv2.putText(composite, texture_status, (10, 230), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                    
                    # æ˜¾ç¤ºARåˆæˆç»“æœ
                    cv2.imshow("AR Face Mask", composite)
                else:
                    # åªæ˜¾ç¤º3Dæ¨¡å‹
                    cv2.imshow("AR Face Mask", img_3d_bgr)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('b'):
                    self.show_camera_background = not self.show_camera_background
                    print(f"èƒŒæ™¯æ˜¾ç¤º: {'å¼€å¯' if self.show_camera_background else 'å…³é—­'}")
                elif key == ord('c'):
                    # å¾ªç¯åˆ‡æ¢ä¸‹ä¸€ä¸ªé¢å…·é¢œè‰²
                    next_color = (self.current_color_index + 1) % len(self.mask_colors)
                    self.change_mask_color(next_color)
                elif key >= ord('1') and key <= ord('6'):
                    # ç›´æ¥é€‰æ‹©é¢å…·é¢œè‰² (1-6)
                    color_idx = key - ord('1')
                    if color_idx < len(self.mask_colors):
                        self.change_mask_color(color_idx)
                elif key == ord('l'):
                    # ğŸ†• æ–°å¢ï¼šåˆ‡æ¢åŸå§‹landmarksæ˜¾ç¤º
                    self.show_original_landmarks = not self.show_original_landmarks
                    print(f"åŸå§‹landmarksæ˜¾ç¤º: {'å¼€å¯' if self.show_original_landmarks else 'å…³é—­'}")
                elif key == ord('t'):
                    # ğŸ†• æ–°å¢ï¼šåˆ‡æ¢çº¹ç†/é¢œè‰²æ¨¡å¼
                    self.toggle_texture_mode()
                elif key == ord('e'):
                    # ğŸ†• æ–°å¢ï¼šå¯¼å‡ºå½“å‰å®æ—¶3Dæ¨¡å‹
                    exported_file = self.export_realtime_model()
                    if exported_file:
                        print(f"ğŸ‰ å®æ—¶3Dæ¨¡å‹å·²å¯¼å‡ºï¼Œå¯åœ¨Blenderä¸­æŸ¥çœ‹: {exported_file}")
                    else:
                        print("âŒ å¯¼å‡ºå¤±è´¥ï¼Œè¯·ç¡®ä¿æœ‰æ£€æµ‹åˆ°çš„äººè„¸")
                elif key == ord('q'):
                    break
                
                # ä¿å­˜æœ€æ–°çš„æ£€æµ‹ç»“æœç”¨äºlandmarksç»˜åˆ¶
                if 'detection_result' in locals():
                    self.latest_detection_result = detection_result
                
                # æ§åˆ¶å¸§ç‡
                time.sleep(1.0 / self.fps_target)
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹ æ¸…ç†èµ„æº...")
        self.is_running = False
        self.vis.destroy_window()
        cv2.destroyAllWindows()
        print("âœ… èµ„æºæ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    print("FaceMatrixLab 3D é¢å…·æ¸²æŸ“å™¨")
    print("ä½¿ç”¨MediaPipe faceLandmarks (468ä¸ªNormalizedLandmarkç‚¹) å®ç°ç²¾ç¡®è·Ÿè¸ª")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = "obj/Andy_Wah_facemesh.obj"
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {model_path}")
        print("è¯·ç¡®ä¿Andy_Wah_facemesh.objæ–‡ä»¶ä½äº obj/ ç›®å½•ä¸­")
        return
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œæ¸²æŸ“å™¨
        renderer = FaceMaskRenderer(camera_id=0, model_path=model_path)
        renderer.run()
        
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print("ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main() 