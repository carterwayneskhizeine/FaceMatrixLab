#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FaceMatrixLab 3D é¢å…·æ¸²æŸ“å™¨
ä½¿ç”¨ MediaPipe çš„ faceLandmarks (468ä¸ªNormalizedLandmarkç‚¹) æ¥æŒ‚è½½å¹¶æ¸²æŸ“ Andy_Wah_facemesh.obj æ¨¡å‹
é‡ç‚¹ä½¿ç”¨é¢å¤´ã€å·¦è„¸é¢Šã€ä¸‹å·´ã€å³è„¸é¢Šè¿™4ä¸ªç‰¹å®šç‚¹å®ç°ARè·Ÿè¸ªæ•ˆæœ
ğŸ†• æ–°å¢ï¼šåŸºäº BlendShapes çš„è¡¨æƒ…é©±åŠ¨ç³»ç»Ÿ
"""

import cv2
import mediapipe as mp
import numpy as np
import time
import os
import threading
import queue
import open3d as o3d

# MediaPipe å¯¼å…¥
BaseOptions = mp.tasks.BaseOptions
FaceLandmarker = mp.tasks.vision.FaceLandmarker
FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
FaceLandmarkerResult = mp.tasks.vision.FaceLandmarkerResult
VisionRunningMode = mp.tasks.vision.RunningMode

class FaceMaskRenderer:
    def __init__(self, camera_id=0, model_path="obj/Andy_Wah_facemesh.obj"):
        """åˆå§‹åŒ–3Dé¢å…·æ¸²æŸ“å™¨"""
        print("=== FaceMatrixLab 3D é¢å…·æ¸²æŸ“å™¨åˆå§‹åŒ– ===")
        
        # åŸºæœ¬å‚æ•°
        self.camera_id = camera_id
        self.model_path = model_path
        self.is_running = False
        
        # æ¸²æŸ“å‚æ•°
        self.render_width = 1280
        self.render_height = 720
        self.fps_target = 30
        
        # ğŸ”‘ é‡è¦ï¼šæ·»åŠ å®½é«˜æ¯”å¤„ç†ï¼ˆå‚è€ƒface_landmarker_cmaera_new.pyï¼‰
        self.camera_width = 1280   # æ‘„åƒå¤´åˆ†è¾¨ç‡
        self.camera_height = 720   # æ‘„åƒå¤´åˆ†è¾¨ç‡  
        self.aspect_ratio = self.camera_width / self.camera_height
        self.x_scale_factor = self.aspect_ratio / 1.0  # å¯¹äº16:9ï¼Œçº¦ä¸º1.777
        
        # MediaPipe ç›¸å…³
        self.landmarker = None
        self.mp_model_path = self.download_mediapipe_model()
        
        # ğŸ”‘ å…³é”®ï¼šä½¿ç”¨468ä¸ªfaceLandmarksä¸­çš„4ä¸ªç‰¹å®šç‚¹
        self.forehead_index = 10    # é¢å¤´
        self.left_cheek_index = 234  # å·¦è„¸é¢Š
        self.chin_index = 152        # ä¸‹å·´
        self.right_cheek_index = 454  # å³è„¸é¢Š
        
        # æ•°æ®é˜Ÿåˆ— - ç”¨äºçº¿ç¨‹é—´é€šä¿¡
        self.data_queue = queue.Queue(maxsize=5)
        
        # ARæ¸²æŸ“ç›¸å…³
        self.show_camera_background = True  # é»˜è®¤æ˜¾ç¤ºæ‘„åƒæœºèƒŒæ™¯
        self.latest_camera_frame = None     # ä¿å­˜æœ€æ–°çš„æ‘„åƒæœºå¸§
        
        # é¢å…·è®¾ç½®
        self.current_mask_color = [0.8, 0.7, 0.6]  # é»˜è®¤è‚¤è‰²
        self.mask_colors = [
            [0.8, 0.7, 0.6],  # è‚¤è‰²
            [0.9, 0.1, 0.1],  # çº¢è‰²
            [0.1, 0.8, 0.2],  # ç»¿è‰²
            [0.2, 0.2, 0.9],  # è“è‰²
            [0.9, 0.7, 0.1],  # é‡‘è‰²
            [0.7, 0.3, 0.9],  # ç´«è‰²
        ]
        self.current_color_index = 0
        
        # è°ƒè¯•å’Œè·Ÿè¸ª
        self.debug_mode = True
        self.frame_count = 0
        
        # ğŸ†• æ–°å¢ï¼šåŸå§‹landmarksæ˜¾ç¤ºæ§åˆ¶
        self.show_original_landmarks = True  # æ˜¾ç¤ºåŸå§‹landmarksç‚¹å’Œçº¿æ¡†
        
        # ğŸ†• æ–°å¢ï¼šè¡¨æƒ…é©±åŠ¨ç³»ç»Ÿ
        self.enable_expression_drive = True  # å¯ç”¨è¡¨æƒ…é©±åŠ¨
        self.show_blendshapes_debug = False  # æ˜¾ç¤ºBlendShapesè°ƒè¯•ä¿¡æ¯
        self.expression_strength = 1.0       # è¡¨æƒ…å¼ºåº¦ç³»æ•°
        
        # ğŸ†• æ–°å¢ï¼šçº¹ç†è´´å›¾æ§åˆ¶
        self.texture_mode = True             # ä¼˜å…ˆä½¿ç”¨çº¹ç†è´´å›¾
        self.has_texture = False             # æ˜¯å¦æˆåŠŸåŠ è½½çº¹ç†
        
        # è¡¨æƒ…é©±åŠ¨ç›¸å…³çš„é¡¶ç‚¹ç»„ï¼ˆéœ€è¦æ ¹æ®å…·ä½“æ¨¡å‹è°ƒæ•´ï¼‰
        self.setup_expression_vertex_groups()
        
        # åŠ è½½3Dæ¨¡å‹
        if not self.load_face_model():
            raise Exception("æ— æ³•åŠ è½½3Dæ¨¡å‹æ–‡ä»¶")
        
        # ğŸ†• å…³é”®ï¼šæå–æ¨¡å‹ä¸­4ä¸ªå…³é”®é¡¶ç‚¹çš„åæ ‡
        self.extract_model_key_points()
        
        # ğŸ†• è‡ªåŠ¨æ£€æµ‹è¡¨æƒ…é¡¶ç‚¹ç»„
        self.auto_detect_expression_vertex_groups()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.current_fps = 0
        
        print("âœ… FaceMatrixLab 3D é¢å…·æ¸²æŸ“å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ å®½é«˜æ¯”è®¾ç½®: {self.aspect_ratio:.3f} (16:9)")
        print(f"ğŸ“ Xåæ ‡ä¿®æ­£ç³»æ•°: {self.x_scale_factor:.3f}")
        print(f"ğŸ­ è¡¨æƒ…é©±åŠ¨: {'å¯ç”¨' if self.enable_expression_drive else 'ç¦ç”¨'}")
    
    def setup_expression_vertex_groups(self):
        """ğŸ†• è®¾ç½®è¡¨æƒ…é©±åŠ¨çš„é¡¶ç‚¹ç»„"""
        print("ğŸ­ è®¾ç½®è¡¨æƒ…é©±åŠ¨é¡¶ç‚¹ç»„...")
        
        # è¿™é‡Œéœ€è¦æ ¹æ®ä½ çš„å…·ä½“æ¨¡å‹æ–‡ä»¶æ¥å®šä¹‰å“ªäº›é¡¶ç‚¹å±äºå˜´å·´ã€çœ¼ç›ç­‰éƒ¨ä½
        # ä»¥ä¸‹æ˜¯ç¤ºä¾‹ç´¢å¼•ï¼Œä½ éœ€è¦æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´
        
        # å˜´å·´ç›¸å…³é¡¶ç‚¹ï¼ˆç¤ºä¾‹ï¼‰
        self.mouth_vertex_indices = list(range(100, 150))  # éœ€è¦æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´
        
        # å·¦çœ¼ç›¸å…³é¡¶ç‚¹ï¼ˆç¤ºä¾‹ï¼‰
        self.left_eye_vertex_indices = list(range(200, 230))  # éœ€è¦æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´
        
        # å³çœ¼ç›¸å…³é¡¶ç‚¹ï¼ˆç¤ºä¾‹ï¼‰
        self.right_eye_vertex_indices = list(range(250, 280))  # éœ€è¦æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´
        
        # çœ‰æ¯›ç›¸å…³é¡¶ç‚¹ï¼ˆç¤ºä¾‹ï¼‰
        self.eyebrow_vertex_indices = list(range(300, 350))  # éœ€è¦æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´
        
        print(f"   å˜´å·´é¡¶ç‚¹: {len(self.mouth_vertex_indices)} ä¸ª")
        print(f"   å·¦çœ¼é¡¶ç‚¹: {len(self.left_eye_vertex_indices)} ä¸ª")
        print(f"   å³çœ¼é¡¶ç‚¹: {len(self.right_eye_vertex_indices)} ä¸ª")
        print(f"   çœ‰æ¯›é¡¶ç‚¹: {len(self.eyebrow_vertex_indices)} ä¸ª")
        
        # ğŸ’¡ è‡ªåŠ¨æ£€æµ‹é¡¶ç‚¹ç»„çš„æ–¹æ³•ï¼ˆåŸºäºæ¨¡å‹å‡ ä½•åˆ†æï¼‰
        # è¿™ä¸ªæ–¹æ³•ä¼šåœ¨load_face_model()ä¹‹åè°ƒç”¨
        
    def auto_detect_expression_vertex_groups(self):
        """ğŸ†• è‡ªåŠ¨æ£€æµ‹è¡¨æƒ…ç›¸å…³çš„é¡¶ç‚¹ç»„ï¼ˆåŸºäºå‡ ä½•ä½ç½®ï¼‰"""
        if not hasattr(self, 'original_vertices'):
            return
            
        vertices = self.original_vertices
        print("ğŸ” è‡ªåŠ¨æ£€æµ‹è¡¨æƒ…é¡¶ç‚¹ç»„...")
        
        # è®¡ç®—æ¨¡å‹çš„è¾¹ç•Œæ¡†
        min_bounds = vertices.min(axis=0)
        max_bounds = vertices.max(axis=0)
        center = (min_bounds + max_bounds) / 2
        
        # åŸºäºç›¸å¯¹ä½ç½®è‡ªåŠ¨åˆ†ç»„
        mouth_candidates = []
        left_eye_candidates = []
        right_eye_candidates = []
        eyebrow_candidates = []
        
        for i, vertex in enumerate(vertices):
            # ç›¸å¯¹äºä¸­å¿ƒçš„ä½ç½®
            rel_pos = vertex - center
            
            # å˜´å·´åŒºåŸŸï¼šä¸‹åŠéƒ¨åˆ†ï¼Œä¸­å¤®åŒºåŸŸ
            if (rel_pos[1] < -10 and  # Yè½´è´Ÿæ–¹å‘ï¼ˆä¸‹æ–¹ï¼‰
                abs(rel_pos[0]) < 30 and  # Xè½´ä¸­å¤®
                rel_pos[2] > -5):  # Zè½´å‰æ–¹
                mouth_candidates.append(i)
            
            # å·¦çœ¼åŒºåŸŸï¼šä¸Šæ–¹åå·¦
            elif (rel_pos[1] > 5 and  # Yè½´æ­£æ–¹å‘ï¼ˆä¸Šæ–¹ï¼‰
                  rel_pos[0] < -15 and  # Xè½´è´Ÿæ–¹å‘ï¼ˆå·¦ä¾§ï¼‰
                  rel_pos[2] > -10):
                left_eye_candidates.append(i)
            
            # å³çœ¼åŒºåŸŸï¼šä¸Šæ–¹åå³  
            elif (rel_pos[1] > 5 and  # Yè½´æ­£æ–¹å‘ï¼ˆä¸Šæ–¹ï¼‰
                  rel_pos[0] > 15 and  # Xè½´æ­£æ–¹å‘ï¼ˆå³ä¾§ï¼‰
                  rel_pos[2] > -10):
                right_eye_candidates.append(i)
            
            # çœ‰æ¯›åŒºåŸŸï¼šæ›´ä¸Šæ–¹
            elif (rel_pos[1] > 20 and  # Yè½´æ›´é«˜
                  abs(rel_pos[0]) < 40 and
                  rel_pos[2] > -15):
                eyebrow_candidates.append(i)
        
        # æ›´æ–°é¡¶ç‚¹ç»„
        if mouth_candidates:
            self.mouth_vertex_indices = mouth_candidates
        if left_eye_candidates:
            self.left_eye_vertex_indices = left_eye_candidates
        if right_eye_candidates:
            self.right_eye_vertex_indices = right_eye_candidates
        if eyebrow_candidates:
            self.eyebrow_vertex_indices = eyebrow_candidates
        
        print(f"âœ… è‡ªåŠ¨æ£€æµ‹å®Œæˆ:")
        print(f"   å˜´å·´é¡¶ç‚¹: {len(self.mouth_vertex_indices)} ä¸ª")
        print(f"   å·¦çœ¼é¡¶ç‚¹: {len(self.left_eye_vertex_indices)} ä¸ª")
        print(f"   å³çœ¼é¡¶ç‚¹: {len(self.right_eye_vertex_indices)} ä¸ª")
        print(f"   çœ‰æ¯›é¡¶ç‚¹: {len(self.eyebrow_vertex_indices)} ä¸ª")
    
    def download_mediapipe_model(self):
        """ä¸‹è½½MediaPipeäººè„¸æ ‡å¿—æ£€æµ‹æ¨¡å‹"""
        model_url = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
        model_path = "face_landmarker.task"
        
        if not os.path.exists(model_path):
            print("æ­£åœ¨ä¸‹è½½MediaPipeæ¨¡å‹...")
            try:
                import urllib.request
                urllib.request.urlretrieve(model_url, model_path)
                print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_path}")
            except Exception as e:
                print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
                return None
        else:
            print(f"âœ… MediaPipeæ¨¡å‹å·²å­˜åœ¨: {model_path}")
        
        return model_path
    
    def load_face_model(self):
        """åŠ è½½3Däººè„¸æ¨¡å‹"""
        if not os.path.exists(self.model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            return False
            
        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½3Dæ¨¡å‹: {self.model_path}")
        
        try:
            # åŠ è½½æ¨¡å‹ï¼ˆå¯ç”¨åå¤„ç†ä»¥è¯»å–æè´¨ä¿¡æ¯ï¼‰
            self.face_mesh = o3d.io.read_triangle_mesh(self.model_path, enable_post_processing=True)
            
            if len(self.face_mesh.vertices) == 0:
                print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼šæ²¡æœ‰é¡¶ç‚¹æ•°æ®")
                return False
            
            # è®¡ç®—æ³•çº¿
            self.face_mesh.compute_vertex_normals()
            
            # è·å–é¡¶ç‚¹ä¿¡æ¯
            vertices = np.asarray(self.face_mesh.vertices)
            self.num_vertices = len(vertices)
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ:")
            print(f"   é¡¶ç‚¹æ•°: {self.num_vertices}")
            print(f"   é¢æ•°: {len(self.face_mesh.triangles)}")
            print(f"   åæ ‡èŒƒå›´:")
            print(f"     X: [{vertices[:, 0].min():.2f}, {vertices[:, 0].max():.2f}] mm")
            print(f"     Y: [{vertices[:, 1].min():.2f}, {vertices[:, 1].max():.2f}] mm") 
            print(f"     Z: [{vertices[:, 2].min():.2f}, {vertices[:, 2].max():.2f}] mm")
            
            # ğŸ†• æ–°å¢ï¼šå°è¯•åŠ è½½çº¹ç†è´´å›¾
            texture_path = "obj/enhanced_texture.png"
            if os.path.exists(texture_path):
                try:
                    print(f"ğŸ¨ æ­£åœ¨åŠ è½½çº¹ç†è´´å›¾: {texture_path}")
                    tex_img = o3d.io.read_image(texture_path)
                    
                    # ğŸ”§ ä¿®å¤UVåæ ‡é—®é¢˜ï¼šä¸Šä¸‹ç¿»è½¬çº¹ç†
                    print("ğŸ”„ ä¿®æ­£çº¹ç†æ–¹å‘ï¼ˆä¸Šä¸‹ç¿»è½¬ï¼‰...")
                    img_array = np.asarray(tex_img)
                    
                    # ä¸Šä¸‹ç¿»è½¬å›¾åƒæ•°ç»„
                    flipped_array = np.flipud(img_array)
                    
                    # è½¬æ¢å›Open3Då›¾åƒæ ¼å¼
                    flipped_tex_img = o3d.geometry.Image(flipped_array)
                    self.face_mesh.textures = [flipped_tex_img]
                    
                    # å¦‚æœæ¨¡å‹æ²¡æœ‰æè´¨IDï¼Œè®¾ç½®æ‰€æœ‰é¢éƒ½ä½¿ç”¨çº¹ç†ç´¢å¼•0
                    if len(self.face_mesh.triangle_material_ids) == 0:
                        self.face_mesh.triangle_material_ids = o3d.utility.IntVector([0] * len(self.face_mesh.triangles))
                    
                    print(f"âœ… çº¹ç†è´´å›¾åŠ è½½æˆåŠŸ")
                    # è·å–å›¾åƒå°ºå¯¸ï¼ˆOpen3Dæ–¹å¼ï¼‰
                    height, width = img_array.shape[:2]
                    print(f"   çº¹ç†å°ºå¯¸: {width} x {height}")
                    print(f"   å·²ä¿®æ­£UVåæ ‡æ–¹å‘")
                    self.has_texture = True
                    
                except Exception as e:
                    print(f"âš ï¸ çº¹ç†åŠ è½½å¤±è´¥: {e}")
                    self.has_texture = False
            else:
                print(f"âš ï¸ çº¹ç†æ–‡ä»¶ä¸å­˜åœ¨: {texture_path}")
                self.has_texture = False
            
            # ğŸ”§ ä¿®æ”¹ï¼šåªæœ‰å½“æ²¡æœ‰çº¹ç†æ—¶æ‰ä½¿ç”¨ç»Ÿä¸€é¢œè‰²
            if not hasattr(self, 'has_texture') or not self.has_texture:
                print("ğŸ¨ ä½¿ç”¨ç»Ÿä¸€é¢œè‰²æ¸²æŸ“")
                self.change_mask_color(self.current_color_index)
            else:
                print("ğŸ¨ ä½¿ç”¨çº¹ç†è´´å›¾æ¸²æŸ“")
            
            # å¤‡ä»½åŸå§‹é¡¶ç‚¹
            self.original_vertices = np.asarray(self.face_mesh.vertices).copy()
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def change_mask_color(self, color_index):
        """æ›´æ”¹é¢å…·é¢œè‰²"""
        if 0 <= color_index < len(self.mask_colors):
            self.current_color_index = color_index
            self.current_mask_color = self.mask_colors[color_index]
            
            # ğŸ”§ ä¿®æ”¹ï¼šåªæœ‰åœ¨æ²¡æœ‰çº¹ç†æ—¶æ‰åº”ç”¨ç»Ÿä¸€é¢œè‰²
            if not hasattr(self, 'has_texture') or not self.has_texture:
                self.face_mesh.paint_uniform_color(self.current_mask_color)
                print(f"ğŸ­ é¢å…·é¢œè‰²å·²æ›´æ”¹ä¸ºç´¢å¼• {color_index}")
            else:
                print(f"ğŸ¨ å½“å‰ä½¿ç”¨çº¹ç†è´´å›¾ï¼Œé¢œè‰²åˆ‡æ¢å·²ç¦ç”¨")
            return True
        return False
    
    def toggle_texture_mode(self):
        """ğŸ†• åˆ‡æ¢çº¹ç†/é¢œè‰²æ¨¡å¼"""
        if self.has_texture:
            self.texture_mode = not self.texture_mode
            
            if self.texture_mode:
                print("ğŸ¨ åˆ‡æ¢åˆ°çº¹ç†è´´å›¾æ¨¡å¼")
                # æ¸…é™¤é¡¶ç‚¹é¢œè‰²ï¼Œæ¢å¤çº¹ç†
                self.face_mesh.vertex_colors = o3d.utility.Vector3dVector([])
            else:
                print("ğŸ¨ åˆ‡æ¢åˆ°ç»Ÿä¸€é¢œè‰²æ¨¡å¼")
                # åº”ç”¨ç»Ÿä¸€é¢œè‰²
                self.face_mesh.paint_uniform_color(self.current_mask_color)
        else:
            print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„çº¹ç†è´´å›¾ï¼Œæ— æ³•åˆ‡æ¢")
    
    def setup_visualizer(self):
        """è®¾ç½®Open3Då¯è§†åŒ–å™¨"""
        print("ğŸ¨ åˆå§‹åŒ–Open3Då¯è§†åŒ–å™¨...")
        # åˆ›å»ºå¯è§†åŒ–å™¨çª—å£ï¼ˆç¦»å±æ¸²æŸ“ï¼‰
        self.vis = o3d.visualization.Visualizer()
        self.vis.create_window("FaceMask Renderer", self.render_width, self.render_height, visible=False)
        
        # æ·»åŠ äººè„¸æ¨¡å‹
        self.vis.add_geometry(self.face_mesh)
        
        # è®¾ç½®æ¸²æŸ“é€‰é¡¹
        render_option = self.vis.get_render_option()
        render_option.mesh_show_back_face = True
        render_option.background_color = np.array([0.0, 0.0, 0.0])  # é»‘è‰²èƒŒæ™¯ä¾¿äºåˆæˆ
        
        # è®¾ç½®ç›¸æœºè§†è§’
        ctr = self.vis.get_view_control()
        ctr.set_zoom(1.0)
        
        print("âœ… Open3Då¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        return True
    
    def create_mediapipe_landmarker(self):
        """åˆ›å»ºMediaPipeäººè„¸æ ‡å¿—æ£€æµ‹å™¨"""
        if not self.mp_model_path:
            return None
            
        try:
            options = FaceLandmarkerOptions(
                base_options=BaseOptions(model_asset_path=self.mp_model_path),
                running_mode=VisionRunningMode.VIDEO,
                num_faces=1,
                min_face_detection_confidence=0.5,
                min_face_presence_confidence=0.5,
                min_tracking_confidence=0.5,
                output_face_blendshapes=True,  # ğŸ”‘ å…³é”®ï¼šå¯ç”¨BlendShapesè¾“å‡º
                output_facial_transformation_matrixes=False,  # ğŸ”‘ å…³é”®ï¼šä¸ä½¿ç”¨transformation_matrix
            )
            
            landmarker = FaceLandmarker.create_from_options(options)
            print("âœ… MediaPipeäººè„¸æ£€æµ‹å™¨åˆ›å»ºæˆåŠŸ")
            print("ğŸ­ BlendShapesè¾“å‡ºå·²å¯ç”¨")
            return landmarker
            
        except Exception as e:
            print(f"âŒ MediaPipeæ£€æµ‹å™¨åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def detection_thread(self):
        """MediaPipeæ£€æµ‹çº¿ç¨‹"""
        print("ğŸ¥ å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹...")
        
        # åˆ›å»ºæ£€æµ‹å™¨
        self.landmarker = self.create_mediapipe_landmarker()
        if not self.landmarker:
            print("âŒ MediaPipeæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥")
            return
        
        # æ‰“å¼€æ‘„åƒå¤´
        cap = cv2.VideoCapture(self.camera_id)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_id}")
            return
        
        # è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨ç‡
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        frame_count = 0
        fps_start_time = time.time()
        
        try:
            while self.is_running:
                ret, frame = cap.read()
                if not ret:
                    continue
                
                frame = cv2.flip(frame, 1)  # é•œåƒç¿»è½¬
                frame_count += 1
                
                # è½¬æ¢ä¸ºRGB
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
                
                # è¿›è¡Œäººè„¸æ£€æµ‹
                timestamp_ms = int(time.time() * 1000)
                detection_result = self.landmarker.detect_for_video(mp_image, timestamp_ms)
                
                # å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
                try:
                    data_packet = {
                        'detection_result': detection_result,
                        'frame': rgb_frame,
                        'timestamp': timestamp_ms
                    }
                    self.data_queue.put_nowait(data_packet)
                except queue.Full:
                    # å¦‚æœé˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒæœ€æ—§çš„æ•°æ®
                    try:
                        self.data_queue.get_nowait()
                        self.data_queue.put_nowait(data_packet)
                    except queue.Empty:
                        pass
                
                # è®¡ç®—æ£€æµ‹FPS
                if frame_count % 30 == 0:
                    elapsed = time.time() - fps_start_time
                    self.current_fps = 30.0 / elapsed
                    fps_start_time = time.time()
                
                # æ§åˆ¶å¸§ç‡
                time.sleep(1.0 / self.fps_target)
                
        except Exception as e:
            print(f"âŒ æ£€æµ‹çº¿ç¨‹é”™è¯¯: {e}")
        finally:
            cap.release()
            print("ğŸ¥ MediaPipeæ£€æµ‹çº¿ç¨‹å·²åœæ­¢")
    
    def extract_model_key_points(self):
        """ğŸ†• æå–æ¨¡å‹ä¸­4ä¸ªå…³é”®é¡¶ç‚¹çš„3Dåæ ‡"""
        try:
            # è·å–æ¨¡å‹é¡¶ç‚¹
            vertices = np.asarray(self.face_mesh.vertices)
            
            # æå–4ä¸ªå…³é”®ç‚¹ï¼ˆindexä¸landmarksä¸€è‡´ï¼‰
            self.model_forehead = vertices[self.forehead_index].copy()      # é¢å¤´: 10
            self.model_left_cheek = vertices[self.left_cheek_index].copy()  # å·¦è„¸é¢Š: 234
            self.model_chin = vertices[self.chin_index].copy()              # ä¸‹å·´: 152
            self.model_right_cheek = vertices[self.right_cheek_index].copy() # å³è„¸é¢Š: 454
            
            print(f"ğŸ¯ æ¨¡å‹å…³é”®ç‚¹æå–æˆåŠŸ:")
            print(f"   é¢å¤´[{self.forehead_index}]: {self.model_forehead}")
            print(f"   å·¦è„¸é¢Š[{self.left_cheek_index}]: {self.model_left_cheek}")
            print(f"   ä¸‹å·´[{self.chin_index}]: {self.model_chin}")
            print(f"   å³è„¸é¢Š[{self.right_cheek_index}]: {self.model_right_cheek}")
            
            # è®¡ç®—æ¨¡å‹çš„å°ºå¯¸ä¿¡æ¯
            model_width = np.linalg.norm(self.model_right_cheek - self.model_left_cheek)
            model_height = np.linalg.norm(self.model_chin - self.model_forehead)
            print(f"   æ¨¡å‹é¢éƒ¨å°ºå¯¸: å®½åº¦={model_width:.2f}mm, é«˜åº¦={model_height:.2f}mm")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹å…³é”®ç‚¹æå–å¤±è´¥: {e}")
            return False
    
    def update_face_model(self, detection_result):
        """ğŸ”‘ å…³é”®ï¼šåŸºäº4ä¸ªlandmarksç‚¹çš„å±å¹•ä½ç½®è®¡ç®—æ—‹è½¬ç¼©æ”¾ç§»åŠ¨"""
        if not detection_result.face_landmarks or len(detection_result.face_landmarks) == 0:
            return False
        
        # è·å–ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„äººè„¸çš„468ä¸ªå…³é”®ç‚¹
        landmarks = detection_result.face_landmarks[0]
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å…³é”®ç‚¹
        if len(landmarks) < 468:
            print(f"âš ï¸ å…³é”®ç‚¹æ•°é‡ä¸è¶³: {len(landmarks)}, æœŸæœ›468ä¸ª")
            return False
        
        # ğŸ”‘ æå–4ä¸ªç‰¹å®šå…³é”®ç‚¹ (NormalizedLandmarkç±»å‹)
        forehead = landmarks[self.forehead_index]      # é¢å¤´: 10
        left_cheek = landmarks[self.left_cheek_index]  # å·¦è„¸é¢Š: 234  
        chin = landmarks[self.chin_index]              # ä¸‹å·´: 152
        right_cheek = landmarks[self.right_cheek_index] # å³è„¸é¢Š: 454
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ (å½’ä¸€åŒ–åæ ‡ [0,1])
        forehead_point = np.array([forehead.x, forehead.y, forehead.z])
        left_cheek_point = np.array([left_cheek.x, left_cheek.y, left_cheek.z])
        chin_point = np.array([chin.x, chin.y, chin.z])
        right_cheek_point = np.array([right_cheek.x, right_cheek.y, right_cheek.z])
        
        # ğŸ”‘ é‡è¦ï¼šåº”ç”¨Xåæ ‡ä¿®æ­£ï¼ˆå‚è€ƒface_landmarker_cmaera_new.pyï¼‰
        forehead_point[0] *= self.x_scale_factor
        left_cheek_point[0] *= self.x_scale_factor
        chin_point[0] *= self.x_scale_factor
        right_cheek_point[0] *= self.x_scale_factor
        
        # è°ƒè¯•ä¿¡æ¯ï¼ˆå‰å‡ å¸§ï¼‰
        if self.debug_mode and self.frame_count < 3:
            print(f"\n=== å¸§ {self.frame_count} - åŸºäº4ç‚¹å±å¹•ä½ç½®çš„å˜æ¢ ===")
            print(f"æ€»å…³é”®ç‚¹æ•°: {len(landmarks)}")
            print(f"å®½é«˜æ¯”ä¿®æ­£ç³»æ•°: {self.x_scale_factor:.3f}")
            print(f"ä¿®æ­£åå…³é”®ç‚¹:")
            print(f"  é¢å¤´[{self.forehead_index}]: {forehead_point}")
            print(f"  å·¦è„¸é¢Š[{self.left_cheek_index}]: {left_cheek_point}")
            print(f"  ä¸‹å·´[{self.chin_index}]: {chin_point}")
            print(f"  å³è„¸é¢Š[{self.right_cheek_index}]: {right_cheek_point}")
        
        # ğŸ¯ åŸºäº4ä¸ªlandmarksç‚¹è®¡ç®—å˜æ¢å‚æ•°
        
        # 1. è®¡ç®—é¢éƒ¨å°ºå¯¸å’Œä¸­å¿ƒï¼ˆå½’ä¸€åŒ–åæ ‡ï¼‰
        face_width = abs(right_cheek_point[0] - left_cheek_point[0])
        face_height = abs(chin_point[1] - forehead_point[1])
        face_center_x = (left_cheek_point[0] + right_cheek_point[0]) / 2
        face_center_y = (forehead_point[1] + chin_point[1]) / 2
        face_center_z = (forehead_point[2] + left_cheek_point[2] + chin_point[2] + right_cheek_point[2]) / 4
        
        # 2. ğŸ”‘ æ ¸å¿ƒï¼šåŸºäºlandmarksç‚¹é—´è·è®¡ç®—ç¼©æ”¾
        # ä»æ¨¡å‹ä¸­è·å–å¯¹åº”4ä¸ªç‚¹çš„è·ç¦»ä½œä¸ºå‚è€ƒ
        model_face_width = np.linalg.norm(self.model_right_cheek - self.model_left_cheek)
        model_face_height = np.linalg.norm(self.model_chin - self.model_forehead)
        
        # è®¡ç®—ç¼©æ”¾å› å­ï¼šlandmarksè·ç¦» / æ¨¡å‹è·ç¦»
        # ğŸ”§ é‡æ–°è®¾è®¡ç¼©æ”¾è®¡ç®—ï¼Œè®©ç»“æœæ›´åˆç†
        # landmarksæ˜¯å½’ä¸€åŒ–åæ ‡ï¼Œæ¨¡å‹æ˜¯mmå•ä½ï¼Œéœ€è¦åˆé€‚çš„æ¯”ä¾‹è½¬æ¢
        
        # è®¾ç½®åˆç†çš„ç¼©æ”¾åŸºå‡†ï¼šå‡è®¾æ ‡å‡†äººè„¸åœ¨æ‘„åƒå¤´ä¸­çš„å½’ä¸€åŒ–å°ºå¯¸
        reference_face_width = 0.35    # ğŸ”§ å¢å¤§å‚è€ƒå°ºå¯¸è®©æ¨¡å‹æ›´å°
        reference_face_height = 0.42   # ğŸ”§ å¢å¤§å‚è€ƒå°ºå¯¸è®©æ¨¡å‹æ›´å°
        
        # åŸºäºå®é™…æ£€æµ‹å°ºå¯¸ä¸æ ‡å‡†å°ºå¯¸çš„æ¯”å€¼è®¡ç®—ç¼©æ”¾
        base_scale_x = face_width / reference_face_width
        base_scale_y = face_height / reference_face_height
        
        # ğŸ”§ æ·»åŠ é¢å¤–çš„ç¼©å°ç³»æ•°
        size_reduction = 0.8  # æ•´ä½“ç¼©å°åˆ°80%
        
        scale_x = base_scale_x * size_reduction
        scale_y = base_scale_y * size_reduction
        scale_z = (scale_x + scale_y) / 2  # Zè½´ä½¿ç”¨å¹³å‡å€¼
        
        # ğŸ”§ é™åˆ¶ç¼©æ”¾èŒƒå›´ï¼Œé¿å…è¿‡åº¦å˜å½¢
        scale_x = np.clip(scale_x, 0.1, 2.0)  
        scale_y = np.clip(scale_y, 0.1, 2.0)  
        scale_z = np.clip(scale_z, 0.1, 2.0)  
        
        # 3. è®¡ç®—æ—‹è½¬è§’åº¦
        # Rollè§’åº¦ï¼šæ ¹æ®å·¦å³è„¸é¢Šè¿çº¿è®¡ç®—å¤´éƒ¨å·¦å³å€¾æ–œ
        cheek_vector = right_cheek_point - left_cheek_point
        roll_angle = -np.arctan2(cheek_vector[1], cheek_vector[0])
        
        # Pitchè§’åº¦ï¼šæ ¹æ®é¢å¤´å’Œä¸‹å·´è¿çº¿è®¡ç®—å¤´éƒ¨ä¸Šä¸‹å€¾æ–œ
        vertical_vector = chin_point - forehead_point
        pitch_angle = np.arctan2(vertical_vector[2], vertical_vector[1])
        
        # ğŸ”§ ä¿®å¤Yawè§’åº¦ï¼šä½¿ç”¨æ›´å‡†ç¡®çš„å¤´éƒ¨æœå‘è®¡ç®—
        # æ–¹æ³•1ï¼šåŸºäºå·¦å³è„¸é¢Šçš„Zæ·±åº¦å·®ï¼Œä½†å¢å¼ºå¹…åº¦
        z_left = left_cheek_point[2]
        z_right = right_cheek_point[2]
        z_diff = z_right - z_left
        
        # æ–¹æ³•2ï¼šç»“åˆXåæ ‡å·®å¼‚æ¥å¢å¼ºYawæ£€æµ‹
        # å½“å¤´å‘å·¦è½¬æ—¶ï¼Œå³è„¸é¢Šä¼šæ¯”å·¦è„¸é¢Šæ›´é è¿‘å±å¹•ä¸­å¿ƒ
        x_center = (left_cheek_point[0] + right_cheek_point[0]) / 2
        x_offset = face_center_x - x_center  # é¢éƒ¨ä¸­å¿ƒç›¸å¯¹äºè„¸é¢Šä¸­å¿ƒçš„åç§»
        
        # ç»¼åˆè®¡ç®—Yawè§’åº¦
        yaw_angle = np.arctan2(z_diff, face_width) * 2.0 + x_offset * 0.5  # ğŸ”§ å¢å¼ºæ•æ„Ÿåº¦
        
        # 4. åæ ‡ç³»è½¬æ¢ - å°†å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºæ¨¡å‹åæ ‡
        screen_width = self.render_width
        screen_height = self.render_height
        
        # è½¬æ¢ä¸ºå±å¹•åƒç´ åæ ‡
        screen_center_x = face_center_x * screen_width / self.x_scale_factor
        screen_center_y = face_center_y * screen_height
        
        # è½¬æ¢ä¸ºæ¨¡å‹åæ ‡ç³»ï¼ˆä»¥å±å¹•ä¸­å¿ƒä¸ºåŸç‚¹ï¼‰
        model_x = (screen_center_x - screen_width/2) * 0.05   
        model_y = -(screen_center_y - screen_height/2) * 0.05 + 1.5  # Yè½´ç¿»è½¬ + ğŸ”§ å‘ä¸Šåç§»1.5ä¸ªå•ä½
        model_z = face_center_z * 30 + 2  # Zè½´é€‚å½“å‰ç§»
        
        # è°ƒè¯•ä¿¡æ¯
        if self.debug_mode and self.frame_count < 3:
            print(f"æ£€æµ‹åˆ°çš„é¢éƒ¨å°ºå¯¸: å®½åº¦={face_width:.4f}, é«˜åº¦={face_height:.4f}")
            print(f"å‚è€ƒé¢éƒ¨å°ºå¯¸: å®½åº¦={reference_face_width:.2f}, é«˜åº¦={reference_face_height:.2f}")
            print(f"åŸºç¡€ç¼©æ”¾: X={base_scale_x:.3f}, Y={base_scale_y:.3f}")
            print(f"ç¼©å°ç³»æ•°: {size_reduction}")
            print(f"æœ€ç»ˆç¼©æ”¾å› å­: X={scale_x:.3f}, Y={scale_y:.3f}, Z={scale_z:.3f}")
            print(f"Yawè®¡ç®—: Zå·®å€¼={z_diff:.4f}, Xåç§»={x_offset:.4f}")
            print(f"æ—‹è½¬è§’åº¦: Roll={np.degrees(roll_angle):.1f}Â°, Pitch={np.degrees(pitch_angle):.1f}Â°, Yaw={np.degrees(yaw_angle):.1f}Â°")
            print(f"é¢éƒ¨ä¸­å¿ƒ: ({face_center_x:.4f}, {face_center_y:.4f}, {face_center_z:.4f})")
            print(f"å±å¹•åæ ‡: ({screen_center_x:.1f}, {screen_center_y:.1f})")
            print(f"æ¨¡å‹åæ ‡: ({model_x:.2f}, {model_y:.2f}, {model_z:.2f})")
        
        # 5. æ„å»ºå˜æ¢çŸ©é˜µï¼šå¹³ç§» + æ—‹è½¬ + ç¼©æ”¾ (TRSå˜æ¢)
        
        # ç¼©æ”¾çŸ©é˜µ
        scale_matrix = np.eye(4)
        scale_matrix[0, 0] = scale_x
        scale_matrix[1, 1] = scale_y
        scale_matrix[2, 2] = scale_z
        
        # æ—‹è½¬çŸ©é˜µ - ç»„åˆRollã€Pitchã€Yawæ—‹è½¬
        # Rollæ—‹è½¬ï¼ˆç»•Zè½´ï¼‰
        cos_roll, sin_roll = np.cos(roll_angle), np.sin(roll_angle)
        roll_matrix = np.array([
            [cos_roll, -sin_roll, 0, 0],
            [sin_roll, cos_roll, 0, 0],
            [0, 0, 1, 0],
            [0, 0, 0, 1]
        ])
        
        # Pitchæ—‹è½¬ï¼ˆç»•Xè½´ï¼‰
        cos_pitch, sin_pitch = np.cos(pitch_angle), np.sin(pitch_angle)
        pitch_matrix = np.array([
            [1, 0, 0, 0],
            [0, cos_pitch, -sin_pitch, 0],
            [0, sin_pitch, cos_pitch, 0],
            [0, 0, 0, 1]
        ])
        
        # Yawæ—‹è½¬ï¼ˆç»•Yè½´ï¼‰
        cos_yaw, sin_yaw = np.cos(yaw_angle), np.sin(yaw_angle)
        yaw_matrix = np.array([
            [cos_yaw, 0, sin_yaw, 0],
            [0, 1, 0, 0],
            [-sin_yaw, 0, cos_yaw, 0],
            [0, 0, 0, 1]
        ])
        
        # ç»„åˆæ—‹è½¬çŸ©é˜µï¼šYaw * Pitch * Roll
        rotation_matrix = yaw_matrix @ pitch_matrix @ roll_matrix
        
        # å¹³ç§»çŸ©é˜µ
        translation_matrix = np.eye(4)
        translation_matrix[0, 3] = model_x
        translation_matrix[1, 3] = model_y
        translation_matrix[2, 3] = model_z
        
        # æœ€ç»ˆå˜æ¢çŸ©é˜µï¼šT * R * Sï¼ˆä»å³åˆ°å·¦åº”ç”¨ï¼‰
        transform_matrix = translation_matrix @ rotation_matrix @ scale_matrix
        
        # ğŸ†• ä¿å­˜å˜æ¢çŸ©é˜µä¾›å¯¼å‡ºä½¿ç”¨
        self.current_transform_matrix = transform_matrix
        
        if self.debug_mode and self.frame_count < 3:
            print(f"å˜æ¢çŸ©é˜µ:\n{transform_matrix}")
        
        # åº”ç”¨å˜æ¢åˆ°æ¨¡å‹é¡¶ç‚¹
        vertices = self.original_vertices.copy()
        vertices_homogeneous = np.hstack([vertices, np.ones((len(vertices), 1))])
        transformed_vertices = (transform_matrix @ vertices_homogeneous.T).T[:, :3]
        
        # ğŸ†• ä¿å­˜å˜æ¢åçš„é¡¶ç‚¹ä¾›å¯¼å‡ºä½¿ç”¨
        self.current_transformed_vertices = transformed_vertices
        
        # ğŸ†• æ–°å¢ï¼šåº”ç”¨è¡¨æƒ…é©±åŠ¨
        if self.enable_expression_drive:
            transformed_vertices = self.apply_expression_drive(transformed_vertices, detection_result)
        
        # æ›´æ–°æ¨¡å‹
        self.face_mesh.vertices = o3d.utility.Vector3dVector(transformed_vertices)
        self.face_mesh.compute_vertex_normals()
        
        self.frame_count += 1
        if self.frame_count >= 3:
            self.debug_mode = False
        
        return True
    
    def apply_expression_drive(self, vertices, detection_result):
        """ğŸ†• åŸºäºBlendShapesåº”ç”¨è¡¨æƒ…é©±åŠ¨"""
        if not detection_result.face_blendshapes or len(detection_result.face_blendshapes) == 0:
            return vertices
        
        # è·å–BlendShapesæ•°æ®
        blendshapes = detection_result.face_blendshapes[0]
        
        # åˆ›å»ºé¡¶ç‚¹åç§»æ•°ç»„
        vertex_offsets = np.zeros_like(vertices)
        
        # éå†BlendShapeså¹¶åº”ç”¨åˆ°å¯¹åº”çš„é¡¶ç‚¹ç»„
        for category in blendshapes:
            category_name = category.category_name
            score = category.score * self.expression_strength
            
            # åªå¤„ç†æœ‰æ˜¾è‘—å½±å“çš„BlendShapes
            if score < 0.1:
                continue
            
            # ğŸ­ å˜´å·´ç›¸å…³çš„BlendShapes
            if 'mouth' in category_name.lower() or 'jaw' in category_name.lower():
                self.apply_mouth_blendshapes(vertex_offsets, category_name, score)
            
            # ğŸ‘ï¸ çœ¼ç›ç›¸å…³çš„BlendShapes
            elif 'eye' in category_name.lower() or 'blink' in category_name.lower():
                self.apply_eye_blendshapes(vertex_offsets, category_name, score)
            
            # ğŸ¤” çœ‰æ¯›ç›¸å…³çš„BlendShapes
            elif 'brow' in category_name.lower():
                self.apply_eyebrow_blendshapes(vertex_offsets, category_name, score)
            
            # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            if self.show_blendshapes_debug and score > 0.2:
                print(f"   {category_name}: {score:.3f}")
        
        # åº”ç”¨é¡¶ç‚¹åç§»
        return vertices + vertex_offsets
    
    def apply_mouth_blendshapes(self, vertex_offsets, category_name, score):
        """åº”ç”¨å˜´å·´ç›¸å…³çš„BlendShapes"""
        mouth_indices = self.mouth_vertex_indices
        
        if 'open' in category_name.lower() or 'jaw' in category_name.lower():
            # å˜´å·´å¼ å¼€ï¼šä¸‹å·´å‘ä¸‹ç§»åŠ¨
            for idx in mouth_indices:
                if idx < len(vertex_offsets):
                    vertex_offsets[idx, 1] -= score * 3.0  # Yè½´å‘ä¸‹
        
        elif 'smile' in category_name.lower():
            # å¾®ç¬‘ï¼šå˜´è§’å‘ä¸Šå‘å¤–
            for idx in mouth_indices:
                if idx < len(vertex_offsets):
                    vertex_offsets[idx, 1] += score * 1.5  # Yè½´å‘ä¸Š
                    vertex_offsets[idx, 0] += score * 1.0 * np.sign(vertex_offsets[idx, 0])  # Xè½´å‘å¤–
        
        elif 'pucker' in category_name.lower():
            # æ’…å˜´ï¼šå˜´éƒ¨å‘å‰
            for idx in mouth_indices:
                if idx < len(vertex_offsets):
                    vertex_offsets[idx, 2] += score * 2.0  # Zè½´å‘å‰
    
    def apply_eye_blendshapes(self, vertex_offsets, category_name, score):
        """åº”ç”¨çœ¼ç›ç›¸å…³çš„BlendShapes"""
        if 'left' in category_name.lower():
            eye_indices = self.left_eye_vertex_indices
        elif 'right' in category_name.lower():
            eye_indices = self.right_eye_vertex_indices
        else:
            # åŒçœ¼
            eye_indices = self.left_eye_vertex_indices + self.right_eye_vertex_indices
        
        if 'blink' in category_name.lower() or 'close' in category_name.lower():
            # çœ¨çœ¼ï¼šçœ¼çš®å‘å†…æ”¶ç¼©
            for idx in eye_indices:
                if idx < len(vertex_offsets):
                    vertex_offsets[idx, 1] -= score * 1.0  # Yè½´å‘å†…
        
        elif 'wide' in category_name.lower():
            # çœ¼ç›çå¤§ï¼šå‘å¤–æ‰©å¼ 
            for idx in eye_indices:
                if idx < len(vertex_offsets):
                    vertex_offsets[idx, 1] += score * 0.8  # Yè½´å‘å¤–
    
    def apply_eyebrow_blendshapes(self, vertex_offsets, category_name, score):
        """åº”ç”¨çœ‰æ¯›ç›¸å…³çš„BlendShapes"""
        if 'left' in category_name.lower():
            brow_indices = self.eyebrow_vertex_indices[:len(self.eyebrow_vertex_indices)//2]
        elif 'right' in category_name.lower():
            brow_indices = self.eyebrow_vertex_indices[len(self.eyebrow_vertex_indices)//2:]
        else:
            brow_indices = self.eyebrow_vertex_indices
        
        if 'up' in category_name.lower() or 'raise' in category_name.lower():
            # çœ‰æ¯›ä¸Šæ‰¬
            for idx in brow_indices:
                if idx < len(vertex_offsets):
                    vertex_offsets[idx, 1] += score * 2.0  # Yè½´å‘ä¸Š
        
        elif 'down' in category_name.lower() or 'frown' in category_name.lower():
            # çœ‰æ¯›ä¸‹çš±
            for idx in brow_indices:
                if idx < len(vertex_offsets):
                    vertex_offsets[idx, 1] -= score * 1.5  # Yè½´å‘ä¸‹
    
    def draw_original_landmarks(self, image, detection_result):
        """ğŸ†• æ–°å¢ï¼šç»˜åˆ¶åŸå§‹landmarksç‚¹å’Œçº¿æ¡†"""
        if not self.show_original_landmarks or not detection_result.face_landmarks:
            return image
        
        try:
            # è·å–MediaPipeé¢éƒ¨ç½‘æ ¼è¿æ¥ä¿¡æ¯
            mp_face_mesh = mp.solutions.face_mesh
            
            for face_landmarks in detection_result.face_landmarks:
                height, width, _ = image.shape
                
                # è·å–åŸå§‹landmarksåæ ‡ï¼ˆä¸åšä»»ä½•å˜æ¢ï¼‰
                coords = np.array([[lm.x, lm.y, lm.z] for lm in face_landmarks[:468]], dtype=np.float32)
                
                # ç»˜åˆ¶landmarksç‚¹ï¼ˆç»¿è‰²å°åœ†ç‚¹ï¼‰
                for x_norm, y_norm, _ in coords:
                    x = int(x_norm * width)
                    y = int(y_norm * height)
                    # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    if 0 <= x < width and 0 <= y < height:
                        cv2.circle(image, (x, y), 1, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹
                
                # ç»˜åˆ¶é¢éƒ¨ç½‘æ ¼è¿çº¿ï¼ˆç»¿è‰²ç»†çº¿ï¼‰
                if hasattr(mp_face_mesh, 'FACEMESH_TESSELATION'):
                    connections = mp_face_mesh.FACEMESH_TESSELATION
                    for (start_idx, end_idx) in connections:
                        if start_idx < len(coords) and end_idx < len(coords):
                            sx = int(coords[start_idx, 0] * width)
                            sy = int(coords[start_idx, 1] * height)
                            ex = int(coords[end_idx, 0] * width)
                            ey = int(coords[end_idx, 1] * height)
                            # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                            if (0 <= sx < width and 0 <= sy < height and 
                                0 <= ex < width and 0 <= ey < height):
                                cv2.line(image, (sx, sy), (ex, ey), (0, 255, 0), 1)  # ç»¿è‰²çº¿
                
                # ğŸ”‘ ç‰¹åˆ«æ ‡è®°4ä¸ªå…³é”®ç‚¹ï¼ˆçº¢è‰²å¤§åœ†ç‚¹ï¼‰
                key_indices = [self.forehead_index, self.left_cheek_index, 
                              self.chin_index, self.right_cheek_index]
                key_labels = ["é¢å¤´", "å·¦è„¸é¢Š", "ä¸‹å·´", "å³è„¸é¢Š"]
                
                for idx, label in zip(key_indices, key_labels):
                    if idx < len(coords):
                        x = int(coords[idx, 0] * width)
                        y = int(coords[idx, 1] * height)
                        if 0 <= x < width and 0 <= y < height:
                            cv2.circle(image, (x, y), 3, (0, 0, 255), -1)  # çº¢è‰²å¤§ç‚¹
                            cv2.putText(image, f"{idx}", (x+5, y-5), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)
            
            return image
            
        except Exception as e:
            print(f"ç»˜åˆ¶åŸå§‹landmarksé”™è¯¯: {e}")
            return image
    
    def export_realtime_model(self):
        """ğŸ†• æ–°å¢ï¼šå¯¼å‡ºå½“å‰å®æ—¶å˜æ¢åçš„3Dæ¨¡å‹"""
        if not hasattr(self, 'current_transformed_vertices') or self.current_transformed_vertices is None:
            print("âŒ æ²¡æœ‰å¯å¯¼å‡ºçš„å˜æ¢åæ¨¡å‹æ•°æ®")
            return None
        
        try:
            # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
            timestamp = int(time.time())
            filename = f"realtime_face_model_{timestamp}.obj"
            
            # ç¡®ä¿å¯¼å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
            export_dir = "exported_models"
            os.makedirs(export_dir, exist_ok=True)
            filepath = os.path.join(export_dir, filename)
            
            print(f"\n=== å¯¼å‡ºå®æ—¶3Dæ¨¡å‹ ===")
            print(f"æ–‡ä»¶è·¯å¾„: {filepath}")
            print(f"é¡¶ç‚¹æ•°: {len(self.current_transformed_vertices)}")
            
            with open(filepath, 'w', encoding='utf-8') as f:
                # å†™å…¥OBJæ–‡ä»¶å¤´
                f.write("# FaceMatrixLab å®æ—¶3Dé¢å…·æ¨¡å‹\n")
                f.write(f"# å¯¼å‡ºæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# åŸºäºAndy_Wah_facemesh.objï¼Œåº”ç”¨å®æ—¶äººè„¸è·Ÿè¸ªå˜æ¢\n")
                f.write(f"# æ€»é¡¶ç‚¹æ•°: {len(self.current_transformed_vertices)}\n")
                f.write(f"# æ€»é¢æ•°: {len(self.face_mesh.triangles)}\n")
                f.write("\n")
                
                # å†™å…¥å˜æ¢åçš„é¡¶ç‚¹
                for i, vertex in enumerate(self.current_transformed_vertices):
                    f.write(f"v {vertex[0]:.6f} {vertex[1]:.6f} {vertex[2]:.6f}\n")
                
                f.write("\n")
                
                # å†™å…¥é¢ä¿¡æ¯ï¼ˆä¸‰è§’å½¢ï¼‰
                triangles = np.asarray(self.face_mesh.triangles)
                f.write("# é¢å®šä¹‰ (ä¸‰è§’å½¢)\n")
                for i, triangle in enumerate(triangles):
                    # OBJæ–‡ä»¶çš„é¡¶ç‚¹ç´¢å¼•ä»1å¼€å§‹
                    f.write(f"f {triangle[0]+1} {triangle[1]+1} {triangle[2]+1}\n")
                
                # å¦‚æœæœ‰å˜æ¢çŸ©é˜µï¼Œä¹Ÿä¿å­˜ä¸ºæ³¨é‡Š
                if hasattr(self, 'current_transform_matrix'):
                    f.write("\n# å½“å‰å˜æ¢çŸ©é˜µ (TRS)\n")
                    for row in self.current_transform_matrix:
                        f.write(f"# {row[0]:.6f} {row[1]:.6f} {row[2]:.6f} {row[3]:.6f}\n")
            
            # ç»Ÿè®¡æ¨¡å‹ä¿¡æ¯
            vertices = self.current_transformed_vertices
            print(f"å˜æ¢åæ¨¡å‹åæ ‡èŒƒå›´:")
            print(f"  X: [{vertices[:, 0].min():.3f}, {vertices[:, 0].max():.3f}]")
            print(f"  Y: [{vertices[:, 1].min():.3f}, {vertices[:, 1].max():.3f}]")
            print(f"  Z: [{vertices[:, 2].min():.3f}, {vertices[:, 2].max():.3f}]")
            print(f"âœ… å®æ—¶3Dæ¨¡å‹å·²å¯¼å‡º: {filepath}")
            print("ğŸ’¡ å¯ä»¥åœ¨Blenderä¸­å¯¼å…¥æ­¤OBJæ–‡ä»¶æŸ¥çœ‹æ•ˆæœ")
            
            return filepath
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå®æ—¶æ¨¡å‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def run(self):
        """å¯åŠ¨æ¸²æŸ“å™¨"""
        print("\nå¯åŠ¨FaceMatrixLab 3Dé¢å…·æ¸²æŸ“å™¨")
        print("=" * 60)
        print("ğŸ”‘ ä½¿ç”¨MediaPipe faceLandmarks (468ä¸ªNormalizedLandmarkç‚¹)")
        print("ğŸ¯ é‡ç‚¹ä½¿ç”¨4ä¸ªç‰¹å®šç‚¹è¿›è¡ŒARè·Ÿè¸ª:")
        print(f"   é¢å¤´: ç´¢å¼• {self.forehead_index}")
        print(f"   å·¦è„¸é¢Š: ç´¢å¼• {self.left_cheek_index}")
        print(f"   ä¸‹å·´: ç´¢å¼• {self.chin_index}")
        print(f"   å³è„¸é¢Š: ç´¢å¼• {self.right_cheek_index}")
        print("ğŸš€ æ–°å¢åŠŸèƒ½:")
        print("   âœ… åŠ¨æ€ç¼©æ”¾ï¼šæ¨¡å‹å°ºå¯¸è·Ÿéšäººè„¸å¤§å°")
        print("   âœ… å¤´éƒ¨æ—‹è½¬ï¼šRollã€Pitchã€Yawä¸‰è½´æ—‹è½¬")
        print("   âœ… å®Œæ•´å˜æ¢ï¼šå¹³ç§»+æ—‹è½¬+ç¼©æ”¾ (TRS)")
        print("   âœ… 16:9å®½é«˜æ¯”ä¿®æ­£ï¼šæ­£ç¡®å¤„ç†1280x720åˆ†è¾¨ç‡")
        print("   âœ… åŸå§‹landmarksæ˜¾ç¤ºï¼šç»¿è‰²çº¿æ¡†å’Œå…³é”®ç‚¹")
        print("   âœ… è¡¨æƒ…é©±åŠ¨ï¼šåŸºäºBlendShapesçš„è¡¨æƒ…ç³»ç»Ÿ")
        print("=" * 60)
        print("æ§åˆ¶è¯´æ˜:")
        print("  Bé”®: åˆ‡æ¢æ‘„åƒæœºèƒŒæ™¯æ˜¾ç¤º")
        print("  Cé”®: åˆ‡æ¢é¢å…·é¢œè‰²")
        print("  1-6é”®: ç›´æ¥é€‰æ‹©é¢å…·é¢œè‰²")
        print("  Té”®: åˆ‡æ¢çº¹ç†è´´å›¾/ç»Ÿä¸€é¢œè‰²æ¨¡å¼")
        print("  Lé”®: åˆ‡æ¢åŸå§‹landmarksæ˜¾ç¤º")
        print("  Fé”®: åˆ‡æ¢è¡¨æƒ…é©±åŠ¨åŠŸèƒ½")
        print("  Dé”®: åˆ‡æ¢BlendShapesè°ƒè¯•ä¿¡æ¯")
        print("  +/-é”®: è°ƒèŠ‚è¡¨æƒ…å¼ºåº¦ (0.0-3.0)")
        print("  Eé”®: å¯¼å‡ºå½“å‰å®æ—¶3Dæ¨¡å‹ä¸ºOBJæ–‡ä»¶")
        print("  Qé”®: é€€å‡ºç¨‹åº")
        print("=" * 60)
        
        self.is_running = True
        
        # è®¾ç½®å¯è§†åŒ–å™¨
        if not self.setup_visualizer():
            print("âŒ å¯è§†åŒ–å™¨åˆå§‹åŒ–å¤±è´¥")
            return
        
        # å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹
        detection_thread = threading.Thread(target=self.detection_thread, daemon=True)
        detection_thread.start()
        
        # ç­‰å¾…æ£€æµ‹çº¿ç¨‹å¯åŠ¨
        time.sleep(2)
        
        # åˆ›å»ºARåˆæˆçª—å£ - 1280x720
        cv2.namedWindow("AR Face Mask", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("AR Face Mask", self.render_width, self.render_height)
        
        try:
            # ä¸»æ¸²æŸ“å¾ªç¯
            while self.is_running:
                # è¯»å–æœ€æ–°æ•°æ®
                frame = None
                try:
                    pkt = self.data_queue.get_nowait()
                    detection_result = pkt['detection_result']
                    frame = pkt.get('frame')
                    
                    # ä¿å­˜æœ€æ–°å¸§ç”¨äºARåˆæˆ
                    if frame is not None:
                        self.latest_camera_frame = frame.copy()
                    
                    # æ›´æ–°3Dæ¨¡å‹
                    if self.update_face_model(detection_result):
                        self.vis.update_geometry(self.face_mesh)
                except queue.Empty:
                    pass
                
                # ç¦»å±æ¸²æŸ“è·å–3Dæ¨¡å‹å›¾åƒ
                self.vis.poll_events()
                self.vis.update_renderer()
                img_3d = np.asarray(self.vis.capture_screen_float_buffer(False))
                img_3d = (img_3d * 255).astype(np.uint8)
                img_3d_bgr = cv2.cvtColor(img_3d, cv2.COLOR_RGB2BGR)
                
                # ARåˆæˆ: å°†3Dæ¨¡å‹å åŠ åˆ°æ‘„åƒæœºèƒŒæ™¯ä¸Š
                if self.show_camera_background and self.latest_camera_frame is not None:
                    # å‡†å¤‡èƒŒæ™¯å›¾åƒ
                    bg = cv2.cvtColor(self.latest_camera_frame, cv2.COLOR_RGB2BGR)
                    bg = cv2.resize(bg, (self.render_width, self.render_height))
                    
                    # ğŸ†• æ–°å¢ï¼šåœ¨èƒŒæ™¯ä¸Šç»˜åˆ¶åŸå§‹landmarks
                    if hasattr(self, 'latest_detection_result'):
                        bg = self.draw_original_landmarks(bg, self.latest_detection_result)
                    
                    # åˆ›å»ºæ©ç : éé»‘è‰²åƒç´ çš„åŒºåŸŸä¸º3Dæ¨¡å‹
                    mask = img_3d_bgr.sum(axis=2) > 30
                    
                    # åˆæˆå›¾åƒ: èƒŒæ™¯ + 3Dæ¨¡å‹
                    composite = bg.copy()
                    composite[mask] = img_3d_bgr[mask]
                    
                    # æ·»åŠ ä¿¡æ¯æ˜¾ç¤º
                    fps_text = f"FPS: {self.current_fps:.1f}"
                    mask_text = f"é¢å…·é¢œè‰²: {self.current_color_index+1}/{len(self.mask_colors)}"
                    landmarks_text = "faceLandmarks: 468ç‚¹è·Ÿè¸ª"
                    ratio_text = f"å®½é«˜æ¯”: {self.aspect_ratio:.3f} (16:9ä¿®æ­£)"
                    cv2.putText(composite, fps_text, (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    cv2.putText(composite, mask_text, (10, 70), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    cv2.putText(composite, landmarks_text, (10, 110), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    cv2.putText(composite, ratio_text, (10, 150), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
                    
                    # æ˜¾ç¤ºåŸå§‹landmarksçŠ¶æ€
                    landmarks_status = f"åŸå§‹landmarks: {'æ˜¾ç¤º' if self.show_original_landmarks else 'éšè—'} (Lé”®åˆ‡æ¢)"
                    cv2.putText(composite, landmarks_status, (10, 190), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                    
                    # ğŸ†• æ˜¾ç¤ºè¡¨æƒ…é©±åŠ¨çŠ¶æ€
                    expression_status = f"è¡¨æƒ…é©±åŠ¨: {'å¯ç”¨' if self.enable_expression_drive else 'ç¦ç”¨'} (Fé”®åˆ‡æ¢)"
                    cv2.putText(composite, expression_status, (10, 230), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)
                    
                    # æ˜¾ç¤ºè¡¨æƒ…å¼ºåº¦
                    strength_status = f"è¡¨æƒ…å¼ºåº¦: {self.expression_strength:.1f} (+-é”®è°ƒèŠ‚)"
                    cv2.putText(composite, strength_status, (10, 270), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)
                    
                    # ğŸ†• æ˜¾ç¤ºçº¹ç†çŠ¶æ€
                    if hasattr(self, 'has_texture') and self.has_texture:
                        texture_status = f"æ¸²æŸ“æ¨¡å¼: {'çº¹ç†è´´å›¾' if self.texture_mode else 'ç»Ÿä¸€é¢œè‰²'} (Té”®åˆ‡æ¢)"
                        cv2.putText(composite, texture_status, (10, 310), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                    
                    # æ˜¾ç¤ºARåˆæˆç»“æœ
                    cv2.imshow("AR Face Mask", composite)
                else:
                    # åªæ˜¾ç¤º3Dæ¨¡å‹
                    cv2.imshow("AR Face Mask", img_3d_bgr)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('b'):
                    self.show_camera_background = not self.show_camera_background
                    print(f"èƒŒæ™¯æ˜¾ç¤º: {'å¼€å¯' if self.show_camera_background else 'å…³é—­'}")
                elif key == ord('c'):
                    # å¾ªç¯åˆ‡æ¢ä¸‹ä¸€ä¸ªé¢å…·é¢œè‰²
                    next_color = (self.current_color_index + 1) % len(self.mask_colors)
                    self.change_mask_color(next_color)
                elif key >= ord('1') and key <= ord('6'):
                    # ç›´æ¥é€‰æ‹©é¢å…·é¢œè‰² (1-6)
                    color_idx = key - ord('1')
                    if color_idx < len(self.mask_colors):
                        self.change_mask_color(color_idx)
                elif key == ord('l'):
                    # ğŸ†• æ–°å¢ï¼šåˆ‡æ¢åŸå§‹landmarksæ˜¾ç¤º
                    self.show_original_landmarks = not self.show_original_landmarks
                    print(f"åŸå§‹landmarksæ˜¾ç¤º: {'å¼€å¯' if self.show_original_landmarks else 'å…³é—­'}")
                elif key == ord('f'):
                    # ğŸ†• æ–°å¢ï¼šåˆ‡æ¢è¡¨æƒ…é©±åŠ¨
                    self.enable_expression_drive = not self.enable_expression_drive
                    print(f"è¡¨æƒ…é©±åŠ¨: {'å¯ç”¨' if self.enable_expression_drive else 'ç¦ç”¨'}")
                elif key == ord('d'):
                    # ğŸ†• æ–°å¢ï¼šåˆ‡æ¢BlendShapesè°ƒè¯•ä¿¡æ¯
                    self.show_blendshapes_debug = not self.show_blendshapes_debug
                    print(f"BlendShapesè°ƒè¯•: {'æ˜¾ç¤º' if self.show_blendshapes_debug else 'éšè—'}")
                elif key == ord('+') or key == ord('='):
                    # å¢åŠ è¡¨æƒ…å¼ºåº¦
                    self.expression_strength = min(self.expression_strength + 0.1, 3.0)
                    print(f"è¡¨æƒ…å¼ºåº¦: {self.expression_strength:.1f}")
                elif key == ord('-'):
                    # å‡å°‘è¡¨æƒ…å¼ºåº¦
                    self.expression_strength = max(self.expression_strength - 0.1, 0.0)
                    print(f"è¡¨æƒ…å¼ºåº¦: {self.expression_strength:.1f}")
                elif key == ord('t'):
                    # ğŸ†• æ–°å¢ï¼šåˆ‡æ¢çº¹ç†/é¢œè‰²æ¨¡å¼
                    self.toggle_texture_mode()
                elif key == ord('e'):
                    # ğŸ†• æ–°å¢ï¼šå¯¼å‡ºå½“å‰å®æ—¶3Dæ¨¡å‹
                    exported_file = self.export_realtime_model()
                    if exported_file:
                        print(f"ğŸ‰ å®æ—¶3Dæ¨¡å‹å·²å¯¼å‡ºï¼Œå¯åœ¨Blenderä¸­æŸ¥çœ‹: {exported_file}")
                    else:
                        print("âŒ å¯¼å‡ºå¤±è´¥ï¼Œè¯·ç¡®ä¿æœ‰æ£€æµ‹åˆ°çš„äººè„¸")
                elif key == ord('q'):
                    break
                
                # ä¿å­˜æœ€æ–°çš„æ£€æµ‹ç»“æœç”¨äºlandmarksç»˜åˆ¶
                if 'detection_result' in locals():
                    self.latest_detection_result = detection_result
                
                # æ§åˆ¶å¸§ç‡
                time.sleep(1.0 / self.fps_target)
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹ æ¸…ç†èµ„æº...")
        self.is_running = False
        self.vis.destroy_window()
        cv2.destroyAllWindows()
        print("âœ… èµ„æºæ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    print("FaceMatrixLab 3D é¢å…·æ¸²æŸ“å™¨")
    print("ä½¿ç”¨MediaPipe faceLandmarks (468ä¸ªNormalizedLandmarkç‚¹) å®ç°ç²¾ç¡®è·Ÿè¸ª")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = "obj/Andy_Wah_facemesh.obj"
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {model_path}")
        print("è¯·ç¡®ä¿Andy_Wah_facemesh.objæ–‡ä»¶ä½äº obj/ ç›®å½•ä¸­")
        return
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œæ¸²æŸ“å™¨
        renderer = FaceMaskRenderer(camera_id=0, model_path=model_path)
        renderer.run()
        
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print("ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main() 