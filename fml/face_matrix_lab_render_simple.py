#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FaceMatrixLab 3D æ¸²æŸ“å™¨ - ç®€åŒ–ç‰ˆ
ä½¿ç”¨ç¨³å®šçš„Open3D APIè¿›è¡Œå®æ—¶äººè„¸è¿½è¸ªæ¸²æŸ“
"""

import cv2
import mediapipe as mp
import numpy as np
import time
import os
import threading
import queue
import open3d as o3d

# MediaPipe å¯¼å…¥
BaseOptions = mp.tasks.BaseOptions
FaceLandmarker = mp.tasks.vision.FaceLandmarker
FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
VisionRunningMode = mp.tasks.vision.RunningMode


class SimpleFaceRenderer:
    def __init__(self, camera_id=0, model_path="../obj/Andy_Wah_facemesh.obj"):
        """åˆå§‹åŒ–ç®€åŒ–ç‰ˆ3Däººè„¸æ¸²æŸ“å™¨"""
        print("=== FaceMatrixLab ç®€åŒ–ç‰ˆ3Dæ¸²æŸ“å™¨ ===")
        
        self.camera_id = camera_id
        self.model_path = model_path
        self.is_running = False
        
        # MediaPipe è®¾ç½®
        self.mp_model_path = self.download_mediapipe_model()
        self.landmarker = None
        
        # æ•°æ®é˜Ÿåˆ—
        self.data_queue = queue.Queue(maxsize=3)
        self.latest_result = None
        
        # åŠ è½½3Dæ¨¡å‹
        self.load_face_model()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.current_detection_fps = 0
        
        print("âœ… ç®€åŒ–ç‰ˆæ¸²æŸ“å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def download_mediapipe_model(self):
        """ä¸‹è½½MediaPipeæ¨¡å‹"""
        model_url = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
        model_path = "face_landmarker.task"
        
        if not os.path.exists(model_path):
            print("æ­£åœ¨ä¸‹è½½MediaPipeæ¨¡å‹...")
            try:
                import urllib.request
                urllib.request.urlretrieve(model_url, model_path)
                print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_path}")
            except Exception as e:
                print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
                return None
        else:
            print(f"âœ… MediaPipeæ¨¡å‹å·²å­˜åœ¨: {model_path}")
        
        return model_path
    
    def load_face_model(self):
        """åŠ è½½3Däººè„¸æ¨¡å‹"""
        if not os.path.exists(self.model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            return False
            
        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½3Dæ¨¡å‹: {self.model_path}")
        
        try:
            self.face_mesh = o3d.io.read_triangle_mesh(self.model_path)
            
            if len(self.face_mesh.vertices) == 0:
                print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼šæ²¡æœ‰é¡¶ç‚¹æ•°æ®")
                return False
            
            # è®¡ç®—æ³•çº¿
            self.face_mesh.compute_vertex_normals()
            
            # è·å–æ¨¡å‹ä¿¡æ¯
            vertices = np.asarray(self.face_mesh.vertices)
            self.num_vertices = len(vertices)
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ:")
            print(f"   é¡¶ç‚¹æ•°: {self.num_vertices}")
            print(f"   é¢æ•°: {len(self.face_mesh.triangles)}")
            
            # è®¾ç½®æè´¨é¢œè‰²
            self.face_mesh.paint_uniform_color([0.8, 0.7, 0.6])  # è‚¤è‰²
            
            # å¤‡ä»½åŸå§‹é¡¶ç‚¹
            self.original_vertices = np.asarray(self.face_mesh.vertices).copy()
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def create_mediapipe_landmarker(self):
        """åˆ›å»ºMediaPipeæ£€æµ‹å™¨"""
        if not self.mp_model_path:
            return None
            
        try:
            options = FaceLandmarkerOptions(
                base_options=BaseOptions(model_asset_path=self.mp_model_path),
                running_mode=VisionRunningMode.VIDEO,
                num_faces=1,
                min_face_detection_confidence=0.5,
                min_face_presence_confidence=0.5,
                min_tracking_confidence=0.5,
                output_face_blendshapes=False,
                output_facial_transformation_matrixes=True,
            )
            
            return FaceLandmarker.create_from_options(options)
            
        except Exception as e:
            print(f"âŒ MediaPipeæ£€æµ‹å™¨åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def detection_thread(self):
        """MediaPipeæ£€æµ‹çº¿ç¨‹"""
        print("ğŸ¥ å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹...")
        
        self.landmarker = self.create_mediapipe_landmarker()
        if not self.landmarker:
            print("âŒ MediaPipeæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥")
            return
        
        cap = cv2.VideoCapture(self.camera_id)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_id}")
            return
        
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        frame_count = 0
        fps_start_time = time.time()
        
        try:
            while self.is_running:
                ret, frame = cap.read()
                if not ret:
                    continue
                
                frame = cv2.flip(frame, 1)
                frame_count += 1
                
                # è½¬æ¢ä¸ºRGBå¹¶æ£€æµ‹
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
                
                timestamp_ms = int(time.time() * 1000)
                detection_result = self.landmarker.detect_for_video(mp_image, timestamp_ms)
                
                # å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
                try:
                    data_packet = {
                        'detection_result': detection_result,
                        'timestamp': timestamp_ms
                    }
                    self.data_queue.put_nowait(data_packet)
                except queue.Full:
                    # é˜Ÿåˆ—æ»¡äº†å°±ä¸¢å¼ƒæœ€æ—§çš„æ•°æ®
                    try:
                        self.data_queue.get_nowait()
                        self.data_queue.put_nowait(data_packet)
                    except queue.Empty:
                        pass
                
                # è®¡ç®—æ£€æµ‹FPS
                if frame_count % 30 == 0:
                    elapsed = time.time() - fps_start_time
                    self.current_detection_fps = 30.0 / elapsed
                    fps_start_time = time.time()
                    print(f"æ£€æµ‹FPS: {self.current_detection_fps:.1f}")
                
                time.sleep(1.0 / 30)  # é™åˆ¶30FPS
                
        except Exception as e:
            print(f"âŒ æ£€æµ‹çº¿ç¨‹é”™è¯¯: {e}")
        finally:
            cap.release()
            print("ğŸ¥ MediaPipeæ£€æµ‹çº¿ç¨‹å·²åœæ­¢")
    
    def update_face_model(self, detection_result):
        """æ›´æ–°3Däººè„¸æ¨¡å‹"""
        if not detection_result.face_landmarks:
            return
        
        # è·å–å˜æ¢çŸ©é˜µ
        if (detection_result.facial_transformation_matrixes and 
            len(detection_result.facial_transformation_matrixes) > 0):
            
            facial_transform = np.array(detection_result.facial_transformation_matrixes[0])
            
            # åº”ç”¨å˜æ¢åˆ°åŸå§‹é¡¶ç‚¹
            vertices = self.original_vertices.copy()
            
            # å°†é¡¶ç‚¹è½¬æ¢ä¸ºé½æ¬¡åæ ‡
            vertices_homogeneous = np.hstack([vertices, np.ones((len(vertices), 1))])
            
            # åº”ç”¨å˜æ¢çŸ©é˜µ
            transformed_vertices = (facial_transform @ vertices_homogeneous.T).T[:, :3]
            
            # æ›´æ–°æ¨¡å‹é¡¶ç‚¹
            self.face_mesh.vertices = o3d.utility.Vector3dVector(transformed_vertices)
            self.face_mesh.compute_vertex_normals()
            
            return True
        
        return False
    
    def run_with_visualizer(self):
        """ä½¿ç”¨Open3Då¯è§†åŒ–å™¨è¿è¡Œ"""
        print("ğŸ¬ å¯åŠ¨Open3Då¯è§†åŒ–å™¨...")
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        vis = o3d.visualization.Visualizer()
        vis.create_window("FaceMatrixLab - 3D Face Renderer", 1280, 720)
        
        # æ·»åŠ æ¨¡å‹åˆ°å¯è§†åŒ–å™¨
        vis.add_geometry(self.face_mesh)
        
        # è®¾ç½®æ¸²æŸ“é€‰é¡¹
        render_option = vis.get_render_option()
        render_option.mesh_show_back_face = True
        render_option.background_color = np.array([0.1, 0.1, 0.1])
        
        # è®¾ç½®ç›¸æœºå‚æ•°
        view_control = vis.get_view_control()
        
        print("âœ… å¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        print("æ§åˆ¶è¯´æ˜:")
        print("  é¼ æ ‡å·¦é”® + æ‹–æ‹½: æ—‹è½¬è§†è§’")
        print("  é¼ æ ‡å³é”® + æ‹–æ‹½: ç¼©æ”¾")
        print("  é¼ æ ‡æ»šè½®: ç¼©æ”¾")
        print("  Qé”® æˆ–å…³é—­çª—å£: é€€å‡º")
        
        try:
            while self.is_running:
                # å¤„ç†MediaPipeæ•°æ®
                try:
                    while not self.data_queue.empty():
                        data_packet = self.data_queue.get_nowait()
                        if self.update_face_model(data_packet['detection_result']):
                            # æ›´æ–°å¯è§†åŒ–å™¨ä¸­çš„å‡ ä½•ä½“
                            vis.update_geometry(self.face_mesh)
                except queue.Empty:
                    pass
                
                # æ›´æ–°å¯è§†åŒ–å™¨
                if not vis.poll_events():
                    break
                vis.update_renderer()
                
                time.sleep(1.0 / 60)  # 60FPSæ¸²æŸ“
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
        finally:
            vis.destroy_window()
    
    def run(self):
        """å¯åŠ¨æ¸²æŸ“å™¨"""
        print("\nğŸš€ å¯åŠ¨FaceMatrixLab ç®€åŒ–ç‰ˆ3Dæ¸²æŸ“å™¨")
        print("=" * 50)
        
        self.is_running = True
        
        # å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹
        detection_thread = threading.Thread(target=self.detection_thread, daemon=True)
        detection_thread.start()
        
        # ç­‰å¾…æ£€æµ‹çº¿ç¨‹å¯åŠ¨
        time.sleep(2)
        
        try:
            # è¿è¡Œå¯è§†åŒ–å™¨
            self.run_with_visualizer()
        finally:
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹ æ¸…ç†èµ„æº...")
        self.is_running = False
        print("âœ… èµ„æºæ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    print("FaceMatrixLab ç®€åŒ–ç‰ˆ3Däººè„¸æ¸²æŸ“å™¨")
    print("ä½¿ç”¨MediaPipe + Open3Då®ç°å®æ—¶3Däººè„¸è¿½è¸ªæ¸²æŸ“")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = "../obj/Andy_Wah_facemesh.obj"
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {model_path}")
        print("è¯·ç¡®ä¿Andy_Wah_facemesh.objæ–‡ä»¶ä½äº obj/ ç›®å½•ä¸­")
        return
    
    try:
        renderer = SimpleFaceRenderer(camera_id=0, model_path=model_path)
        renderer.run()
        
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print("ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main() 