#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FaceMatrixLab 3D æ¸²æŸ“å™¨
ä½¿ç”¨ Open3D æ¸²æŸ“ Andy_Wah_facemesh.objï¼Œé€šè¿‡ MediaPipe æ•°æ®æµé©±åŠ¨
æ”¯æŒå®æ—¶äººè„¸å§¿æ€å’Œè¡¨æƒ…å˜åŒ–
"""

import cv2
import mediapipe as mp
import numpy as np
import time
import os
import threading
import queue
from typing import Optional, Tuple
import open3d as o3d


# MediaPipe å¯¼å…¥
BaseOptions = mp.tasks.BaseOptions
FaceLandmarker = mp.tasks.vision.FaceLandmarker
FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
FaceLandmarkerResult = mp.tasks.vision.FaceLandmarkerResult
VisionRunningMode = mp.tasks.vision.RunningMode


class FaceMatrixLabRenderer:
    def __init__(self, camera_id=0, model_path="obj/Andy_Wah_facemesh.obj"):
        """åˆå§‹åŒ–3Däººè„¸æ¸²æŸ“å™¨"""
        print("=== FaceMatrixLab 3D æ¸²æŸ“å™¨åˆå§‹åŒ– ===")
        
        # åŸºæœ¬å‚æ•°
        self.camera_id = camera_id
        self.model_path = model_path
        self.is_running = False
        
        # æ¸²æŸ“å‚æ•°
        self.render_width = 1280
        self.render_height = 720
        self.fps_target = 30
        
        # MediaPipe ç›¸å…³
        self.landmarker = None
        self.mp_model_path = self.download_mediapipe_model()
        
        # æ•°æ®é˜Ÿåˆ— - ç”¨äºçº¿ç¨‹é—´é€šä¿¡
        self.data_queue = queue.Queue(maxsize=5)
        self.latest_result = None
        self.latest_frame = None
        
        # ARèƒŒæ™¯æ§åˆ¶
        self.show_camera_background = True  # é»˜è®¤æ˜¾ç¤ºæ‘„åƒæœºèƒŒæ™¯
        self.background_image = None
        self.latest_camera_frame = None  # ä¿å­˜æœ€æ–°çš„æ‘„åƒæœºå¸§
        
                # ã€solvePnPæ–¹æ³•ã€‘ç›¸æœºæ ¡å‡†å‚æ•°
        self.use_solvepnp = True  # ä½¿ç”¨solvePnPè¿›è¡Œç²¾ç¡®3Dè·Ÿè¸ª
        self.calibration_file = "calib.npz"  # ç›¸æœºæ ‡å®šæ–‡ä»¶
        
        # ç›¸æœºå†…å‚çŸ©é˜µ
        self.K = None  # 3x3ç›¸æœºå†…å‚çŸ©é˜µ
        self.dist = None  # ç•¸å˜ç³»æ•°
        
        # ã€solvePnPå…³é”®ç‚¹é…ç½®ã€‘åŸºäºæ‚¨æä¾›çš„landmarkåˆ†æ
        # åŸºäºcanonical_face_model.objåˆ†æçš„å‡†ç¡®é…ç½®
        # ä¸­çº¿ç‚¹ç´¢å¼•ï¼ˆè¿™äº›ç‚¹çš„Xåæ ‡åº”è¯¥ä¸º0ï¼‰
        self.centerline_indices = [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 94, 151, 152, 164, 168, 175, 195, 197, 199, 200]
       
        # å¯¹ç§°ç‚¹å¯¹ç´¢å¼•ï¼ˆå·¦ç‚¹ç´¢å¼•, å³ç‚¹ç´¢å¼•ï¼‰
        self.symmetric_pairs = [
            (3, 248), (7, 249), (20, 250), (21, 251), (22, 252), (23, 253), (24, 254), (25, 255),
            (26, 256), (27, 257), (28, 258), (29, 259), (30, 260), (31, 261), (32, 262), (33, 263),
            (34, 264), (35, 265), (36, 266), (37, 267), (38, 268), (39, 269), (40, 270), (41, 271),
            (42, 272), (43, 273), (44, 274), (45, 275), (46, 276), (47, 277), (48, 278), (49, 279),
            (50, 280), (51, 281), (52, 282), (53, 283), (54, 284), (55, 285), (56, 286), (57, 287),
            (58, 288), (59, 289), (60, 290), (61, 291), (62, 292), (63, 293), (64, 294), (65, 295),
            (66, 296), (67, 297), (68, 298), (69, 299), (70, 300), (71, 301), (72, 302), (73, 303)
        ]
       
        # å…³é”®landmarkç‚¹
        self.key_landmarks = {
            'nose_tip': 4,      # é¼»å°–
            'left_eye': 34,     # å·¦çœ¼è§’
            'right_eye': 264,   # å³çœ¼è§’
            'left_mouth': 192,  # å·¦å˜´è§’
            'right_mouth': 416  # å³å˜´è§’
        }
        
        # ã€solvePnPç”¨çš„3D-2Då¯¹åº”ç‚¹ã€‘åŸºäºlandmarkåˆ†æé€‰æ‹©ç¨³å®šçš„å…³é”®ç‚¹
        # é€‰æ‹©MediaPipeæœ€ç¨³å®šã€æœ€å‡†ç¡®çš„æ£€æµ‹ç‚¹
        self.pnp_indices = [
            # æ ¸å¿ƒé¢éƒ¨ç‰¹å¾ç‚¹ï¼ˆæœ€ç¨³å®šï¼‰
            1,     # é¼»å°–ä¸­å¿ƒ
            168,   # é¢éƒ¨ä¸­å¿ƒç‚¹
            10,    # ä¸Šå”‡ä¸­å¿ƒ
            152,   # çœ‰å¿ƒä¸­å¿ƒ
            175,   # ä¸‹å”‡ä¸­å¿ƒ
            
            # åŒçœ¼å…³é”®ç‚¹ï¼ˆé«˜ç²¾åº¦ï¼‰
            33, 263,   # åŒçœ¼å†…è§’
            130, 359,  # åŒçœ¼å¤–è§’
            
            # çœ‰æ¯›å’Œçœ¼éƒ¨è½®å»“
            70, 300,   # çœ‰æ¯›ä¸­éƒ¨
            107, 336,  # çœ¼éƒ¨è½®å»“
            
            # é¼»éƒ¨ç‰¹å¾
            19, 94,    # é¼»æ¡¥
            
            # é¢éƒ¨è¾¹ç•Œç‚¹
            234, 454,  # é¢é¢Š
            172, 397,  # é¢éƒ¨ä¾§è¾¹
        ]
        
        # ARè·Ÿè¸ªæ§åˆ¶å‚æ•°
        self.ar_tracking_enabled = True    # æ˜¯å¦å¯ç”¨ARè·Ÿè¸ª
        self.coordinate_system_flip_z = False  # æ˜¯å¦ç¿»è½¬Zè½´åæ ‡
        self.ar_scale_factor = 1.0         # ARæ¨¡å‹ç¼©æ”¾ç³»æ•°
        self.ar_offset_x = 0.0             # ARæ¨¡å‹Xè½´åç§»
        self.ar_offset_y = 0.0             # ARæ¨¡å‹Yè½´åç§» 
        self.ar_offset_z = 0.0             # ARæ¨¡å‹Zè½´åç§»
        
        # ã€è°ƒè¯•æ¨¡å¼ã€‘
        self.fallback_to_matrix = False    # å¦‚æœsolvePnPå¤±è´¥ï¼Œæ˜¯å¦å›é€€åˆ°transformation_matrixæ–¹æ³•
        self.debug_mode = True             # æ˜¯å¦è¾“å‡ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯
        
        # ã€solvePnPæ–¹æ³•ã€‘åŠ è½½ç›¸æœºæ ‡å®šå‚æ•°
        self.load_camera_calibration()
        
        # ç›¸æœºå‚æ•°ï¼ˆ50mm ç­‰æ•ˆç„¦è·ï¼‰- å°†åœ¨setup_camera_parametersä¸­æ ¹æ®æ ¡å‡†ç»“æœè®¾ç½®
        self.setup_camera_parameters()
        
        # åŠ è½½3Dæ¨¡å‹
        if not self.load_face_model():
            raise Exception("æ— æ³•åŠ è½½3Dæ¨¡å‹æ–‡ä»¶")
        
        # æ€§èƒ½ç»Ÿè®¡
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.current_render_fps = 0
        self.current_detection_fps = 0
        
        print("âœ… FaceMatrixLab 3D æ¸²æŸ“å™¨åˆå§‹åŒ–å®Œæˆ")
        
    def download_mediapipe_model(self):
        """ä¸‹è½½MediaPipeäººè„¸æ ‡å¿—æ£€æµ‹æ¨¡å‹"""
        model_url = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
        model_path = "face_landmarker.task"
        
        if not os.path.exists(model_path):
            print("æ­£åœ¨ä¸‹è½½MediaPipeæ¨¡å‹...")
            try:
                import urllib.request
                urllib.request.urlretrieve(model_url, model_path)
                print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_path}")
            except Exception as e:
                print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
                return None
        else:
            print(f"âœ… MediaPipeæ¨¡å‹å·²å­˜åœ¨: {model_path}")
        
        return model_path
    
    def load_camera_calibration(self):
        """ã€solvePnPæ–¹æ³•ã€‘åŠ è½½ç›¸æœºæ ‡å®šå‚æ•°"""
        if not self.use_solvepnp:
            print("ğŸ“· æœªå¯ç”¨solvePnPï¼Œå°†ä½¿ç”¨é»˜è®¤ä¼°è®¡å‚æ•°")
            return
        
        try:
            if os.path.exists(self.calibration_file):
                print(f"ğŸ“· æ­£åœ¨åŠ è½½ç›¸æœºæ ‡å®šæ–‡ä»¶: {self.calibration_file}")
                
                # åŠ è½½numpyæ ‡å®šæ–‡ä»¶
                calib_data = np.load(self.calibration_file)
                self.K = calib_data['K']  # 3x3ç›¸æœºå†…å‚çŸ©é˜µ
                self.dist = calib_data['dist']  # ç•¸å˜ç³»æ•°
                
                print("âœ… ç›¸æœºæ ‡å®šå‚æ•°åŠ è½½æˆåŠŸ:")
                print("ğŸ“ ç›¸æœºå†…å‚çŸ©é˜µ (K):")
                print(self.K)
                print(f"   ç„¦è·: fx={self.K[0,0]:.2f}, fy={self.K[1,1]:.2f}")
                print(f"   ä¸»ç‚¹: cx={self.K[0,2]:.2f}, cy={self.K[1,2]:.2f}")
                print(f"ğŸ”§ ç•¸å˜ç³»æ•°: {self.dist.ravel()}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è´¨é‡ä¿¡æ¯
                if 'mean_error' in calib_data:
                    mean_error = calib_data['mean_error']
                    print(f"ğŸ“Š æ ‡å®šç²¾åº¦: {mean_error:.3f} åƒç´ ")
                    
                print("ğŸ¯ solvePnPæ–¹æ³•å·²å¯ç”¨ï¼Œå°†è¿›è¡Œç²¾ç¡®3Då§¿æ€ä¼°è®¡")
                
            else:
                print(f"âŒ æ ‡å®šæ–‡ä»¶ä¸å­˜åœ¨: {self.calibration_file}")
                print("ğŸ”„ å°è¯•åŠ è½½å…¼å®¹æ ¼å¼çš„æ ‡å®šæ–‡ä»¶...")
                
                # å°è¯•åŠ è½½face_landmarker_cmaera_new.pyæ ¼å¼çš„æ ‡å®šæ–‡ä»¶
                intrinsic_path = "Camera-Calibration/output/intrinsic.txt"
                if self.load_calibration_from_text(intrinsic_path):
                    print("âœ… æˆåŠŸä»æ–‡æœ¬æ ¼å¼åŠ è½½ç›¸æœºæ ‡å®š")
                else:
                    print("è¯·å…ˆè¿è¡Œ python calibrate_cam.py è¿›è¡Œç›¸æœºæ ‡å®š")
                    self.use_solvepnp = False
                
        except Exception as e:
            print(f"âŒ åŠ è½½ç›¸æœºæ ‡å®šå‚æ•°å¤±è´¥: {e}")
            print("âš ï¸ å°†å›é€€åˆ°ä¼°è®¡ç›¸æœºå‚æ•°")
            self.use_solvepnp = False
            self.K = None
            self.dist = None
    
    def load_calibration_from_text(self, intrinsic_path):
        """ä»æ–‡æœ¬æ ¼å¼åŠ è½½ç›¸æœºæ ‡å®šå‚æ•°ï¼ˆå…¼å®¹face_landmarker_cmaera_new.pyï¼‰"""
        try:
            if os.path.exists(intrinsic_path):
                print(f"ğŸ“„ æ­£åœ¨åŠ è½½æ–‡æœ¬æ ¼å¼æ ‡å®šæ–‡ä»¶: {intrinsic_path}")
                
                # è¯»å–å†…å‚æ–‡ä»¶
                with open(intrinsic_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£æå†…å‚çŸ©é˜µ - æ”¯æŒå¤šç§æ ¼å¼
                lines = content.strip().split('\n')
                matrix_lines = []
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('A=') and '[' in line and ']' in line:
                        # æ¸…ç†æ–¹æ‹¬å·å¹¶æå–æ•°å­—
                        line = line.replace('[', '').replace(']', '')
                        matrix_lines.append(line)
                
                if len(matrix_lines) >= 3:
                    # è§£æ3x3å†…å‚çŸ©é˜µ
                    intrinsic_matrix = []
                    for line in matrix_lines[:3]:
                        # åˆ†å‰²æ•°å­—ï¼ˆå¤„ç†å¯èƒ½çš„ç§‘å­¦è®¡æ•°æ³•ï¼‰
                        values = []
                        parts = line.split()
                        for part in parts:
                            try:
                                values.append(float(part))
                            except ValueError:
                                continue
                        if len(values) >= 3:
                            intrinsic_matrix.append(values[:3])
                    
                    if len(intrinsic_matrix) == 3:
                        # æå–ç›¸æœºå‚æ•°
                        self.K = np.array(intrinsic_matrix)
                        
                        # è®¾ç½®é»˜è®¤ç•¸å˜ç³»æ•°ï¼ˆå¦‚æœæ²¡æœ‰ä¸“é—¨çš„ç•¸å˜æ–‡ä»¶ï¼‰
                        self.dist = np.zeros((5,), dtype=np.float64)
                        
                        print("âœ… ä»æ–‡æœ¬æ ¼å¼åŠ è½½ç›¸æœºå†…å‚:")
                        print(f"   fx: {self.K[0,0]:.2f}")
                        print(f"   fy: {self.K[1,1]:.2f}")
                        print(f"   cx: {self.K[0,2]:.2f}")
                        print(f"   cy: {self.K[1,2]:.2f}")
                        print(f"   ç•¸å˜ç³»æ•°: ä½¿ç”¨é›¶ç•¸å˜ï¼ˆå¯æŒ‰éœ€è°ƒæ•´ï¼‰")
                        
                        self.use_solvepnp = True
                        return True
                    else:
                        print("âŒ æ— æ³•è§£æå†…å‚çŸ©é˜µæ ¼å¼")
                        return False
                else:
                    print("âŒ å†…å‚æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
                    return False
            else:
                print(f"âŒ æ–‡æœ¬æ ¼å¼æ ‡å®šæ–‡ä»¶ä¸å­˜åœ¨: {intrinsic_path}")
                return False
                
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡æœ¬æ ¼å¼æ ‡å®šå¤±è´¥: {e}")
            return False
    
    def setup_camera_parameters(self):
        """ã€solvePnPæ–¹æ³•ã€‘è®¾ç½®ç›¸æœºå‚æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨æ ‡å®šå‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨ä¼°è®¡å€¼ï¼‰"""
        print("ğŸ“· ç›¸æœºå‚æ•°è®¾ç½®:")
        print(f"   åˆ†è¾¨ç‡: {self.render_width}x{self.render_height}")
        
        # å¦‚æœæˆåŠŸåŠ è½½äº†æ ‡å®šå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨
        if self.use_solvepnp and self.K is not None:
            self.fx = self.K[0, 0]
            self.fy = self.K[1, 1]
            self.cx = self.K[0, 2]
            self.cy = self.K[1, 2]
            
            print("âœ… ä½¿ç”¨æ ‡å®šç›¸æœºå‚æ•°:")
            print(f"   ç„¦è·: fx={self.fx:.2f}, fy={self.fy:.2f}")
            print(f"   ä¸»ç‚¹: cx={self.cx:.2f}, cy={self.cy:.2f}")
            print("   ğŸ¯ solvePnPå°†ä½¿ç”¨è¿™äº›ç²¾ç¡®å‚æ•°è¿›è¡Œ3Då§¿æ€ä¼°è®¡")
        
        else:
            # å›é€€åˆ°50mmç­‰æ•ˆç„¦è·ä¼°è®¡
            print("âš ï¸ ä½¿ç”¨50mmç­‰æ•ˆç„¦è·ä¼°è®¡å‚æ•°:")
            
        # 50mm ç­‰æ•ˆç„¦è·å‚æ•°
        f_mm = 50.0  # ç„¦è·(mm)
        sensor_width_mm = 36.0  # å…¨ç”»å¹…ä¼ æ„Ÿå™¨å®½åº¦(mm)
        
        # è®¡ç®—åƒç´ ç„¦è·
        self.fx = (f_mm / sensor_width_mm) * self.render_width
        self.fy = (f_mm / sensor_width_mm) * self.render_height
        self.cx = self.render_width / 2.0
        self.cy = self.render_height / 2.0
        
        # åˆ›å»ºä¼°è®¡çš„KçŸ©é˜µå’Œç•¸å˜ç³»æ•°ï¼ˆç”¨äºsolvePnPï¼‰
        self.K = np.array([
            [self.fx, 0, self.cx],
            [0, self.fy, self.cy],
            [0, 0, 1]
        ], dtype=np.float32)
        self.dist = np.zeros(5, dtype=np.float32)  # å‡è®¾æ— ç•¸å˜
        
        print(f"   ç„¦è·: fx={self.fx:.2f}, fy={self.fy:.2f}")
        print(f"   ä¸»ç‚¹: cx={self.cx:.2f}, cy={self.cy:.2f}")
        print(f"   æ³¨æ„: è¿™æ˜¯åŸºäº50mmç­‰æ•ˆç„¦è·çš„ä¼°è®¡å€¼")
        
        # åˆ›å»ºOpen3Dç›¸æœºå†…å‚
        self.intrinsic = o3d.camera.PinholeCameraIntrinsic(
            self.render_width, self.render_height, 
            self.fx, self.fy, self.cx, self.cy
        )
        
        print(f"âœ… Open3Dç›¸æœºå†…å‚åˆ›å»ºå®Œæˆ")
    
    def load_face_model(self):
        """åŠ è½½3Däººè„¸æ¨¡å‹ï¼ˆä½¿ç”¨ä¸æµ‹è¯•è„šæœ¬ç›¸åŒçš„æ–¹å¼ï¼‰"""
        if not os.path.exists(self.model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            return False
            
        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½3Dæ¨¡å‹: {self.model_path}")
        
        try:
            # ã€å…³é”®ä¿®æ­£ã€‘ç›´æ¥ä»OBJæ–‡ä»¶è¯»å–å‰468ä¸ªé¡¶ç‚¹ï¼Œä¸MediaPipe landmarksåŒ¹é…
            vertices = []
            with open(self.model_path, 'r') as f:
                for line in f:
                    if line.startswith('v '):
                        parts = line.strip().split()
                        x, y, z = float(parts[1]), float(parts[2]), float(parts[3])
                        vertices.append([x, y, z])
                        # åªè¯»å–å‰468ä¸ªé¡¶ç‚¹ï¼ŒåŒ¹é…MediaPipe landmarksæ•°é‡
                        if len(vertices) >= 468:
                            break
            
            vertices = np.array(vertices, dtype=np.float32)
            
            if len(vertices) == 0:
                print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼šæ²¡æœ‰é¡¶ç‚¹æ•°æ®")
                return False
            
            # ä½¿ç”¨ç®€åŒ–çš„é¡¶ç‚¹åˆ›å»ºåŸºç¡€å‡ ä½•ä½“
            # åˆ›å»ºç‚¹äº‘ç”¨äºå¯è§†åŒ–
            self.face_mesh = o3d.geometry.PointCloud()
            self.face_mesh.points = o3d.utility.Vector3dVector(vertices)
            self.face_mesh.paint_uniform_color([0.8, 0.7, 0.6])  # è‚¤è‰²
            
            # ä¸ºäº†æ›´å¥½çš„å¯è§†åŒ–æ•ˆæœï¼Œä¹Ÿåˆ›å»ºä¸€ä¸ªç®€å•çš„ä¸‰è§’ç½‘æ ¼
            # è¯»å–å®Œæ•´çš„OBJæ–‡ä»¶ç”¨äºæ¸²æŸ“
            self.face_mesh_full = o3d.io.read_triangle_mesh(self.model_path)
            if len(self.face_mesh_full.vertices) > 0:
                self.face_mesh_full.compute_vertex_normals()
                self.face_mesh_full.paint_uniform_color([0.8, 0.7, 0.6])
                # ä½¿ç”¨å®Œæ•´ç½‘æ ¼è¿›è¡Œæ˜¾ç¤º
                self.face_mesh = self.face_mesh_full
            
            self.num_vertices = len(vertices)  # ç”¨äºsolvePnPçš„é¡¶ç‚¹æ•°é‡ï¼ˆ468ï¼‰
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ:")
            print(f"   solvePnPé¡¶ç‚¹æ•°: {self.num_vertices} (å‰468ä¸ª)")
            print(f"   æ˜¾ç¤ºç½‘æ ¼é¡¶ç‚¹æ•°: {len(self.face_mesh.vertices)}")
            print(f"   é¢æ•°: {len(self.face_mesh.triangles) if hasattr(self.face_mesh, 'triangles') else 0}")
            print(f"   åæ ‡èŒƒå›´:")
            print(f"     X: [{vertices[:, 0].min():.2f}, {vertices[:, 0].max():.2f}] mm")
            print(f"     Y: [{vertices[:, 1].min():.2f}, {vertices[:, 1].max():.2f}] mm") 
            print(f"     Z: [{vertices[:, 2].min():.2f}, {vertices[:, 2].max():.2f}] mm")
            
            # ã€é‡è¦ã€‘å¤‡ä»½å‰468ä¸ªé¡¶ç‚¹ç”¨äºsolvePnP
            self.original_vertices = vertices.copy()
            
            # ã€å…³é”®ä¿®æ­£ã€‘è·å–å®Œæ•´æ¨¡å‹çš„åŸå§‹é¡¶ç‚¹ä½œä¸ºå¤‡ä»½
            if hasattr(self, 'face_mesh_full') and len(self.face_mesh_full.vertices) > 0:
                self.original_full_vertices = np.asarray(self.face_mesh_full.vertices).copy()
            else:
                self.original_full_vertices = vertices.copy()
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def setup_visualizer(self):
        """è®¾ç½®Open3Då¯è§†åŒ–å™¨ï¼ˆç¦»å±æ¸²æŸ“ç‰ˆæœ¬ï¼Œå…¼å®¹Windowsï¼‰"""
        print("ğŸ¨ åˆå§‹åŒ–Open3Då¯è§†åŒ–å™¨...")
        # åˆ›å»ºéšè—çš„å¯è§†åŒ–å™¨çª—å£è¿›è¡Œç¦»å±æ¸²æŸ“
        self.vis = o3d.visualization.Visualizer()
        self.vis.create_window("_", self.render_width, self.render_height, visible=False)
        
        # æ·»åŠ äººè„¸æ¨¡å‹ï¼ˆä¸ä½¿ç”¨MaterialRecordï¼Œç›´æ¥ä½¿ç”¨ç½‘æ ¼é¢œè‰²ï¼‰
        self.vis.add_geometry(self.face_mesh)
        
        # è®¾ç½®æ¸²æŸ“é€‰é¡¹
        render_option = self.vis.get_render_option()
        render_option.mesh_show_back_face = True
        render_option.background_color = np.array([0.0, 0.0, 0.0])  # é»‘è‰²èƒŒæ™¯ä¾¿äºåˆæˆ
        
        # è®¾ç½®ç›¸æœºå‚æ•°
        ctr = self.vis.get_view_control()
        # åˆ›å»ºç›¸æœºå‚æ•°å¯¹è±¡
        camera_params = o3d.camera.PinholeCameraParameters()
        camera_params.intrinsic = self.intrinsic
        camera_params.extrinsic = np.eye(4)
        ctr.convert_from_pinhole_camera_parameters(camera_params)
        
        # è°ƒæ•´near/farè£å‰ªé¢ï¼Œæ”¯æŒæ¯«ç±³çº§æ·±åº¦èŒƒå›´
        try:
            ctr.set_constant_z_near(1.0)
            ctr.set_constant_z_far(10000.0)
            print("ğŸ”§ è§†é”¥è£å‰ªèŒƒå›´: near=1mm, far=10000mm")
        except AttributeError:
            # æŸäº›Open3Dç‰ˆæœ¬å¯èƒ½ä¸æ”¯æŒæ­¤æ–¹æ³•
            pass
        
        print("âœ… Open3Då¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        return True
    
    def setup_camera_background(self):
        """è®¾ç½®æ‘„åƒæœºèƒŒæ™¯æ˜¾ç¤º"""
        # åˆ›å»ºèƒŒæ™¯å¹³é¢ï¼ˆç”¨äºæ˜¾ç¤ºæ‘„åƒæœºç”»é¢ï¼‰
        # èƒŒæ™¯å¹³é¢ä½äºæ¨¡å‹åæ–¹ï¼Œå¤§å°åŒ¹é…æ¸²æŸ“è§†å›¾
        background_vertices = np.array([
            [-200, -150, -300],  # å·¦ä¸‹
            [200, -150, -300],   # å³ä¸‹
            [200, 150, -300],    # å³ä¸Š
            [-200, 150, -300]    # å·¦ä¸Š
        ])
        
        background_triangles = np.array([
            [0, 1, 2],  # ç¬¬ä¸€ä¸ªä¸‰è§’å½¢
            [0, 2, 3]   # ç¬¬äºŒä¸ªä¸‰è§’å½¢
        ])
        
        # åˆ›å»ºèƒŒæ™¯ç½‘æ ¼
        self.background_mesh = o3d.geometry.TriangleMesh()
        self.background_mesh.vertices = o3d.utility.Vector3dVector(background_vertices)
        self.background_mesh.triangles = o3d.utility.Vector3iVector(background_triangles)
        self.background_mesh.compute_vertex_normals()
        
        # è®¾ç½®UVåæ ‡ç”¨äºçº¹ç†æ˜ å°„
        uv_coordinates = np.array([
            [0, 0],  # å·¦ä¸‹
            [1, 0],  # å³ä¸‹
            [1, 1],  # å³ä¸Š
            [0, 1]   # å·¦ä¸Š
        ])
        
        # åˆå§‹æ—¶éšè—èƒŒæ™¯
        self.background_mesh.paint_uniform_color([0.1, 0.1, 0.1])  # æ·±ç°è‰²
        
        # æ·»åŠ åˆ°å¯è§†åŒ–å™¨
        self.vis.add_geometry(self.background_mesh)
        
        print("ğŸ“º æ‘„åƒæœºèƒŒæ™¯å¹³é¢å·²åˆ›å»º")
    
    def create_mediapipe_landmarker(self):
        """åˆ›å»ºMediaPipeäººè„¸æ ‡å¿—æ£€æµ‹å™¨"""
        if not self.mp_model_path:
            return None
            
        try:
            options = FaceLandmarkerOptions(
                base_options=BaseOptions(model_asset_path=self.mp_model_path),
                running_mode=VisionRunningMode.VIDEO,
                num_faces=1,
                min_face_detection_confidence=0.5,
                min_face_presence_confidence=0.5,
                min_tracking_confidence=0.5,
                output_face_blendshapes=False,  # æš‚æ—¶ä¸ç”¨blendshapes
                output_facial_transformation_matrixes=True,  # è¾“å‡ºå˜æ¢çŸ©é˜µ
            )
            
            landmarker = FaceLandmarker.create_from_options(options)
            print("âœ… MediaPipeäººè„¸æ£€æµ‹å™¨åˆ›å»ºæˆåŠŸ")
            return landmarker
            
        except Exception as e:
            print(f"âŒ MediaPipeæ£€æµ‹å™¨åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def detection_thread(self):
        """MediaPipeæ£€æµ‹çº¿ç¨‹"""
        print("ğŸ¥ å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹...")
        
        # åˆ›å»ºæ£€æµ‹å™¨
        self.landmarker = self.create_mediapipe_landmarker()
        if not self.landmarker:
            print("âŒ MediaPipeæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥")
            return
        
        # æ‰“å¼€æ‘„åƒå¤´
        cap = cv2.VideoCapture(self.camera_id)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_id}")
            return
        
        # è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨ç‡
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        frame_count = 0
        fps_start_time = time.time()
        
        try:
            while self.is_running:
                ret, frame = cap.read()
                if not ret:
                    continue
                
                frame = cv2.flip(frame, 1)  # é•œåƒç¿»è½¬
                frame_count += 1
                
                # è½¬æ¢ä¸ºRGB
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
                
                # è¿›è¡Œäººè„¸æ£€æµ‹
                timestamp_ms = int(time.time() * 1000)
                detection_result = self.landmarker.detect_for_video(mp_image, timestamp_ms)
                
                # å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
                try:
                    data_packet = {
                        'detection_result': detection_result,
                        'frame': rgb_frame,
                        'timestamp': timestamp_ms
                    }
                    self.data_queue.put_nowait(data_packet)
                except queue.Full:
                    # å¦‚æœé˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒæœ€æ—§çš„æ•°æ®
                    try:
                        self.data_queue.get_nowait()
                        self.data_queue.put_nowait(data_packet)
                    except queue.Empty:
                        pass
                
                # è®¡ç®—æ£€æµ‹FPS
                if frame_count % 30 == 0:
                    elapsed = time.time() - fps_start_time
                    self.current_detection_fps = 30.0 / elapsed
                    fps_start_time = time.time()
                
                # æ§åˆ¶å¸§ç‡
                time.sleep(1.0 / self.fps_target)
                
        except Exception as e:
            print(f"âŒ æ£€æµ‹çº¿ç¨‹é”™è¯¯: {e}")
        finally:
            cap.release()
            print("ğŸ¥ MediaPipeæ£€æµ‹çº¿ç¨‹å·²åœæ­¢")
    
    def update_face_model(self, detection_result):
        """ã€solvePnPæ–¹æ³•ã€‘æ ¹æ®MediaPipeç»“æœæ›´æ–°3Däººè„¸æ¨¡å‹"""
        if not detection_result.face_landmarks:
            return False
        
        # è·å–ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„äººè„¸landmarks
        landmarks = detection_result.face_landmarks[0]
        
        # ã€solvePnPæ ¸å¿ƒã€‘å‡†å¤‡3D-2Då¯¹åº”ç‚¹
        # 1. 2Då›¾åƒç‚¹ï¼šä»MediaPipe landmarksæå–åƒç´ åæ ‡
        img_points = []
        obj_points = []
        
        for idx in self.pnp_indices:
            if idx < len(landmarks) and idx < len(self.original_vertices):
                # MediaPipeè¾“å‡ºçš„åæ ‡æ˜¯[0,1]èŒƒå›´ï¼Œéœ€è¦è½¬æ¢ä¸ºåƒç´ åæ ‡
                x_pixel = landmarks[idx].x * self.render_width
                y_pixel = landmarks[idx].y * self.render_height
                img_points.append([x_pixel, y_pixel])
                
                # å¯¹åº”çš„3Dæ¨¡å‹ç‚¹ï¼ˆAndy_Wah_facemesh.objä¸­çš„é¡¶ç‚¹ï¼‰
                obj_points.append(self.original_vertices[idx])
        
        img_points = np.array(img_points, dtype=np.float32)
        obj_points = np.array(obj_points, dtype=np.float32)
        
        # æ£€æŸ¥ç‚¹æ•°é‡æ˜¯å¦è¶³å¤Ÿ
        if len(img_points) < 8 or len(obj_points) < 8:
            print(f"âš ï¸ solvePnPéœ€è¦è‡³å°‘8ä¸ªå¯¹åº”ç‚¹ï¼Œå½“å‰åªæœ‰{len(img_points)}ä¸ª")
            return False
        
        # ã€å…³é”®æ”¹è¿›ã€‘å¯¹3Dç‚¹è¿›è¡Œé€‚å½“çš„ç¼©æ”¾å’Œè°ƒæ•´
        # Andy_Wah_facemesh.objçš„åæ ‡å¯èƒ½éœ€è¦ç¼©æ”¾åˆ°åˆé€‚çš„çœŸå®ä¸–ç•Œå°ºå¯¸
        # ä¸€èˆ¬äººè„¸å®½åº¦çº¦15-18cmï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿3Dæ¨¡å‹å°ºå¯¸åˆç†
        
        # è®¡ç®—æ¨¡å‹çš„å°ºå¯¸å¹¶è°ƒæ•´åˆ°çœŸå®äººè„¸å°ºå¯¸
        model_bbox = np.array([
            [obj_points[:, 0].min(), obj_points[:, 1].min(), obj_points[:, 2].min()],
            [obj_points[:, 0].max(), obj_points[:, 1].max(), obj_points[:, 2].max()]
        ])
        model_width = model_bbox[1, 0] - model_bbox[0, 0]  # Xæ–¹å‘å®½åº¦
        model_height = model_bbox[1, 1] - model_bbox[0, 1]  # Yæ–¹å‘é«˜åº¦
        
        # ã€é‡è¦ä¿®æ­£ã€‘æ ¹æ®Blenderè°ƒè¯•ç»“æœï¼Œå‡å°ç¼©æ”¾ç³»æ•°
        # ä¹‹å‰160mmå¯¼è‡´11.433xç¼©æ”¾å¤ªå¤§ï¼Œç”¨æˆ·éœ€è¦0.1å€æ‰èƒ½åŒ¹é…
        # æ”¹ä¸ºæ›´å°çš„ç›®æ ‡å°ºå¯¸ï¼Œè®©æ¨¡å‹æ¥è¿‘åŸå§‹å¤§å°
        target_width = 14.0  # æ¯«ç±³ (çº¦ä¸ºåŸå§‹æ¨¡å‹å¤§å°ï¼Œé¿å…è¿‡åº¦ç¼©æ”¾)
        scale_factor = target_width / model_width if model_width > 0 else 1.0
        
        # ç¼©æ”¾3Dç‚¹åˆ°åˆç†çš„çœŸå®ä¸–ç•Œå°ºå¯¸
        obj_points_scaled = obj_points * scale_factor
        
        # ã€è°ƒè¯•ã€‘æ‰“å°å‰å‡ ä¸ªå¯¹åº”ç‚¹çš„åæ ‡ï¼ˆåˆæ¬¡è¿è¡Œæ—¶ï¼‰
        if not hasattr(self, '_debug_points_printed'):
            self._debug_points_printed = True
            print("ğŸ” solvePnPå¯¹åº”ç‚¹æ£€æŸ¥:")
            print(f"   æ¨¡å‹åŸå§‹å°ºå¯¸: å®½{model_width:.2f} é«˜{model_height:.2f}")
            print(f"   ç¼©æ”¾ç³»æ•°: {scale_factor:.3f} (ç›®æ ‡å®½åº¦{target_width}mm)")
            for i in range(min(5, len(img_points))):
                print(f"   ç‚¹{self.pnp_indices[i]}: 3D{obj_points_scaled[i]} -> 2D{img_points[i]}")
        
        # ã€solvePnPæ ¸å¿ƒã€‘æ±‚è§£3Då§¿æ€ï¼ˆæ—‹è½¬å’Œå¹³ç§»ï¼‰
        try:
            # ä½¿ç”¨SOLVEPNP_ITERATIVEç®—æ³•ï¼Œé€šå¸¸æ›´ç¨³å®š
            success, rvec, tvec = cv2.solvePnP(
                obj_points_scaled,  # 3Dç‰©ä½“ç‚¹ï¼ˆç¼©æ”¾åçš„æ¯«ç±³ï¼‰
                img_points,         # 2Då›¾åƒç‚¹ï¼ˆåƒç´ ï¼‰
                self.K,             # ç›¸æœºå†…å‚çŸ©é˜µ
                self.dist,          # ç•¸å˜ç³»æ•°
                flags=cv2.SOLVEPNP_ITERATIVE  # ä½¿ç”¨è¿­ä»£ç®—æ³•
            )
            
            if not success:
                print("âŒ solvePnPæ±‚è§£å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ solvePnPå¼‚å¸¸: {e}")
            return False
        
        # ã€è½¬æ¢ç»“æœã€‘å°†Rodrigueså‘é‡è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
        R, _ = cv2.Rodrigues(rvec)
        T = tvec.reshape(3)
        
        # ã€é‡è¦ä¿®æ­£ã€‘åæ ‡ç³»è½¬æ¢
        # OpenCV/solvePnPåæ ‡ç³»: Xå‘å³ï¼ŒYå‘ä¸‹ï¼ŒZå‘å‰ï¼ˆè¿œç¦»ç›¸æœºï¼‰
        # Open3Dæ¸²æŸ“åæ ‡ç³»: Xå‘å³ï¼ŒYå‘ä¸Šï¼ŒZå‘å¤–ï¼ˆæœå‘ç”¨æˆ·ï¼‰
        # éœ€è¦è¿›è¡ŒYè½´å’ŒZè½´ç¿»è½¬
        
        # ä¿®æ­£æ—‹è½¬çŸ©é˜µï¼ˆYè½´å’ŒZè½´ç¿»è½¬ï¼‰
        flip_matrix = np.array([
            [1,  0,  0],
            [0, -1,  0],
            [0,  0, -1]
        ], dtype=np.float32)
        
        R_corrected = flip_matrix @ R
        T_corrected = flip_matrix @ T
        
        # ã€åº”ç”¨å˜æ¢ã€‘å°†æ—‹è½¬å’Œå¹³ç§»åº”ç”¨åˆ°æ‰€æœ‰é¡¶ç‚¹
        # ä½¿ç”¨å®Œæ•´æ¨¡å‹çš„åŸå§‹é¡¶ç‚¹è¿›è¡Œå˜æ¢
        if hasattr(self, 'original_full_vertices'):
            # ä½¿ç”¨å®Œæ•´æ¨¡å‹çš„åŸå§‹é¡¶ç‚¹è¿›è¡Œå˜æ¢
            full_vertices_scaled = self.original_full_vertices * scale_factor
            # åº”ç”¨æ—‹è½¬å’Œå¹³ç§»ï¼šR @ vertices.T + T
            transformed_vertices = (R_corrected @ full_vertices_scaled.T).T + T_corrected
        else:
            # å›é€€åˆ°ä½¿ç”¨å‰468ä¸ªé¡¶ç‚¹
            all_vertices_scaled = self.original_vertices * scale_factor
            transformed_vertices = (R_corrected @ all_vertices_scaled.T).T + T_corrected
        
        # ã€ç”¨æˆ·æ§åˆ¶å‚æ•°ã€‘åº”ç”¨å¾®è°ƒ
        final_vertices = transformed_vertices.copy()
        
        if self.coordinate_system_flip_z:
            # å¦‚æœç”¨æˆ·éœ€è¦é¢å¤–ç¿»è½¬Zè½´
            final_vertices[:, 2] = -final_vertices[:, 2]
        
        # åº”ç”¨ç¼©æ”¾
        if self.ar_scale_factor != 1.0:
            center = np.mean(final_vertices, axis=0)
            final_vertices = center + (final_vertices - center) * self.ar_scale_factor
        
        # åº”ç”¨åç§»
        final_vertices[:, 0] += self.ar_offset_x
        final_vertices[:, 1] += self.ar_offset_y
        final_vertices[:, 2] += self.ar_offset_z
        
        # ä¿æŒå½“å‰å•ä½ï¼ˆæ¯«ç±³ï¼‰ï¼Œä¸åŸå§‹æ¨¡å‹ä¿æŒä¸€è‡´
        self.face_mesh.vertices = o3d.utility.Vector3dVector(final_vertices)
        self.face_mesh.compute_vertex_normals()
        
        # ã€è°ƒè¯•ä¿¡æ¯ã€‘æ¯10å¸§è¾“å‡ºä¸€æ¬¡
        if not hasattr(self, '_solvepnp_frame_count'):
            self._solvepnp_frame_count = 0
        self._solvepnp_frame_count += 1
        
        if self.debug_mode and self._solvepnp_frame_count % 10 == 0:
            print(f"ğŸ¯ solvePnPç»“æœ (ç¬¬{self._solvepnp_frame_count}å¸§):")
            print(f"   åŸå§‹å¹³ç§»: T=[{T[0]:.1f}, {T[1]:.1f}, {T[2]:.1f}] mm")
            print(f"   ä¿®æ­£å¹³ç§»: T_corrected=[{T_corrected[0]:.1f}, {T_corrected[1]:.1f}, {T_corrected[2]:.1f}] mm")
            print(f"   æ—‹è½¬å‘é‡: rvec={rvec.ravel()}")
            print(f"   æ¨¡å‹ç¼©æ”¾: {scale_factor:.3f}x (ç›®æ ‡çœŸå®å°ºå¯¸)")
            
            center = np.mean(final_vertices, axis=0)
            z_range = (final_vertices[:, 2].min(), final_vertices[:, 2].max())
            print(f"   æœ€ç»ˆæ¨¡å‹ä¸­å¿ƒ: [{center[0]:.1f}, {center[1]:.1f}, {center[2]:.1f}]")
            print(f"   æœ€ç»ˆZæ·±åº¦èŒƒå›´: [{z_range[0]:.1f}, {z_range[1]:.1f}]")
            
            # è®¡ç®—é‡æŠ•å½±è¯¯å·®ï¼ˆè´¨é‡æ£€æŸ¥ï¼‰
            try:
                reproj_points, _ = cv2.projectPoints(obj_points_scaled, rvec, tvec, self.K, self.dist)
                reproj_points = reproj_points.reshape(-1, 2)
                reproj_error = np.mean(np.linalg.norm(img_points - reproj_points, axis=1))
                print(f"   é‡æŠ•å½±è¯¯å·®: {reproj_error:.2f} åƒç´ ")
                
                # ä¼˜åŒ–é‡æŠ•å½±è¯¯å·®è¯„åˆ¤æ ‡å‡†
                if reproj_error > 20:
                    print("âš ï¸ é‡æŠ•å½±è¯¯å·®åå¤§ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´æ¨¡å‹æˆ–æ ‡å®š")
                elif reproj_error < 10:
                    print("âœ… é‡æŠ•å½±è¯¯å·®è‰¯å¥½")
                    
            except Exception as e:
                print(f"âš ï¸ é‡æŠ•å½±è¯¯å·®è®¡ç®—å¤±è´¥: {e}")
        
        return True
    
    def update_face_model_fallback(self, detection_result):
        """ã€å›é€€æ–¹æ³•ã€‘ä½¿ç”¨MediaPipeçš„facial_transformation_matrixï¼ˆç”¨äºè°ƒè¯•å¯¹æ¯”ï¼‰"""
        if not detection_result.face_landmarks:
            return False
        
        # ä½¿ç”¨MediaPipeçš„facial_transformation_matrixè¿›è¡ŒARè·Ÿè¸ª
        if (detection_result.facial_transformation_matrixes and 
            len(detection_result.facial_transformation_matrixes) > 0):
            
            # è·å–4Ã—4é¢éƒ¨å˜æ¢çŸ©é˜µ
            facial_transform_matrix = np.array(detection_result.facial_transformation_matrixes[0])
            
            if self.debug_mode:
                print(f"ğŸ”„ å›é€€æ–¹æ³• - é¢éƒ¨å˜æ¢çŸ©é˜µ:")
                print(f"   å¹³ç§»: [{facial_transform_matrix[0,3]:.2f}, {facial_transform_matrix[1,3]:.2f}, {facial_transform_matrix[2,3]:.2f}]")
            
            # è·å–åŸå§‹æ¨¡å‹é¡¶ç‚¹
            original_vertices = self.original_vertices.copy()
            
            # å°†é¡¶ç‚¹è½¬æ¢ä¸ºé½æ¬¡åæ ‡
            num_vertices = len(original_vertices)
            vertices_homogeneous = np.hstack([original_vertices, np.ones((num_vertices, 1))])
            
            # åº”ç”¨å˜æ¢çŸ©é˜µ
            transformed_vertices_homogeneous = (facial_transform_matrix @ vertices_homogeneous.T).T
            transformed_vertices = transformed_vertices_homogeneous[:, :3]
            
            # åº”ç”¨ç”¨æˆ·æ§åˆ¶å‚æ•°
            final_vertices = transformed_vertices.copy()
            
            if self.coordinate_system_flip_z:
                final_vertices[:, 2] = -final_vertices[:, 2]
            
            if self.ar_scale_factor != 1.0:
                center = np.mean(final_vertices, axis=0)
                final_vertices = center + (final_vertices - center) * self.ar_scale_factor
            
            final_vertices[:, 0] += self.ar_offset_x
            final_vertices[:, 1] += self.ar_offset_y
            final_vertices[:, 2] += self.ar_offset_z
            
            # ä¿æŒå½“å‰å•ä½ï¼ˆæ¯«ç±³ï¼‰ï¼Œä¸åŸå§‹æ¨¡å‹ä¿æŒä¸€è‡´
            self.face_mesh.vertices = o3d.utility.Vector3dVector(final_vertices)
            self.face_mesh.compute_vertex_normals()
            
            return True
        
        return False
    
    def update_camera_background(self, frame):
        """æ›´æ–°æ‘„åƒæœºèƒŒæ™¯æ˜¾ç¤º"""
        if frame is None:
            return
            
        # ä¿å­˜æœ€æ–°å¸§ç”¨äºæ˜¾ç¤º
        self.latest_camera_frame = frame.copy()
        
        try:
            if self.show_camera_background:
                # æ–¹æ¡ˆ1ï¼šåœ¨ç‹¬ç«‹çš„OpenCVçª—å£ä¸­æ˜¾ç¤ºæ‘„åƒæœºç”»é¢
                # åˆ›å»ºARåˆæˆè§†å›¾
                display_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                
                # æ·»åŠ ARä¿¡æ¯å åŠ 
                overlay_text = "AR Background - Live Camera"
                cv2.putText(display_frame, overlay_text, (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                # æ˜¾ç¤ºæ‘„åƒæœºèƒŒæ™¯çª—å£
                cv2.namedWindow("Camera Background", cv2.WINDOW_NORMAL)
                cv2.resizeWindow("Camera Background", 640, 480)
                cv2.imshow("Camera Background", display_frame)
                
                # æ–¹æ¡ˆ2ï¼šåŒæ—¶å°è¯•æ”¹è¿›3DèƒŒæ™¯å¹³é¢çš„æ˜¾ç¤º
                if hasattr(self, 'background_mesh'):
                    # ä½¿ç”¨å›¾åƒçš„æ•´ä½“äº®åº¦æ¥è°ƒæ•´èƒŒæ™¯å¹³é¢
                    avg_brightness = np.mean(frame) / 255.0
                    
                    # æ ¹æ®æ‘„åƒæœºç”»é¢è°ƒæ•´èƒŒæ™¯è‰²
                    # å–ä¸åŒåŒºåŸŸçš„é¢œè‰²
                    h, w = frame.shape[:2]
                    
                    # æ›´å¯†é›†çš„é‡‡æ ·ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœ
                    sample_points = [
                        (h//4, w//4),     # å·¦ä¸Š
                        (h//4, 3*w//4),   # å³ä¸Š
                        (3*h//4, 3*w//4), # å³ä¸‹
                        (3*h//4, w//4)    # å·¦ä¸‹
                    ]
                    
                    colors = []
                    for y, x in sample_points:
                        pixel_color = frame[y, x] / 255.0
                        # å¢å¼ºé¢œè‰²é¥±å’Œåº¦ä»¥ä¾¿æ›´å¥½åœ°æ˜¾ç¤º
                        pixel_color = pixel_color * 1.5
                        pixel_color = np.clip(pixel_color, 0, 1)
                        colors.append(pixel_color)
                    
                    # è®¾ç½®é¡¶ç‚¹é¢œè‰²
                    self.background_mesh.vertex_colors = o3d.utility.Vector3dVector(colors)
                    
                                    # æ›´æ–°å¯è§†åŒ–å™¨ä¸­çš„èƒŒæ™¯
                self.vis.update_geometry(self.background_mesh)
                    
        except Exception as e:
            print(f"âš ï¸ èƒŒæ™¯æ›´æ–°å¤±è´¥: {e}")
    
    def toggle_camera_background(self):
        """åˆ‡æ¢æ‘„åƒæœºèƒŒæ™¯æ˜¾ç¤º"""
        self.show_camera_background = not self.show_camera_background
        
        if self.show_camera_background:
            print("ğŸ“º æ‘„åƒæœºèƒŒæ™¯å·²å¼€å¯ - ARæ¨¡å¼")
            # æ˜¾ç¤ºæœ€æ–°çš„æ‘„åƒæœºç”»é¢ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if self.latest_camera_frame is not None:
                self.update_camera_background(self.latest_camera_frame)
        else:
            print("ğŸ­ æ‘„åƒæœºèƒŒæ™¯å·²å…³é—­ - çº¯3Dæ¨¡å¼") 
            # å…³é—­æ‘„åƒæœºèƒŒæ™¯çª—å£
            try:
                cv2.destroyWindow("Camera Background")
            except:
                pass
            
            # éšè—èƒŒæ™¯å¹³é¢
            if hasattr(self, 'background_mesh'):
                self.background_mesh.paint_uniform_color([0.1, 0.1, 0.1])  # æ·±ç°è‰²
                self.vis.update_geometry(self.background_mesh)
    
    def export_current_model(self):
        """å¯¼å‡ºå½“å‰å˜æ¢åçš„3Dæ¨¡å‹åˆ°OBJæ–‡ä»¶"""
        try:
            if not hasattr(self.face_mesh, 'vertices') or len(self.face_mesh.vertices) == 0:
                print("âŒ æ— å½“å‰3Dæ¨¡å‹å¯å¯¼å‡º")
                return False
            
            # è·å–å½“å‰å˜æ¢åçš„é¡¶ç‚¹
            current_vertices = np.asarray(self.face_mesh.vertices)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"output_realtime_model_{timestamp}.obj"
            
            # ç¡®ä¿outputæ–‡ä»¶å¤¹å­˜åœ¨
            output_dir = "output"
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            
            filepath = os.path.join(output_dir, filename)
            
            # å†™å…¥OBJæ–‡ä»¶
            with open(filepath, 'w') as f:
                # å†™å…¥æ–‡ä»¶å¤´ä¿¡æ¯
                f.write(f"# FaceMatrixLab å®æ—¶3Däººè„¸æ¨¡å‹å¯¼å‡º\n")
                f.write(f"# å¯¼å‡ºæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# åŸºäºæ¨¡å‹: {self.model_path}\n")
                f.write(f"# å˜æ¢æ–¹æ³•: {'solvePnP' if not self.fallback_to_matrix else 'MediaPipe transformation matrix'}\n")
                f.write(f"# æ€»é¡¶ç‚¹æ•°: {len(current_vertices)}\n")
                f.write(f"# æ¨¡å‹å‚æ•°:\n")
                f.write(f"#   ç¼©æ”¾: {self.ar_scale_factor:.3f}x\n")
                f.write(f"#   åç§»: X={self.ar_offset_x:.1f}, Y={self.ar_offset_y:.1f}, Z={self.ar_offset_z:.1f}\n")
                f.write(f"#   Zè½´ç¿»è½¬: {'æ˜¯' if self.coordinate_system_flip_z else 'å¦'}\n")
                f.write("\n")
                
                # å†™å…¥é¡¶ç‚¹æ•°æ®
                for i, vertex in enumerate(current_vertices):
                    f.write(f"v {vertex[0]:.6f} {vertex[1]:.6f} {vertex[2]:.6f}\n")
                
                # å¦‚æœåŸå§‹æ¨¡å‹æœ‰é¢ä¿¡æ¯ï¼Œä¹Ÿå†™å…¥é¢ä¿¡æ¯
                if hasattr(self.face_mesh, 'triangles') and len(self.face_mesh.triangles) > 0:
                    f.write("\n# é¢ä¿¡æ¯\n")
                    triangles = np.asarray(self.face_mesh.triangles)
                    for triangle in triangles:
                        # OBJæ–‡ä»¶çš„é¡¶ç‚¹ç´¢å¼•ä»1å¼€å§‹
                        f.write(f"f {triangle[0]+1} {triangle[1]+1} {triangle[2]+1}\n")
            
            # ç»Ÿè®¡ä¿¡æ¯
            bbox_min = current_vertices.min(axis=0)
            bbox_max = current_vertices.max(axis=0)
            bbox_size = bbox_max - bbox_min
            
            print(f"âœ… å®æ—¶3Dæ¨¡å‹å·²å¯¼å‡º: {filepath}")
            print(f"ğŸ“Š æ¨¡å‹ç»Ÿè®¡:")
            print(f"   é¡¶ç‚¹æ•°: {len(current_vertices)}")
            print(f"   é¢æ•°: {len(self.face_mesh.triangles) if hasattr(self.face_mesh, 'triangles') else 0}")
            print(f"   åŒ…å›´ç›’å°ºå¯¸: {bbox_size[0]:.2f} x {bbox_size[1]:.2f} x {bbox_size[2]:.2f} mm")
            print(f"   ä¸­å¿ƒä½ç½®: ({np.mean(current_vertices, axis=0)[0]:.2f}, {np.mean(current_vertices, axis=0)[1]:.2f}, {np.mean(current_vertices, axis=0)[2]:.2f}) mm")
            print(f"ğŸ’¡ åœ¨Blenderä¸­ä¸åŸå§‹æ¨¡å‹ {self.model_path} æ¯”è¾ƒ:")
            print(f"   1. å¯¼å…¥åŸå§‹æ¨¡å‹: {self.model_path}")
            print(f"   2. å¯¼å…¥å®æ—¶æ¨¡å‹: {filepath}")
            print(f"   3. æŸ¥çœ‹ä¸¤ä¸ªæ¨¡å‹çš„ç›¸å¯¹ä½ç½®å’Œå˜æ¢çŠ¶æ€")
            
            return True
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºæ¨¡å‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def run_with_visualizer(self):
        """ä½¿ç”¨Open3Déšè—çª—å£æ¸²æŸ“å¹¶åˆæˆARè§†å›¾"""
        if not self.setup_visualizer():
            print("âŒ å¯è§†åŒ–å™¨åˆå§‹åŒ–å¤±è´¥")
            return
            
        cv2.namedWindow("AR View", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("AR View", self.render_width, self.render_height)
        
        try:
            while self.is_running:
                # è¯»å–æœ€æ–°æ•°æ®
                frame = None
                try:
                    pkt = self.data_queue.get_nowait()
                    detection_result = pkt['detection_result']
                    frame = pkt.get('frame')
                except queue.Empty:
                    detection_result = None
                
                # æ›´æ–°3Dæ¨¡å‹ - å¯ä»¥åœ¨solvePnPå’Œå›é€€æ–¹æ³•ä¹‹é—´åˆ‡æ¢
                model_updated = False
                if detection_result:
                    if self.fallback_to_matrix:
                        # ä½¿ç”¨å›é€€æ–¹æ³•ï¼ˆMediaPipe transformation matrixï¼‰
                        model_updated = self.update_face_model_fallback(detection_result)
                    else:
                        # ä½¿ç”¨solvePnPæ–¹æ³•
                        model_updated = self.update_face_model(detection_result)
                
                if model_updated:
                    self.vis.update_geometry(self.face_mesh)
                
                # ç¦»å±æ¸²æŸ“è·å–å›¾åƒ
                self.vis.poll_events()
                self.vis.update_renderer()
                img_3d = np.asarray(self.vis.capture_screen_float_buffer(False))
                img_3d = (img_3d * 255).astype(np.uint8)
                img_3d_bgr = cv2.cvtColor(img_3d, cv2.COLOR_RGB2BGR)
                
                # æ‘„åƒæœºèƒŒæ™¯
                if self.show_camera_background and frame is not None:
                    bg = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    bg = cv2.resize(bg, (self.render_width, self.render_height))
                else:
                    bg = np.zeros_like(img_3d_bgr)
                
                # ARåˆæˆï¼šå°†3Dæ¨¡å‹å åŠ åˆ°èƒŒæ™¯ä¸Š
                # åˆ›å»ºæ©ç ï¼šéé»‘è‰²åƒç´ çš„åŒºåŸŸ
                mask = img_3d_bgr.sum(axis=2) > 30
                composite = bg.copy()
                composite[mask] = img_3d_bgr[mask]
                
                # æ˜¾ç¤ºåˆæˆç»“æœ
                cv2.imshow("AR View", composite)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('o'):
                    self.toggle_camera_background()
                elif key == ord('q') or key == 27:  # Qé”®æˆ–ESCé”®ï¼šé€€å‡º
                    break
                elif key == ord('f') or key == ord('F'):  # Fé”®ï¼šåˆ‡æ¢Zè½´ç¿»è½¬
                    self.coordinate_system_flip_z = not self.coordinate_system_flip_z
                    print(f"ğŸ”„ Zè½´ç¿»è½¬: {'å¼€å¯' if self.coordinate_system_flip_z else 'å…³é—­'}")
                elif key == ord('+') or key == ord('='):  # +é”®ï¼šæ”¾å¤§ARæ¨¡å‹
                    self.ar_scale_factor = min(5.0, self.ar_scale_factor + 0.1)
                    print(f"ğŸ“ ARæ¨¡å‹ç¼©æ”¾: {self.ar_scale_factor:.1f}x")
                elif key == ord('-') or key == ord('_'):  # -é”®ï¼šç¼©å°ARæ¨¡å‹
                    self.ar_scale_factor = max(0.1, self.ar_scale_factor - 0.1)
                    print(f"ğŸ“ ARæ¨¡å‹ç¼©æ”¾: {self.ar_scale_factor:.1f}x")
                elif key == 82:  # ä¸Šç®­å¤´ï¼šYè½´æ­£å‘åç§»
                    self.ar_offset_y -= 5.0
                    print(f"ğŸ“ ARæ¨¡å‹Yåç§»: {self.ar_offset_y:.1f}")
                elif key == 84:  # ä¸‹ç®­å¤´ï¼šYè½´è´Ÿå‘åç§»
                    self.ar_offset_y += 5.0
                    print(f"ğŸ“ ARæ¨¡å‹Yåç§»: {self.ar_offset_y:.1f}")
                elif key == 81:  # å·¦ç®­å¤´ï¼šXè½´è´Ÿå‘åç§»
                    self.ar_offset_x -= 5.0
                    print(f"ğŸ“ ARæ¨¡å‹Xåç§»: {self.ar_offset_x:.1f}")
                elif key == 83:  # å³ç®­å¤´ï¼šXè½´æ­£å‘åç§»
                    self.ar_offset_x += 5.0
                    print(f"ğŸ“ ARæ¨¡å‹Xåç§»: {self.ar_offset_x:.1f}")
                elif key == 85:  # Page Upï¼šZè½´å‰ç§»
                    self.ar_offset_z -= 10.0
                    print(f"ğŸ“ ARæ¨¡å‹Zåç§»: {self.ar_offset_z:.1f}")
                elif key == 86:  # Page Downï¼šZè½´åç§»
                    self.ar_offset_z += 10.0
                    print(f"ğŸ“ ARæ¨¡å‹Zåç§»: {self.ar_offset_z:.1f}")
                elif key == ord('m') or key == ord('M'):  # Mé”®ï¼šåˆ‡æ¢è·Ÿè¸ªæ–¹æ³•
                    self.fallback_to_matrix = not self.fallback_to_matrix
                    method_name = "MediaPipe transformation matrix" if self.fallback_to_matrix else "solvePnP"
                    print(f"ğŸ”„ åˆ‡æ¢è·Ÿè¸ªæ–¹æ³•: {method_name}")
                elif key == ord('d') or key == ord('D'):  # Dé”®ï¼šåˆ‡æ¢è°ƒè¯•æ¨¡å¼
                    self.debug_mode = not self.debug_mode
                    print(f"ğŸ› è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if self.debug_mode else 'å…³é—­'}")
                elif key == ord('e') or key == ord('E'):  # Eé”®ï¼šå¯¼å‡ºå½“å‰3Dæ¨¡å‹
                    print("ğŸ“¤ å¯¼å‡ºå½“å‰å®æ—¶3Dæ¨¡å‹...")
                    self.export_current_model()
                elif key == ord('r') or key == ord('R'):  # Ré”®ï¼šé‡ç½®æ‰€æœ‰å‚æ•°
                    self.ar_scale_factor = 1.0
                    self.ar_offset_x = 0.0
                    self.ar_offset_y = 0.0
                    self.ar_offset_z = 0.0
                    self.coordinate_system_flip_z = False
                    print("ğŸ”„ æ‰€æœ‰ARå‚æ•°å·²é‡ç½®")
                elif key == ord('s') or key == ord('S'):  # Sé”®ï¼šæ˜¾ç¤ºå½“å‰å‚æ•°çŠ¶æ€
                    print("ğŸ“Š å½“å‰ARå‚æ•°çŠ¶æ€:")
                    print(f"   ç¼©æ”¾: {self.ar_scale_factor:.2f}x")
                    print(f"   åç§»: X={self.ar_offset_x:.1f}, Y={self.ar_offset_y:.1f}, Z={self.ar_offset_z:.1f}")
                    print(f"   Zè½´ç¿»è½¬: {'æ˜¯' if self.coordinate_system_flip_z else 'å¦'}")
                    print(f"   è·Ÿè¸ªæ–¹æ³•: {'MediaPipe transformation matrix' if self.fallback_to_matrix else 'solvePnP'}")
                elif key == ord('['):  # [é”®ï¼šå¤§å¹…ç¼©å°æ¨¡å‹ï¼ˆ0.1å€ï¼‰
                    self.ar_scale_factor = max(0.01, self.ar_scale_factor * 0.1)
                    print(f"ğŸ“ æ¨¡å‹å¤§å¹…ç¼©å°: {self.ar_scale_factor:.3f}x")
                elif key == ord(']'):  # ]é”®ï¼šå¤§å¹…æ”¾å¤§æ¨¡å‹ï¼ˆ10å€ï¼‰
                    self.ar_scale_factor = min(100.0, self.ar_scale_factor * 10.0)
                    print(f"ğŸ“ æ¨¡å‹å¤§å¹…æ”¾å¤§: {self.ar_scale_factor:.3f}x")
                    
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
        finally:
            self.vis.destroy_window()
            cv2.destroyAllWindows()
    
    def run(self):
        """å¯åŠ¨æ¸²æŸ“å™¨"""
        print("\nå¯åŠ¨FaceMatrixLab 3Dæ¸²æŸ“å™¨ï¼ˆARå¢å¼ºç°å®ç‰ˆæœ¬ï¼‰")
        print("=" * 60)
        print("ğŸ“· ç›¸æœºç³»ç»Ÿ:")
        if self.use_solvepnp and self.K is not None:
            print("  âœ… ä½¿ç”¨solvePnP + çœŸå®ç›¸æœºæ ‡å®šå‚æ•°")
            print(f"  ğŸ“‚ æ ‡å®šæ–‡ä»¶: {self.calibration_file}")
            print("  ğŸ¯ å°†è¿›è¡Œç²¾ç¡®çš„3Då§¿æ€ä¼°è®¡")
        else:
            print("  âš ï¸ ä½¿ç”¨ä¼°è®¡ç›¸æœºå‚æ•°ï¼ˆ50mmç­‰æ•ˆç„¦è·ï¼‰")
            print("  ğŸ’¡ å¦‚éœ€ç²¾ç¡®æ¸²æŸ“ï¼Œè¯·è¿è¡Œ: python calibrate_cam.py")
        print("=" * 60)
        print("æ§åˆ¶è¯´æ˜:")
        print("  Oé”®: åˆ‡æ¢æ‘„åƒæœºèƒŒæ™¯æ˜¾ç¤ºï¼ˆARæ¨¡å¼ / çº¯3Dæ¨¡å¼ï¼‰")
        print("  Qé”®: é€€å‡ºç¨‹åº")
        print("  å›ºå®šè§†è§’æ˜¾ç¤ºï¼Œ3Dæ¨¡å‹å åŠ åœ¨çœŸå®æ‘„åƒæœºç”»é¢ä¸Š")
        print("  ã€ARè·Ÿè¸ªæ§åˆ¶ã€‘:")
        print("  Mé”®: åˆ‡æ¢è·Ÿè¸ªæ–¹æ³•ï¼ˆsolvePnP â‡„ transformation matrixï¼‰")
        print("  Dé”®: åˆ‡æ¢è°ƒè¯•æ¨¡å¼ï¼ˆæ˜¾ç¤º/éšè—è¯¦ç»†ä¿¡æ¯ï¼‰")
        print("  Eé”®: å¯¼å‡ºå½“å‰å®æ—¶3Dæ¨¡å‹åˆ°output/æ–‡ä»¶å¤¹ï¼ˆç”¨äºBlenderè°ƒè¯•ï¼‰")
        print("  Fé”®: åˆ‡æ¢Zè½´ç¿»è½¬ï¼ˆè§£å†³åæ ‡ç³»ä¸åŒ¹é…é—®é¢˜ï¼‰")
        print("  ã€æ¨¡å‹ç¼©æ”¾æ§åˆ¶ã€‘:")
        print("  +/-é”®: ç»†å¾®è°ƒæ•´ç¼©æ”¾ï¼ˆÂ±0.1å€ï¼‰")
        print("  [/]é”®: å¤§å¹…è°ƒæ•´ç¼©æ”¾ï¼ˆÃ·10å€/Ã—10å€ï¼‰")
        print("  ã€ä½ç½®æ§åˆ¶ã€‘:")
        print("  æ–¹å‘é”®: è°ƒæ•´ARæ¨¡å‹ä½ç½®åç§»")
        print("    â†‘â†“: Yè½´åç§»    â†â†’: Xè½´åç§»")
        print("  PgUp/PgDn: Zè½´åç§»ï¼ˆå‰åç§»åŠ¨ï¼‰")
        print("  ã€å®ç”¨åŠŸèƒ½ã€‘:")
        print("  Ré”®: é‡ç½®æ‰€æœ‰ARå‚æ•°åˆ°é»˜è®¤å€¼")
        print("  Sé”®: æ˜¾ç¤ºå½“å‰ARå‚æ•°çŠ¶æ€")
        print("=" * 60)
        
        self.is_running = True
        
        # å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹
        detection_thread = threading.Thread(target=self.detection_thread, daemon=True)
        detection_thread.start()
        
        # ç­‰å¾…æ£€æµ‹çº¿ç¨‹å¯åŠ¨
        time.sleep(2)
        
        try:
            # è¿è¡Œå¯è§†åŒ–å™¨
            self.run_with_visualizer()
        finally:
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹ æ¸…ç†èµ„æº...")
        self.is_running = False
        print("âœ… èµ„æºæ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    print("FaceMatrixLab 3D äººè„¸æ¸²æŸ“å™¨ï¼ˆsolvePnPç²¾ç¡®ARç‰ˆæœ¬ï¼‰")
    print("ä½¿ç”¨MediaPipe + solvePnP + Open3Då®ç°ç²¾ç¡®3Däººè„¸è¿½è¸ªæ¸²æŸ“")
    print("é€šè¿‡ç›¸æœºæ ‡å®šå’ŒsolvePnPç®—æ³•ï¼Œå®ç°æ¯«ç±³çº§ç²¾åº¦çš„ARå åŠ æ•ˆæœ")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = "obj/Andy_Wah_facemesh.obj"
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {model_path}")
        print("è¯·ç¡®ä¿Andy_Wah_facemesh.objæ–‡ä»¶ä½äº obj/ ç›®å½•ä¸­")
        return
    
    # æ£€æŸ¥ç›¸æœºæ ‡å®šæ–‡ä»¶ï¼ˆé‡è¦ï¼‰
    calibration_path = "calib.npz"
    if os.path.exists(calibration_path):
        print(f"âœ… å‘ç°ç›¸æœºæ ‡å®šæ–‡ä»¶ï¼š{calibration_path}")
        print("å°†ä½¿ç”¨solvePnPè¿›è¡Œç²¾ç¡®3Då§¿æ€ä¼°è®¡")
        
        # æ˜¾ç¤ºæ ‡å®šä¿¡æ¯
        try:
            calib_data = np.load(calibration_path)
            if 'mean_error' in calib_data:
                print(f"ğŸ“Š æ ‡å®šç²¾åº¦: {calib_data['mean_error']:.3f} åƒç´ ")
        except:
            pass
    else:
        print(f"âš ï¸ æœªå‘ç°ç›¸æœºæ ‡å®šæ–‡ä»¶ï¼š{calibration_path}")
        print("å°†ä½¿ç”¨ä¼°è®¡å‚æ•°ï¼Œç²¾åº¦æœ‰é™")
        print("ğŸ’¡ å¼ºçƒˆå»ºè®®å…ˆè¿è¡Œ: python calibrate_cam.py è¿›è¡Œç›¸æœºæ ‡å®š")
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œæ¸²æŸ“å™¨
        renderer = FaceMatrixLabRenderer(camera_id=0, model_path=model_path)
        renderer.run()
        
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print("ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()
