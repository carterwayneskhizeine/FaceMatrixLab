#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FaceMatrixLab 3D æ¸²æŸ“å™¨
ä½¿ç”¨ Open3D æ¸²æŸ“ Andy_Wah_facemesh.objï¼Œé€šè¿‡ MediaPipe æ•°æ®æµé©±åŠ¨
æ”¯æŒå®æ—¶äººè„¸å§¿æ€å’Œè¡¨æƒ…å˜åŒ–
"""

import cv2
import mediapipe as mp
import numpy as np
import time
import os
import threading
import queue
from typing import Optional, Tuple
import open3d as o3d

# MediaPipe å¯¼å…¥
BaseOptions = mp.tasks.BaseOptions
FaceLandmarker = mp.tasks.vision.FaceLandmarker
FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
FaceLandmarkerResult = mp.tasks.vision.FaceLandmarkerResult
VisionRunningMode = mp.tasks.vision.RunningMode


class FaceMatrixLabRenderer:
    def __init__(self, camera_id=0, model_path="../obj/Andy_Wah_facemesh.obj"):
        """åˆå§‹åŒ–3Däººè„¸æ¸²æŸ“å™¨"""
        print("=== FaceMatrixLab 3D æ¸²æŸ“å™¨åˆå§‹åŒ– ===")
        
        # åŸºæœ¬å‚æ•°
        self.camera_id = camera_id
        self.model_path = model_path
        self.is_running = False
        
        # æ¸²æŸ“å‚æ•°
        self.render_width = 1280
        self.render_height = 720
        self.fps_target = 30
        
        # MediaPipe ç›¸å…³
        self.landmarker = None
        self.mp_model_path = self.download_mediapipe_model()
        
        # æ•°æ®é˜Ÿåˆ— - ç”¨äºçº¿ç¨‹é—´é€šä¿¡
        self.data_queue = queue.Queue(maxsize=5)
        self.latest_result = None
        
        # ç›¸æœºå‚æ•°ï¼ˆ50mm ç­‰æ•ˆç„¦è·ï¼‰
        self.setup_camera_parameters()
        
        # åŠ è½½3Dæ¨¡å‹
        if not self.load_face_model():
            raise Exception("æ— æ³•åŠ è½½3Dæ¨¡å‹æ–‡ä»¶")
        
        # æ€§èƒ½ç»Ÿè®¡
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.current_render_fps = 0
        self.current_detection_fps = 0
        
        print("âœ… FaceMatrixLab 3D æ¸²æŸ“å™¨åˆå§‹åŒ–å®Œæˆ")
        
    def download_mediapipe_model(self):
        """ä¸‹è½½MediaPipeäººè„¸æ ‡å¿—æ£€æµ‹æ¨¡å‹"""
        model_url = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
        model_path = "face_landmarker.task"
        
        if not os.path.exists(model_path):
            print("æ­£åœ¨ä¸‹è½½MediaPipeæ¨¡å‹...")
            try:
                import urllib.request
                urllib.request.urlretrieve(model_url, model_path)
                print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_path}")
            except Exception as e:
                print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
                return None
        else:
            print(f"âœ… MediaPipeæ¨¡å‹å·²å­˜åœ¨: {model_path}")
        
        return model_path
    
    def setup_camera_parameters(self):
        """è®¾ç½®ç›¸æœºå‚æ•°ï¼ˆ50mmç­‰æ•ˆç„¦è·ï¼‰"""
        # 50mm ç­‰æ•ˆç„¦è·å‚æ•°
        f_mm = 50.0  # ç„¦è·(mm)
        sensor_width_mm = 36.0  # å…¨ç”»å¹…ä¼ æ„Ÿå™¨å®½åº¦(mm)
        
        # è®¡ç®—åƒç´ ç„¦è·
        self.fx = (f_mm / sensor_width_mm) * self.render_width
        self.fy = (f_mm / sensor_width_mm) * self.render_height  # å‡è®¾æ­£æ–¹å½¢åƒç´ 
        self.cx = self.render_width / 2.0
        self.cy = self.render_height / 2.0
        
        print(f"ğŸ“· ç›¸æœºå‚æ•°è®¾ç½®:")
        print(f"   åˆ†è¾¨ç‡: {self.render_width}x{self.render_height}")
        print(f"   ç„¦è·: fx={self.fx:.2f}, fy={self.fy:.2f}")
        print(f"   ä¸»ç‚¹: cx={self.cx:.2f}, cy={self.cy:.2f}")
        
        # åˆ›å»ºOpen3Dç›¸æœºå†…å‚
        self.intrinsic = o3d.camera.PinholeCameraIntrinsic(
            self.render_width, self.render_height, 
            self.fx, self.fy, self.cx, self.cy
        )
    
    def load_face_model(self):
        """åŠ è½½3Däººè„¸æ¨¡å‹"""
        if not os.path.exists(self.model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            return False
            
        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½3Dæ¨¡å‹: {self.model_path}")
        
        try:
            # åŠ è½½æ¨¡å‹
            self.face_mesh = o3d.io.read_triangle_mesh(self.model_path)
            
            if len(self.face_mesh.vertices) == 0:
                print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼šæ²¡æœ‰é¡¶ç‚¹æ•°æ®")
                return False
            
            # è®¡ç®—æ³•çº¿
            self.face_mesh.compute_vertex_normals()
            
            # è·å–é¡¶ç‚¹ä¿¡æ¯
            vertices = np.asarray(self.face_mesh.vertices)
            self.num_vertices = len(vertices)
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ:")
            print(f"   é¡¶ç‚¹æ•°: {self.num_vertices}")
            print(f"   é¢æ•°: {len(self.face_mesh.triangles)}")
            print(f"   åæ ‡èŒƒå›´:")
            print(f"     X: [{vertices[:, 0].min():.2f}, {vertices[:, 0].max():.2f}] mm")
            print(f"     Y: [{vertices[:, 1].min():.2f}, {vertices[:, 1].max():.2f}] mm") 
            print(f"     Z: [{vertices[:, 2].min():.2f}, {vertices[:, 2].max():.2f}] mm")
            
            # è®¾ç½®æè´¨
            self.face_mesh.paint_uniform_color([0.8, 0.7, 0.6])  # è‚¤è‰²
            
            # å¤‡ä»½åŸå§‹é¡¶ç‚¹
            self.original_vertices = np.asarray(self.face_mesh.vertices).copy()
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def setup_visualizer(self):
        """è®¾ç½®Open3Då¯è§†åŒ–å™¨ï¼ˆå›ºå®šè§†è§’ç‰ˆæœ¬ï¼‰"""
        print("ğŸ¨ åˆå§‹åŒ–Open3Då¯è§†åŒ–å™¨...")
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        self.vis = o3d.visualization.Visualizer()
        self.vis.create_window("FaceMatrixLab - 3D Face Renderer", self.render_width, self.render_height)
        
        # æ·»åŠ æ¨¡å‹åˆ°å¯è§†åŒ–å™¨
        self.vis.add_geometry(self.face_mesh)
        
        # è®¾ç½®æ¸²æŸ“é€‰é¡¹
        render_option = self.vis.get_render_option()
        render_option.mesh_show_back_face = True
        render_option.background_color = np.array([0.1, 0.1, 0.1])
        
        # è®¾ç½®ç›¸æœºå‚æ•°ï¼ˆå›ºå®šè§†è§’ï¼‰
        view_control = self.vis.get_view_control()
        
        print("âœ… Open3Då¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        return True
    
    def create_mediapipe_landmarker(self):
        """åˆ›å»ºMediaPipeäººè„¸æ ‡å¿—æ£€æµ‹å™¨"""
        if not self.mp_model_path:
            return None
            
        try:
            options = FaceLandmarkerOptions(
                base_options=BaseOptions(model_asset_path=self.mp_model_path),
                running_mode=VisionRunningMode.VIDEO,
                num_faces=1,
                min_face_detection_confidence=0.5,
                min_face_presence_confidence=0.5,
                min_tracking_confidence=0.5,
                output_face_blendshapes=False,  # æš‚æ—¶ä¸ç”¨blendshapes
                output_facial_transformation_matrixes=True,  # è¾“å‡ºå˜æ¢çŸ©é˜µ
            )
            
            landmarker = FaceLandmarker.create_from_options(options)
            print("âœ… MediaPipeäººè„¸æ£€æµ‹å™¨åˆ›å»ºæˆåŠŸ")
            return landmarker
            
        except Exception as e:
            print(f"âŒ MediaPipeæ£€æµ‹å™¨åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def detection_thread(self):
        """MediaPipeæ£€æµ‹çº¿ç¨‹"""
        print("ğŸ¥ å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹...")
        
        # åˆ›å»ºæ£€æµ‹å™¨
        self.landmarker = self.create_mediapipe_landmarker()
        if not self.landmarker:
            print("âŒ MediaPipeæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥")
            return
        
        # æ‰“å¼€æ‘„åƒå¤´
        cap = cv2.VideoCapture(self.camera_id)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_id}")
            return
        
        # è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨ç‡
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        frame_count = 0
        fps_start_time = time.time()
        
        try:
            while self.is_running:
                ret, frame = cap.read()
                if not ret:
                    continue
                
                frame = cv2.flip(frame, 1)  # é•œåƒç¿»è½¬
                frame_count += 1
                
                # è½¬æ¢ä¸ºRGB
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
                
                # è¿›è¡Œäººè„¸æ£€æµ‹
                timestamp_ms = int(time.time() * 1000)
                detection_result = self.landmarker.detect_for_video(mp_image, timestamp_ms)
                
                # å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
                try:
                    data_packet = {
                        'detection_result': detection_result,
                        'frame': rgb_frame,
                        'timestamp': timestamp_ms
                    }
                    self.data_queue.put_nowait(data_packet)
                except queue.Full:
                    # å¦‚æœé˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒæœ€æ—§çš„æ•°æ®
                    try:
                        self.data_queue.get_nowait()
                        self.data_queue.put_nowait(data_packet)
                    except queue.Empty:
                        pass
                
                # è®¡ç®—æ£€æµ‹FPS
                if frame_count % 30 == 0:
                    elapsed = time.time() - fps_start_time
                    self.current_detection_fps = 30.0 / elapsed
                    fps_start_time = time.time()
                
                # æ§åˆ¶å¸§ç‡
                time.sleep(1.0 / self.fps_target)
                
        except Exception as e:
            print(f"âŒ æ£€æµ‹çº¿ç¨‹é”™è¯¯: {e}")
        finally:
            cap.release()
            print("ğŸ¥ MediaPipeæ£€æµ‹çº¿ç¨‹å·²åœæ­¢")
    
    def update_face_model(self, detection_result):
        """æ ¹æ®MediaPipeç»“æœæ›´æ–°3Däººè„¸æ¨¡å‹"""
        if not detection_result.face_landmarks:
            return False
        
        # è·å–å˜æ¢çŸ©é˜µ
        if (detection_result.facial_transformation_matrixes and 
            len(detection_result.facial_transformation_matrixes) > 0):
            
            facial_transform = np.array(detection_result.facial_transformation_matrixes[0])
            
            # åº”ç”¨å˜æ¢åˆ°åŸå§‹é¡¶ç‚¹
            vertices = self.original_vertices.copy()
            
            # å°†é¡¶ç‚¹è½¬æ¢ä¸ºé½æ¬¡åæ ‡
            vertices_homogeneous = np.hstack([vertices, np.ones((len(vertices), 1))])
            
            # åº”ç”¨å˜æ¢çŸ©é˜µ
            transformed_vertices = (facial_transform @ vertices_homogeneous.T).T[:, :3]
            
            # æ›´æ–°æ¨¡å‹é¡¶ç‚¹
            self.face_mesh.vertices = o3d.utility.Vector3dVector(transformed_vertices)
            self.face_mesh.compute_vertex_normals()
            
            return True
        
        return False
    

    
    def run_with_visualizer(self):
        """ä½¿ç”¨Open3Då¯è§†åŒ–å™¨è¿è¡Œï¼ˆå›ºå®šè§†è§’ç‰ˆæœ¬ï¼‰"""
        print("ğŸ¬ å¯åŠ¨Open3Då¯è§†åŒ–å™¨...")
        
        # è®¾ç½®å¯è§†åŒ–å™¨
        if not self.setup_visualizer():
            print("âŒ å¯è§†åŒ–å™¨åˆå§‹åŒ–å¤±è´¥")
            return
        
        print("âœ… å¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        
        try:
            while self.is_running:
                # å¤„ç†MediaPipeæ•°æ®
                try:
                    while not self.data_queue.empty():
                        data_packet = self.data_queue.get_nowait()
                        if self.update_face_model(data_packet['detection_result']):
                            # æ›´æ–°å¯è§†åŒ–å™¨ä¸­çš„å‡ ä½•ä½“
                            self.vis.update_geometry(self.face_mesh)
                except queue.Empty:
                    pass
                
                # æ›´æ–°å¯è§†åŒ–å™¨
                if not self.vis.poll_events():
                    break
                self.vis.update_renderer()
                
                time.sleep(1.0 / 60)  # 60FPSæ¸²æŸ“
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
        finally:
            self.vis.destroy_window()
    
    def run(self):
        """å¯åŠ¨æ¸²æŸ“å™¨"""
        print("\nğŸš€ å¯åŠ¨FaceMatrixLab 3Dæ¸²æŸ“å™¨ï¼ˆå›ºå®šè§†è§’ç‰ˆæœ¬ï¼‰")
        print("=" * 60)
        print("æ§åˆ¶è¯´æ˜:")
        print("  å›ºå®šè§†è§’æ˜¾ç¤º")
        print("  Qé”® æˆ–å…³é—­çª—å£: é€€å‡º")
        print("=" * 60)
        
        self.is_running = True
        
        # å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹
        detection_thread = threading.Thread(target=self.detection_thread, daemon=True)
        detection_thread.start()
        
        # ç­‰å¾…æ£€æµ‹çº¿ç¨‹å¯åŠ¨
        time.sleep(2)
        
        try:
            # è¿è¡Œå¯è§†åŒ–å™¨
            self.run_with_visualizer()
        finally:
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹ æ¸…ç†èµ„æº...")
        self.is_running = False
        print("âœ… èµ„æºæ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    print("FaceMatrixLab 3D äººè„¸æ¸²æŸ“å™¨ï¼ˆå›ºå®šè§†è§’ç‰ˆæœ¬ï¼‰")
    print("ä½¿ç”¨MediaPipe + Open3Då®ç°å®æ—¶3Däººè„¸è¿½è¸ªæ¸²æŸ“")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = "../obj/Andy_Wah_facemesh.obj"
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {model_path}")
        print("è¯·ç¡®ä¿Andy_Wah_facemesh.objæ–‡ä»¶ä½äº obj/ ç›®å½•ä¸­")
        return
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œæ¸²æŸ“å™¨
        renderer = FaceMatrixLabRenderer(camera_id=0, model_path=model_path)
        renderer.run()
        
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print("ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()
