#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FaceMatrixLab 3D æ¸²æŸ“å™¨
ä½¿ç”¨ Open3D æ¸²æŸ“ Andy_Wah_facemesh.objï¼Œé€šè¿‡ MediaPipe æ•°æ®æµé©±åŠ¨
æ”¯æŒå®æ—¶äººè„¸å§¿æ€å’Œè¡¨æƒ…å˜åŒ–
"""

import cv2
import mediapipe as mp
import numpy as np
import time
import os
import threading
import queue
from typing import Optional, Tuple
import open3d as o3d


# MediaPipe å¯¼å…¥
BaseOptions = mp.tasks.BaseOptions
FaceLandmarker = mp.tasks.vision.FaceLandmarker
FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
FaceLandmarkerResult = mp.tasks.vision.FaceLandmarkerResult
VisionRunningMode = mp.tasks.vision.RunningMode


class FaceMatrixLabRenderer:
    def __init__(self, camera_id=0, model_path="../obj/Andy_Wah_facemesh.obj"):
        """åˆå§‹åŒ–3Däººè„¸æ¸²æŸ“å™¨"""
        print("=== FaceMatrixLab 3D æ¸²æŸ“å™¨åˆå§‹åŒ– ===")
        
        # åŸºæœ¬å‚æ•°
        self.camera_id = camera_id
        self.model_path = model_path
        self.is_running = False
        
        # æ¸²æŸ“å‚æ•°
        self.render_width = 1280
        self.render_height = 720
        self.fps_target = 30
        
        # MediaPipe ç›¸å…³
        self.landmarker = None
        self.mp_model_path = self.download_mediapipe_model()
        
        # æ•°æ®é˜Ÿåˆ— - ç”¨äºçº¿ç¨‹é—´é€šä¿¡
        self.data_queue = queue.Queue(maxsize=5)
        self.latest_result = None
        self.latest_frame = None
        
        # ARèƒŒæ™¯æ§åˆ¶
        self.show_camera_background = True  # é»˜è®¤æ˜¾ç¤ºæ‘„åƒæœºèƒŒæ™¯
        self.background_image = None
        self.latest_camera_frame = None  # ä¿å­˜æœ€æ–°çš„æ‘„åƒæœºå¸§
        
        # ã€æ–°å¢ã€‘ç›¸æœºæ ¡å‡†å‚æ•°åŠ è½½
        self.use_real_calibration = True  # æ˜¯å¦ä½¿ç”¨çœŸå®æ ¡å‡†å‚æ•°
        self.calibration_intrinsic_path = "Camera-Calibration/output/intrinsic.txt"  # å†…å‚æ–‡ä»¶è·¯å¾„
        self.calibration_extrinsic_path = "Camera-Calibration/output/extrinsic.txt"  # å¤–å‚æ–‡ä»¶è·¯å¾„
        
        # ç›¸æœºå‚æ•°ï¼ˆå°†æ ¹æ®çœŸå®æ ¡å‡†æˆ–æ‰‹åŠ¨è®¾ç½®ï¼‰
        self.camera_fx = None
        self.camera_fy = None
        self.camera_cx = None
        self.camera_cy = None
        self.camera_skew = 0.0  # å€¾æ–œå‚æ•°
        
        # åŠ è½½çœŸå®ç›¸æœºæ ¡å‡†å‚æ•°
        self.load_camera_calibration()
        
        # ç›¸æœºå‚æ•°ï¼ˆ50mm ç­‰æ•ˆç„¦è·ï¼‰- å°†åœ¨setup_camera_parametersä¸­æ ¹æ®æ ¡å‡†ç»“æœè®¾ç½®
        self.setup_camera_parameters()
        
        # åŠ è½½3Dæ¨¡å‹
        if not self.load_face_model():
            raise Exception("æ— æ³•åŠ è½½3Dæ¨¡å‹æ–‡ä»¶")
        
        # æ€§èƒ½ç»Ÿè®¡
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.current_render_fps = 0
        self.current_detection_fps = 0
        
        print("âœ… FaceMatrixLab 3D æ¸²æŸ“å™¨åˆå§‹åŒ–å®Œæˆ")
        
    def download_mediapipe_model(self):
        """ä¸‹è½½MediaPipeäººè„¸æ ‡å¿—æ£€æµ‹æ¨¡å‹"""
        model_url = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
        model_path = "face_landmarker.task"
        
        if not os.path.exists(model_path):
            print("æ­£åœ¨ä¸‹è½½MediaPipeæ¨¡å‹...")
            try:
                import urllib.request
                urllib.request.urlretrieve(model_url, model_path)
                print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_path}")
            except Exception as e:
                print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
                return None
        else:
            print(f"âœ… MediaPipeæ¨¡å‹å·²å­˜åœ¨: {model_path}")
        
        return model_path
    
    def load_camera_calibration(self):
        """åŠ è½½çœŸå®çš„ç›¸æœºæ ¡å‡†å‚æ•°"""
        if not self.use_real_calibration:
            print("ğŸ“· æœªå¯ç”¨çœŸå®ç›¸æœºæ ¡å‡†ï¼Œå°†ä½¿ç”¨é»˜è®¤ä¼°è®¡å‚æ•°")
            return
        
        try:
            # åŠ è½½å†…å‚çŸ©é˜µ
            if os.path.exists(self.calibration_intrinsic_path):
                print(f"ğŸ“· æ­£åœ¨åŠ è½½ç›¸æœºå†…å‚: {self.calibration_intrinsic_path}")
                
                # è¯»å–å†…å‚æ–‡ä»¶
                with open(self.calibration_intrinsic_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£æå†…å‚çŸ©é˜µ - æ”¯æŒå¤šç§æ ¼å¼
                lines = content.strip().split('\n')
                matrix_lines = []
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('A=') and '[' in line and ']' in line:
                        # æ¸…ç†æ–¹æ‹¬å·å¹¶æå–æ•°å­—
                        line = line.replace('[', '').replace(']', '')
                        matrix_lines.append(line)
                
                if len(matrix_lines) >= 3:
                    # è§£æ3x3å†…å‚çŸ©é˜µ
                    intrinsic_matrix = []
                    for line in matrix_lines[:3]:
                        # åˆ†å‰²æ•°å­—ï¼ˆå¤„ç†å¯èƒ½çš„ç§‘å­¦è®¡æ•°æ³•ï¼‰
                        values = []
                        parts = line.split()
                        for part in parts:
                            try:
                                values.append(float(part))
                            except ValueError:
                                continue
                        if len(values) >= 3:
                            intrinsic_matrix.append(values[:3])
                    
                    if len(intrinsic_matrix) == 3:
                        # æå–ç›¸æœºå‚æ•°
                        A = np.array(intrinsic_matrix)
                        self.camera_fx = A[0, 0]  # fx
                        self.camera_fy = A[1, 1]  # fy
                        self.camera_cx = A[0, 2]  # cx (ä¸»ç‚¹xåæ ‡)
                        self.camera_cy = A[1, 2]  # cy (ä¸»ç‚¹yåæ ‡)
                        self.camera_skew = A[0, 1]  # skew (å€¾æ–œå‚æ•°)
                        
                        print("âœ… æˆåŠŸåŠ è½½ç›¸æœºå†…å‚:")
                        print(f"   fx (xæ–¹å‘ç„¦è·): {self.camera_fx:.2f}")
                        print(f"   fy (yæ–¹å‘ç„¦è·): {self.camera_fy:.2f}")
                        print(f"   cx (ä¸»ç‚¹xåæ ‡): {self.camera_cx:.2f}")
                        print(f"   cy (ä¸»ç‚¹yåæ ‡): {self.camera_cy:.2f}")
                        print(f"   skew (å€¾æ–œå‚æ•°): {self.camera_skew:.4f}")
                    else:
                        raise ValueError("æ— æ³•è§£æå†…å‚çŸ©é˜µæ ¼å¼")
                else:
                    raise ValueError("å†…å‚æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
                    
            else:
                print(f"âŒ å†…å‚æ–‡ä»¶ä¸å­˜åœ¨: {self.calibration_intrinsic_path}")
                self.use_real_calibration = False
                return
            
            # åŠ è½½å¤–å‚çŸ©é˜µï¼ˆå¯é€‰ï¼Œç”¨äºæ›´å¤æ‚çš„3DæŠ•å½±ï¼‰
            if os.path.exists(self.calibration_extrinsic_path):
                print(f"ğŸ“· æ£€æµ‹åˆ°å¤–å‚æ–‡ä»¶: {self.calibration_extrinsic_path}")
                # æ³¨æ„ï¼šå½“å‰ä»£ç ä¸»è¦ä½¿ç”¨å†…å‚è¿›è¡Œé€è§†æŠ•å½±ï¼Œå¤–å‚æš‚ä¸ä½¿ç”¨
                # å¦‚æœéœ€è¦æ›´ç²¾ç¡®çš„3Då‡ ä½•è®¡ç®—ï¼Œå¯ä»¥åœ¨è¿™é‡ŒåŠ è½½å¤–å‚çŸ©é˜µ
            
            print("âœ… ç›¸æœºæ ¡å‡†å‚æ•°åŠ è½½å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç›¸æœºæ ¡å‡†å‚æ•°å¤±è´¥: {e}")
            print("âš ï¸ å°†å›é€€åˆ°æ‰‹åŠ¨ä¼°è®¡ç›¸æœºå‚æ•°")
            self.use_real_calibration = False
            # é‡ç½®ç›¸æœºå‚æ•°
            self.camera_fx = None
            self.camera_fy = None
            self.camera_cx = None
            self.camera_cy = None
            self.camera_skew = 0.0
        
    def setup_camera_parameters(self):
        """è®¾ç½®ç›¸æœºå‚æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨çœŸå®æ ¡å‡†å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨50mmç­‰æ•ˆç„¦è·ä¼°è®¡ï¼‰"""
        print("ğŸ“· ç›¸æœºå‚æ•°è®¾ç½®:")
        print(f"   åˆ†è¾¨ç‡: {self.render_width}x{self.render_height}")
        
        # å¦‚æœæˆåŠŸåŠ è½½äº†çœŸå®æ ¡å‡†å‚æ•°ï¼Œç›´æ¥ä½¿ç”¨
        if (self.use_real_calibration and 
            self.camera_fx is not None and self.camera_fy is not None and 
            self.camera_cx is not None and self.camera_cy is not None):
            
            self.fx = self.camera_fx
            self.fy = self.camera_fy
            self.cx = self.camera_cx
            self.cy = self.camera_cy
            
            print("âœ… ä½¿ç”¨çœŸå®ç›¸æœºæ ¡å‡†å‚æ•°:")
            print(f"   ç„¦è·: fx={self.fx:.2f}, fy={self.fy:.2f}")
            print(f"   ä¸»ç‚¹: cx={self.cx:.2f}, cy={self.cy:.2f}")
            if self.camera_skew != 0.0:
                print(f"   å€¾æ–œ: skew={self.camera_skew:.4f}")
        
        else:
            # å›é€€åˆ°50mmç­‰æ•ˆç„¦è·ä¼°è®¡
            print("âš ï¸ ä½¿ç”¨50mmç­‰æ•ˆç„¦è·ä¼°è®¡å‚æ•°:")
            
            # 50mm ç­‰æ•ˆç„¦è·å‚æ•°
            f_mm = 50.0  # ç„¦è·(mm)
            sensor_width_mm = 36.0  # å…¨ç”»å¹…ä¼ æ„Ÿå™¨å®½åº¦(mm)
            
            # è®¡ç®—åƒç´ ç„¦è·
            self.fx = (f_mm / sensor_width_mm) * self.render_width
            self.fy = (f_mm / sensor_width_mm) * self.render_height  # å‡è®¾æ­£æ–¹å½¢åƒç´ 
            self.cx = self.render_width / 2.0
            self.cy = self.render_height / 2.0
            
            print(f"   ç„¦è·: fx={self.fx:.2f}, fy={self.fy:.2f}")
            print(f"   ä¸»ç‚¹: cx={self.cx:.2f}, cy={self.cy:.2f}")
            print(f"   æ³¨æ„: è¿™æ˜¯åŸºäº50mmç­‰æ•ˆç„¦è·çš„ä¼°è®¡å€¼")
        
        # åˆ›å»ºOpen3Dç›¸æœºå†…å‚
        self.intrinsic = o3d.camera.PinholeCameraIntrinsic(
            self.render_width, self.render_height, 
            self.fx, self.fy, self.cx, self.cy
        )
        
        print(f"âœ… Open3Dç›¸æœºå†…å‚åˆ›å»ºå®Œæˆ")
    
    def load_face_model(self):
        """åŠ è½½3Däººè„¸æ¨¡å‹"""
        if not os.path.exists(self.model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            return False
            
        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½3Dæ¨¡å‹: {self.model_path}")
        
        try:
            # åŠ è½½æ¨¡å‹
            self.face_mesh = o3d.io.read_triangle_mesh(self.model_path)
            
            if len(self.face_mesh.vertices) == 0:
                print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼šæ²¡æœ‰é¡¶ç‚¹æ•°æ®")
                return False
            
            # è®¡ç®—æ³•çº¿
            self.face_mesh.compute_vertex_normals()
            
            # è·å–é¡¶ç‚¹ä¿¡æ¯
            vertices = np.asarray(self.face_mesh.vertices)
            self.num_vertices = len(vertices)
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ:")
            print(f"   é¡¶ç‚¹æ•°: {self.num_vertices}")
            print(f"   é¢æ•°: {len(self.face_mesh.triangles)}")
            print(f"   åæ ‡èŒƒå›´:")
            print(f"     X: [{vertices[:, 0].min():.2f}, {vertices[:, 0].max():.2f}] mm")
            print(f"     Y: [{vertices[:, 1].min():.2f}, {vertices[:, 1].max():.2f}] mm") 
            print(f"     Z: [{vertices[:, 2].min():.2f}, {vertices[:, 2].max():.2f}] mm")
            
            # è®¾ç½®æè´¨
            self.face_mesh.paint_uniform_color([0.8, 0.7, 0.6])  # è‚¤è‰²
            
            # å¤‡ä»½åŸå§‹é¡¶ç‚¹
            self.original_vertices = np.asarray(self.face_mesh.vertices).copy()
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def setup_visualizer(self):
        """è®¾ç½®Open3Då¯è§†åŒ–å™¨ï¼ˆç¦»å±æ¸²æŸ“ç‰ˆæœ¬ï¼Œå…¼å®¹Windowsï¼‰"""
        print("ğŸ¨ åˆå§‹åŒ–Open3Då¯è§†åŒ–å™¨...")
        # åˆ›å»ºéšè—çš„å¯è§†åŒ–å™¨çª—å£è¿›è¡Œç¦»å±æ¸²æŸ“
        self.vis = o3d.visualization.Visualizer()
        self.vis.create_window("_", self.render_width, self.render_height, visible=False)
        
        # æ·»åŠ äººè„¸æ¨¡å‹ï¼ˆä¸ä½¿ç”¨MaterialRecordï¼Œç›´æ¥ä½¿ç”¨ç½‘æ ¼é¢œè‰²ï¼‰
        self.vis.add_geometry(self.face_mesh)
        
        # è®¾ç½®æ¸²æŸ“é€‰é¡¹
        render_option = self.vis.get_render_option()
        render_option.mesh_show_back_face = True
        render_option.background_color = np.array([0.0, 0.0, 0.0])  # é»‘è‰²èƒŒæ™¯ä¾¿äºåˆæˆ
        
        # è®¾ç½®ç›¸æœºå‚æ•°
        ctr = self.vis.get_view_control()
        # åˆ›å»ºç›¸æœºå‚æ•°å¯¹è±¡
        camera_params = o3d.camera.PinholeCameraParameters()
        camera_params.intrinsic = self.intrinsic
        camera_params.extrinsic = np.eye(4)
        ctr.convert_from_pinhole_camera_parameters(camera_params)
        
        print("âœ… Open3Då¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        return True
    
    def setup_camera_background(self):
        """è®¾ç½®æ‘„åƒæœºèƒŒæ™¯æ˜¾ç¤º"""
        # åˆ›å»ºèƒŒæ™¯å¹³é¢ï¼ˆç”¨äºæ˜¾ç¤ºæ‘„åƒæœºç”»é¢ï¼‰
        # èƒŒæ™¯å¹³é¢ä½äºæ¨¡å‹åæ–¹ï¼Œå¤§å°åŒ¹é…æ¸²æŸ“è§†å›¾
        background_vertices = np.array([
            [-200, -150, -300],  # å·¦ä¸‹
            [200, -150, -300],   # å³ä¸‹
            [200, 150, -300],    # å³ä¸Š
            [-200, 150, -300]    # å·¦ä¸Š
        ])
        
        background_triangles = np.array([
            [0, 1, 2],  # ç¬¬ä¸€ä¸ªä¸‰è§’å½¢
            [0, 2, 3]   # ç¬¬äºŒä¸ªä¸‰è§’å½¢
        ])
        
        # åˆ›å»ºèƒŒæ™¯ç½‘æ ¼
        self.background_mesh = o3d.geometry.TriangleMesh()
        self.background_mesh.vertices = o3d.utility.Vector3dVector(background_vertices)
        self.background_mesh.triangles = o3d.utility.Vector3iVector(background_triangles)
        self.background_mesh.compute_vertex_normals()
        
        # è®¾ç½®UVåæ ‡ç”¨äºçº¹ç†æ˜ å°„
        uv_coordinates = np.array([
            [0, 0],  # å·¦ä¸‹
            [1, 0],  # å³ä¸‹
            [1, 1],  # å³ä¸Š
            [0, 1]   # å·¦ä¸Š
        ])
        
        # åˆå§‹æ—¶éšè—èƒŒæ™¯
        self.background_mesh.paint_uniform_color([0.1, 0.1, 0.1])  # æ·±ç°è‰²
        
        # æ·»åŠ åˆ°å¯è§†åŒ–å™¨
        self.vis.add_geometry(self.background_mesh)
        
        print("ğŸ“º æ‘„åƒæœºèƒŒæ™¯å¹³é¢å·²åˆ›å»º")
    
    def create_mediapipe_landmarker(self):
        """åˆ›å»ºMediaPipeäººè„¸æ ‡å¿—æ£€æµ‹å™¨"""
        if not self.mp_model_path:
            return None
            
        try:
            options = FaceLandmarkerOptions(
                base_options=BaseOptions(model_asset_path=self.mp_model_path),
                running_mode=VisionRunningMode.VIDEO,
                num_faces=1,
                min_face_detection_confidence=0.5,
                min_face_presence_confidence=0.5,
                min_tracking_confidence=0.5,
                output_face_blendshapes=False,  # æš‚æ—¶ä¸ç”¨blendshapes
                output_facial_transformation_matrixes=True,  # è¾“å‡ºå˜æ¢çŸ©é˜µ
            )
            
            landmarker = FaceLandmarker.create_from_options(options)
            print("âœ… MediaPipeäººè„¸æ£€æµ‹å™¨åˆ›å»ºæˆåŠŸ")
            return landmarker
            
        except Exception as e:
            print(f"âŒ MediaPipeæ£€æµ‹å™¨åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def detection_thread(self):
        """MediaPipeæ£€æµ‹çº¿ç¨‹"""
        print("ğŸ¥ å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹...")
        
        # åˆ›å»ºæ£€æµ‹å™¨
        self.landmarker = self.create_mediapipe_landmarker()
        if not self.landmarker:
            print("âŒ MediaPipeæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥")
            return
        
        # æ‰“å¼€æ‘„åƒå¤´
        cap = cv2.VideoCapture(self.camera_id)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_id}")
            return
        
        # è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨ç‡
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        frame_count = 0
        fps_start_time = time.time()
        
        try:
            while self.is_running:
                ret, frame = cap.read()
                if not ret:
                    continue
                
                frame = cv2.flip(frame, 1)  # é•œåƒç¿»è½¬
                frame_count += 1
                
                # è½¬æ¢ä¸ºRGB
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
                
                # è¿›è¡Œäººè„¸æ£€æµ‹
                timestamp_ms = int(time.time() * 1000)
                detection_result = self.landmarker.detect_for_video(mp_image, timestamp_ms)
                
                # å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
                try:
                    data_packet = {
                        'detection_result': detection_result,
                        'frame': rgb_frame,
                        'timestamp': timestamp_ms
                    }
                    self.data_queue.put_nowait(data_packet)
                except queue.Full:
                    # å¦‚æœé˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒæœ€æ—§çš„æ•°æ®
                    try:
                        self.data_queue.get_nowait()
                        self.data_queue.put_nowait(data_packet)
                    except queue.Empty:
                        pass
                
                # è®¡ç®—æ£€æµ‹FPS
                if frame_count % 30 == 0:
                    elapsed = time.time() - fps_start_time
                    self.current_detection_fps = 30.0 / elapsed
                    fps_start_time = time.time()
                
                # æ§åˆ¶å¸§ç‡
                time.sleep(1.0 / self.fps_target)
                
        except Exception as e:
            print(f"âŒ æ£€æµ‹çº¿ç¨‹é”™è¯¯: {e}")
        finally:
            cap.release()
            print("ğŸ¥ MediaPipeæ£€æµ‹çº¿ç¨‹å·²åœæ­¢")
    
    def update_face_model(self, detection_result):
        """æ ¹æ®MediaPipeç»“æœæ›´æ–°3Däººè„¸æ¨¡å‹"""
        if not detection_result.face_landmarks:
            return False
        
        # è·å–å˜æ¢çŸ©é˜µ
        if (detection_result.facial_transformation_matrixes and 
            len(detection_result.facial_transformation_matrixes) > 0):
            
            facial_transform = np.array(detection_result.facial_transformation_matrixes[0])
            
            # åº”ç”¨å˜æ¢åˆ°åŸå§‹é¡¶ç‚¹
            vertices = self.original_vertices.copy()
            
            # å°†é¡¶ç‚¹è½¬æ¢ä¸ºé½æ¬¡åæ ‡
            vertices_homogeneous = np.hstack([vertices, np.ones((len(vertices), 1))])
            
            # åº”ç”¨å˜æ¢çŸ©é˜µ
            transformed_vertices = (facial_transform @ vertices_homogeneous.T).T[:, :3]
            
            # æ›´æ–°æ¨¡å‹é¡¶ç‚¹
            self.face_mesh.vertices = o3d.utility.Vector3dVector(transformed_vertices)
            self.face_mesh.compute_vertex_normals()
            
            return True
        
        return False
    
    def update_camera_background(self, frame):
        """æ›´æ–°æ‘„åƒæœºèƒŒæ™¯æ˜¾ç¤º"""
        if frame is None:
            return
            
        # ä¿å­˜æœ€æ–°å¸§ç”¨äºæ˜¾ç¤º
        self.latest_camera_frame = frame.copy()
        
        try:
            if self.show_camera_background:
                # æ–¹æ¡ˆ1ï¼šåœ¨ç‹¬ç«‹çš„OpenCVçª—å£ä¸­æ˜¾ç¤ºæ‘„åƒæœºç”»é¢
                # åˆ›å»ºARåˆæˆè§†å›¾
                display_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                
                # æ·»åŠ ARä¿¡æ¯å åŠ 
                overlay_text = "AR Background - Live Camera"
                cv2.putText(display_frame, overlay_text, (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                # æ˜¾ç¤ºæ‘„åƒæœºèƒŒæ™¯çª—å£
                cv2.namedWindow("Camera Background", cv2.WINDOW_NORMAL)
                cv2.resizeWindow("Camera Background", 640, 480)
                cv2.imshow("Camera Background", display_frame)
                
                # æ–¹æ¡ˆ2ï¼šåŒæ—¶å°è¯•æ”¹è¿›3DèƒŒæ™¯å¹³é¢çš„æ˜¾ç¤º
                if hasattr(self, 'background_mesh'):
                    # ä½¿ç”¨å›¾åƒçš„æ•´ä½“äº®åº¦æ¥è°ƒæ•´èƒŒæ™¯å¹³é¢
                    avg_brightness = np.mean(frame) / 255.0
                    
                    # æ ¹æ®æ‘„åƒæœºç”»é¢è°ƒæ•´èƒŒæ™¯è‰²
                    # å–ä¸åŒåŒºåŸŸçš„é¢œè‰²
                    h, w = frame.shape[:2]
                    
                    # æ›´å¯†é›†çš„é‡‡æ ·ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœ
                    sample_points = [
                        (h//4, w//4),     # å·¦ä¸Š
                        (h//4, 3*w//4),   # å³ä¸Š
                        (3*h//4, 3*w//4), # å³ä¸‹
                        (3*h//4, w//4)    # å·¦ä¸‹
                    ]
                    
                    colors = []
                    for y, x in sample_points:
                        pixel_color = frame[y, x] / 255.0
                        # å¢å¼ºé¢œè‰²é¥±å’Œåº¦ä»¥ä¾¿æ›´å¥½åœ°æ˜¾ç¤º
                        pixel_color = pixel_color * 1.5
                        pixel_color = np.clip(pixel_color, 0, 1)
                        colors.append(pixel_color)
                    
                    # è®¾ç½®é¡¶ç‚¹é¢œè‰²
                    self.background_mesh.vertex_colors = o3d.utility.Vector3dVector(colors)
                    
                                    # æ›´æ–°å¯è§†åŒ–å™¨ä¸­çš„èƒŒæ™¯
                self.vis.update_geometry(self.background_mesh)
                    
        except Exception as e:
            print(f"âš ï¸ èƒŒæ™¯æ›´æ–°å¤±è´¥: {e}")
    
    def toggle_camera_background(self):
        """åˆ‡æ¢æ‘„åƒæœºèƒŒæ™¯æ˜¾ç¤º"""
        self.show_camera_background = not self.show_camera_background
        
        if self.show_camera_background:
            print("ğŸ“º æ‘„åƒæœºèƒŒæ™¯å·²å¼€å¯ - ARæ¨¡å¼")
            # æ˜¾ç¤ºæœ€æ–°çš„æ‘„åƒæœºç”»é¢ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if self.latest_camera_frame is not None:
                self.update_camera_background(self.latest_camera_frame)
        else:
            print("ğŸ­ æ‘„åƒæœºèƒŒæ™¯å·²å…³é—­ - çº¯3Dæ¨¡å¼") 
            # å…³é—­æ‘„åƒæœºèƒŒæ™¯çª—å£
            try:
                cv2.destroyWindow("Camera Background")
            except:
                pass
            
            # éšè—èƒŒæ™¯å¹³é¢
            if hasattr(self, 'background_mesh'):
                self.background_mesh.paint_uniform_color([0.1, 0.1, 0.1])  # æ·±ç°è‰²
                self.vis.update_geometry(self.background_mesh)

    def run_with_visualizer(self):
        """ä½¿ç”¨Open3Déšè—çª—å£æ¸²æŸ“å¹¶åˆæˆARè§†å›¾"""
        if not self.setup_visualizer():
            print("âŒ å¯è§†åŒ–å™¨åˆå§‹åŒ–å¤±è´¥")
            return
            
        cv2.namedWindow("AR View", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("AR View", self.render_width, self.render_height)
        
        try:
            while self.is_running:
                # è¯»å–æœ€æ–°æ•°æ®
                frame = None
                try:
                    pkt = self.data_queue.get_nowait()
                    detection_result = pkt['detection_result']
                    frame = pkt.get('frame')
                except queue.Empty:
                    detection_result = None
                
                # æ›´æ–°3Dæ¨¡å‹
                if detection_result and self.update_face_model(detection_result):
                    self.vis.update_geometry(self.face_mesh)
                
                # ç¦»å±æ¸²æŸ“è·å–å›¾åƒ
                self.vis.poll_events()
                self.vis.update_renderer()
                img_3d = np.asarray(self.vis.capture_screen_float_buffer(False))
                img_3d = (img_3d * 255).astype(np.uint8)
                img_3d_bgr = cv2.cvtColor(img_3d, cv2.COLOR_RGB2BGR)
                
                # æ‘„åƒæœºèƒŒæ™¯
                if self.show_camera_background and frame is not None:
                    bg = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    bg = cv2.resize(bg, (self.render_width, self.render_height))
                else:
                    bg = np.zeros_like(img_3d_bgr)
                
                # ARåˆæˆï¼šå°†3Dæ¨¡å‹å åŠ åˆ°èƒŒæ™¯ä¸Š
                # åˆ›å»ºæ©ç ï¼šéé»‘è‰²åƒç´ çš„åŒºåŸŸ
                mask = img_3d_bgr.sum(axis=2) > 30
                composite = bg.copy()
                composite[mask] = img_3d_bgr[mask]
                
                # æ˜¾ç¤ºåˆæˆç»“æœ
                cv2.imshow("AR View", composite)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('o'):
                    self.toggle_camera_background()
                elif key == ord('q'):
                    break
                    
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
        finally:
            self.vis.destroy_window()
            cv2.destroyAllWindows()
    
    def run(self):
        """å¯åŠ¨æ¸²æŸ“å™¨"""
        print("\nå¯åŠ¨FaceMatrixLab 3Dæ¸²æŸ“å™¨ï¼ˆARå¢å¼ºç°å®ç‰ˆæœ¬ï¼‰")
        print("=" * 60)
        print("ğŸ“· ç›¸æœºç³»ç»Ÿ:")
        if self.use_real_calibration and self.camera_fx is not None:
            print("  âœ… ä½¿ç”¨çœŸå®ç›¸æœºæ ¡å‡†å‚æ•°")
            print(f"  ğŸ“‚ å†…å‚æ–‡ä»¶: {self.calibration_intrinsic_path}")
        else:
            print("  âš ï¸ ä½¿ç”¨ä¼°è®¡ç›¸æœºå‚æ•°ï¼ˆ50mmç­‰æ•ˆç„¦è·ï¼‰")
            print("  ğŸ’¡ å¦‚éœ€ç²¾ç¡®æ¸²æŸ“ï¼Œè¯·å°†ç›¸æœºæ ¡å‡†æ–‡ä»¶æ”¾ç½®åœ¨:")
            print(f"     {self.calibration_intrinsic_path}")
        print("=" * 60)
        print("æ§åˆ¶è¯´æ˜:")
        print("  Oé”®: åˆ‡æ¢æ‘„åƒæœºèƒŒæ™¯æ˜¾ç¤ºï¼ˆARæ¨¡å¼ / çº¯3Dæ¨¡å¼ï¼‰")
        print("  Qé”®: é€€å‡ºç¨‹åº")
        print("  å›ºå®šè§†è§’æ˜¾ç¤ºï¼Œ3Dæ¨¡å‹å åŠ åœ¨çœŸå®æ‘„åƒæœºç”»é¢ä¸Š")
        print("=" * 60)
        
        self.is_running = True
        
        # å¯åŠ¨MediaPipeæ£€æµ‹çº¿ç¨‹
        detection_thread = threading.Thread(target=self.detection_thread, daemon=True)
        detection_thread.start()
        
        # ç­‰å¾…æ£€æµ‹çº¿ç¨‹å¯åŠ¨
        time.sleep(2)
        
        try:
            # è¿è¡Œå¯è§†åŒ–å™¨
            self.run_with_visualizer()
        finally:
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹ æ¸…ç†èµ„æº...")
        self.is_running = False
        print("âœ… èµ„æºæ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    print("FaceMatrixLab 3D äººè„¸æ¸²æŸ“å™¨ï¼ˆARå¢å¼ºç°å®ç‰ˆæœ¬ï¼‰")
    print("ä½¿ç”¨MediaPipe + Open3Då®ç°å®æ—¶3Däººè„¸è¿½è¸ªæ¸²æŸ“ + ARå åŠ æ•ˆæœ")
    print("æ”¯æŒçœŸå®ç›¸æœºæ ¡å‡†å‚æ•°ï¼Œæä¾›æ›´ç²¾ç¡®çš„3DæŠ•å½±æ•ˆæœ")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = "obj/Andy_Wah_facemesh.obj"
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {model_path}")
        print("è¯·ç¡®ä¿Andy_Wah_facemesh.objæ–‡ä»¶ä½äº obj/ ç›®å½•ä¸­")
        return
    
    # æ£€æŸ¥ç›¸æœºæ ¡å‡†æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    calibration_path = "Camera-Calibration/output/intrinsic.txt"
    if os.path.exists(calibration_path):
        print(f"âœ… å‘ç°ç›¸æœºæ ¡å‡†æ–‡ä»¶ï¼š{calibration_path}")
        print("å°†ä½¿ç”¨çœŸå®ç›¸æœºå‚æ•°è¿›è¡Œç²¾ç¡®3Dæ¸²æŸ“")
    else:
        print(f"âš ï¸ æœªå‘ç°ç›¸æœºæ ¡å‡†æ–‡ä»¶ï¼š{calibration_path}")
        print("å°†ä½¿ç”¨é»˜è®¤ä¼°è®¡å‚æ•°ï¼ˆ50mmç­‰æ•ˆç„¦è·ï¼‰")
        print("ğŸ’¡ å¦‚éœ€è·å¾—æœ€ä½³æ¸²æŸ“æ•ˆæœï¼Œå»ºè®®å…ˆè¿›è¡Œç›¸æœºæ ¡å‡†")
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œæ¸²æŸ“å™¨
        renderer = FaceMatrixLabRenderer(camera_id=0, model_path=model_path)
        renderer.run()
        
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print("ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()
